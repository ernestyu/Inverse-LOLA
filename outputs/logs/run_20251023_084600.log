2025-10-23 08:46:00,653 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_084600.log
2025-10-23 08:46:00,653 | INFO | Configuration file: config.yaml
2025-10-23 08:46:00,653 | INFO | Reward families to process: homogeneous
2025-10-23 08:46:00,653 | INFO | MA-SPI iterations=3, episodes/stage=50, episode_length=100
2025-10-23 08:46:00,653 | INFO | MA-LfL reward epochs=1000, reward batch size=8192
2025-10-23 08:46:00,654 | INFO | Log file located at outputs\logs\run_20251023_084600.log
2025-10-23 08:46:00,654 | INFO | Running experiment for reward family: homogeneous
2025-10-23 08:46:00,654 | INFO | [Experiment:homogeneous] Starting MA-SPI...
2025-10-23 08:46:01,912 | INFO | [MA-SPI] Starting run with 3 stages, 50 episodes/stage, episode length 100
2025-10-23 08:46:01,925 | INFO | [MA-SPI] Stage 1/3 - collecting trajectories...
2025-10-23 08:46:03,631 | INFO | [MA-SPI] Stage 1/3 - collected 10/50 episodes
2025-10-23 08:46:05,128 | INFO | [MA-SPI] Stage 1/3 - collected 20/50 episodes
2025-10-23 08:46:06,628 | INFO | [MA-SPI] Stage 1/3 - collected 30/50 episodes
2025-10-23 08:46:08,160 | INFO | [MA-SPI] Stage 1/3 - collected 40/50 episodes
2025-10-23 08:46:09,730 | INFO | [MA-SPI] Stage 1/3 - collected 50/50 episodes
2025-10-23 08:46:09,734 | INFO | [MA-SPI] Stage 1/3 - Agent 0 avg episode reward: -431.120 (std 24.046)
2025-10-23 08:46:09,735 | INFO | [MA-SPI] Stage 1/3 - Agent 1 avg episode reward: -411.020 (std 20.728)
2025-10-23 08:46:09,735 | INFO | [MA-SPI] Stage 1/3 - dataset size: 5000 transitions
2025-10-23 08:46:10,035 | INFO | [MA-SPI] Stage 1/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.8595, A1_Q_loss:0.8045]
2025-10-23 08:46:10,164 | INFO | [MA-SPI] Stage 1/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.5710, A1_Q_loss:0.6775]
2025-10-23 08:46:10,300 | INFO | [MA-SPI] Stage 1/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.5431, A1_Q_loss:0.6820]
2025-10-23 08:46:10,428 | INFO | [MA-SPI] Stage 1/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.5438, A1_Q_loss:0.6869]
2025-10-23 08:46:10,547 | INFO | [MA-SPI] Stage 1/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.5496, A1_Q_loss:0.6791]
2025-10-23 08:46:10,605 | INFO | [MA-SPI] Stage 1/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0172, A1_Policy_loss:0.0109]
2025-10-23 08:46:10,654 | INFO | [MA-SPI] Stage 1/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0054, A1_Policy_loss:0.0025]
2025-10-23 08:46:10,699 | INFO | [MA-SPI] Stage 1/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0018, A1_Policy_loss:0.0008]
2025-10-23 08:46:10,753 | INFO | [MA-SPI] Stage 1/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0003]
2025-10-23 08:46:10,800 | INFO | [MA-SPI] Stage 1/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 08:46:10,801 | INFO | [MA-SPI] Stage 1/3 - completed
2025-10-23 08:46:10,801 | INFO | [MA-SPI] Stage 2/3 - collecting trajectories...
2025-10-23 08:46:12,289 | INFO | [MA-SPI] Stage 2/3 - collected 10/50 episodes
2025-10-23 08:46:13,784 | INFO | [MA-SPI] Stage 2/3 - collected 20/50 episodes
2025-10-23 08:46:15,418 | INFO | [MA-SPI] Stage 2/3 - collected 30/50 episodes
2025-10-23 08:46:16,993 | INFO | [MA-SPI] Stage 2/3 - collected 40/50 episodes
2025-10-23 08:46:18,743 | INFO | [MA-SPI] Stage 2/3 - collected 50/50 episodes
2025-10-23 08:46:18,747 | INFO | [MA-SPI] Stage 2/3 - Agent 0 avg episode reward: -291.700 (std 20.339)
2025-10-23 08:46:18,747 | INFO | [MA-SPI] Stage 2/3 - Agent 1 avg episode reward: -295.360 (std 25.351)
2025-10-23 08:46:18,747 | INFO | [MA-SPI] Stage 2/3 - dataset size: 5000 transitions
2025-10-23 08:46:18,932 | INFO | [MA-SPI] Stage 2/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.8117, A1_Q_loss:0.6364]
2025-10-23 08:46:19,064 | INFO | [MA-SPI] Stage 2/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.5547, A1_Q_loss:0.5128]
2025-10-23 08:46:19,198 | INFO | [MA-SPI] Stage 2/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.5357, A1_Q_loss:0.4947]
2025-10-23 08:46:19,330 | INFO | [MA-SPI] Stage 2/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.5447, A1_Q_loss:0.4828]
2025-10-23 08:46:19,453 | INFO | [MA-SPI] Stage 2/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.5380, A1_Q_loss:0.4893]
2025-10-23 08:46:19,498 | INFO | [MA-SPI] Stage 2/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0066, A1_Policy_loss:0.0045]
2025-10-23 08:46:19,546 | INFO | [MA-SPI] Stage 2/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0018, A1_Policy_loss:0.0016]
2025-10-23 08:46:19,593 | INFO | [MA-SPI] Stage 2/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0005]
2025-10-23 08:46:19,638 | INFO | [MA-SPI] Stage 2/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 08:46:19,686 | INFO | [MA-SPI] Stage 2/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 08:46:19,687 | INFO | [MA-SPI] Stage 2/3 - completed
2025-10-23 08:46:19,687 | INFO | [MA-SPI] Stage 3/3 - collecting trajectories...
2025-10-23 08:46:21,253 | INFO | [MA-SPI] Stage 3/3 - collected 10/50 episodes
2025-10-23 08:46:22,770 | INFO | [MA-SPI] Stage 3/3 - collected 20/50 episodes
2025-10-23 08:46:24,213 | INFO | [MA-SPI] Stage 3/3 - collected 30/50 episodes
2025-10-23 08:46:25,732 | INFO | [MA-SPI] Stage 3/3 - collected 40/50 episodes
2025-10-23 08:46:27,238 | INFO | [MA-SPI] Stage 3/3 - collected 50/50 episodes
2025-10-23 08:46:27,241 | INFO | [MA-SPI] Stage 3/3 - Agent 0 avg episode reward: -271.440 (std 20.730)
2025-10-23 08:46:27,241 | INFO | [MA-SPI] Stage 3/3 - Agent 1 avg episode reward: -273.380 (std 19.942)
2025-10-23 08:46:27,241 | INFO | [MA-SPI] Stage 3/3 - dataset size: 5000 transitions
2025-10-23 08:46:27,406 | INFO | [MA-SPI] Stage 3/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.4339, A1_Q_loss:0.4916]
2025-10-23 08:46:27,538 | INFO | [MA-SPI] Stage 3/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.4292, A1_Q_loss:0.4625]
2025-10-23 08:46:27,650 | INFO | [MA-SPI] Stage 3/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.4230, A1_Q_loss:0.4694]
2025-10-23 08:46:27,754 | INFO | [MA-SPI] Stage 3/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.4223, A1_Q_loss:0.4646]
2025-10-23 08:46:27,860 | INFO | [MA-SPI] Stage 3/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.4217, A1_Q_loss:0.4658]
2025-10-23 08:46:27,907 | INFO | [MA-SPI] Stage 3/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0024, A1_Policy_loss:0.0028]
2025-10-23 08:46:27,947 | INFO | [MA-SPI] Stage 3/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0008]
2025-10-23 08:46:27,987 | INFO | [MA-SPI] Stage 3/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0003]
2025-10-23 08:46:28,032 | INFO | [MA-SPI] Stage 3/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-23 08:46:28,075 | INFO | [MA-SPI] Stage 3/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:-0.0001, A1_Policy_loss:0.0000]
2025-10-23 08:46:28,075 | INFO | [MA-SPI] Stage 3/3 - completed
2025-10-23 08:46:28,144 | INFO | [Experiment:homogeneous] MA-SPI completed. Artifacts saved to outputs\homogeneous\ma_spi
2025-10-23 08:46:28,144 | INFO | [Experiment:homogeneous] Starting MA-LfL...
2025-10-23 08:46:28,144 | INFO | [MA-LfL] Estimating policies...
2025-10-23 08:46:28,145 | INFO | [MA-LfL][Policy] Stage 1/3 - preparing data
2025-10-23 08:46:28,190 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 10/10 epochs completed (loss=1.1252, baseline=1.6094)
2025-10-23 08:46:28,221 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 10/10 epochs completed (loss=1.1199, baseline=1.6094)
2025-10-23 08:46:28,221 | INFO | [MA-LfL][Policy] Stage 2/3 - preparing data
2025-10-23 08:46:28,246 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 10/10 epochs completed (loss=1.0980, baseline=1.6094)
2025-10-23 08:46:28,271 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 10/10 epochs completed (loss=1.0973, baseline=1.6094)
2025-10-23 08:46:28,271 | INFO | [MA-LfL][Policy] Stage 3/3 - preparing data
2025-10-23 08:46:28,306 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 10/10 epochs completed (loss=1.0654, baseline=1.6094)
2025-10-23 08:46:28,335 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 10/10 epochs completed (loss=1.0732, baseline=1.6094)
2025-10-23 08:46:28,335 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 08:46:28,335 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 0
2025-10-23 08:46:28,664 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 1
2025-10-23 08:46:28,989 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 0
2025-10-23 08:46:29,323 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 1
2025-10-23 08:46:29,684 | INFO | [MA-LfL] Learning rewards...
2025-10-23 08:46:29,701 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=10000 (batch=8192, epochs=1000)
2025-10-23 08:46:31,231 | INFO | [MA-LfL][Reward] Agent 0 - 100/1000 epochs completed (latest loss=0.1519)
2025-10-23 08:46:32,688 | INFO | [MA-LfL][Reward] Agent 0 - 200/1000 epochs completed (latest loss=0.1498)
2025-10-23 08:46:34,183 | INFO | [MA-LfL][Reward] Agent 0 - 300/1000 epochs completed (latest loss=0.1414)
2025-10-23 08:46:35,677 | INFO | [MA-LfL][Reward] Agent 0 - 400/1000 epochs completed (latest loss=0.1412)
2025-10-23 08:46:37,047 | INFO | [MA-LfL][Reward] Agent 0 - 500/1000 epochs completed (latest loss=0.1457)
2025-10-23 08:46:38,464 | INFO | [MA-LfL][Reward] Agent 0 - 600/1000 epochs completed (latest loss=0.1402)
2025-10-23 08:46:39,903 | INFO | [MA-LfL][Reward] Agent 0 - 700/1000 epochs completed (latest loss=0.1373)
2025-10-23 08:46:41,253 | INFO | [MA-LfL][Reward] Agent 0 - 800/1000 epochs completed (latest loss=0.1406)
2025-10-23 08:46:42,630 | INFO | [MA-LfL][Reward] Agent 0 - 900/1000 epochs completed (latest loss=0.1372)
2025-10-23 08:46:44,023 | INFO | [MA-LfL][Reward] Agent 0 - 1000/1000 epochs completed (latest loss=0.1453)
2025-10-23 08:46:44,031 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=10000 (batch=8192, epochs=1000)
2025-10-23 08:46:45,437 | INFO | [MA-LfL][Reward] Agent 1 - 100/1000 epochs completed (latest loss=0.2112)
2025-10-23 08:46:46,833 | INFO | [MA-LfL][Reward] Agent 1 - 200/1000 epochs completed (latest loss=0.2050)
2025-10-23 08:46:48,221 | INFO | [MA-LfL][Reward] Agent 1 - 300/1000 epochs completed (latest loss=0.2098)
2025-10-23 08:46:49,590 | INFO | [MA-LfL][Reward] Agent 1 - 400/1000 epochs completed (latest loss=0.1999)
2025-10-23 08:46:50,948 | INFO | [MA-LfL][Reward] Agent 1 - 500/1000 epochs completed (latest loss=0.1940)
2025-10-23 08:46:52,381 | INFO | [MA-LfL][Reward] Agent 1 - 600/1000 epochs completed (latest loss=0.1951)
2025-10-23 08:46:53,921 | INFO | [MA-LfL][Reward] Agent 1 - 700/1000 epochs completed (latest loss=0.2014)
2025-10-23 08:46:55,300 | INFO | [MA-LfL][Reward] Agent 1 - 800/1000 epochs completed (latest loss=0.1978)
2025-10-23 08:46:56,785 | INFO | [MA-LfL][Reward] Agent 1 - 900/1000 epochs completed (latest loss=0.1957)
2025-10-23 08:46:58,193 | INFO | [MA-LfL][Reward] Agent 1 - 1000/1000 epochs completed (latest loss=0.1997)
2025-10-23 08:46:58,193 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 08:46:58,991 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 08:46:58,991 | INFO | [Experiment:homogeneous] MA-LfL completed. Artifacts saved to outputs\homogeneous\ma_lfl
2025-10-23 08:46:58,992 | INFO | [Experiment:homogeneous] Agent 0 metrics - Pearson: 0.0712 | Spearman: 0.0979
2025-10-23 08:46:58,992 | INFO | [Experiment:homogeneous] Agent 1 metrics - Pearson: 0.0671 | Spearman: 0.0991
2025-10-23 08:46:58,992 | INFO | [Experiment:homogeneous] Trend stages: 1, 2
2025-10-23 08:46:58,992 | INFO | [Experiment:homogeneous] Trend Pearson: -0.1554, -0.1359
2025-10-23 08:46:58,992 | INFO | [Experiment:homogeneous] Trend Spearman: -0.0989, -0.0900
2025-10-23 08:46:58,992 | INFO | [Experiment:homogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 08:46:58,992 | INFO | [Experiment:homogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 08:46:58,992 | INFO | [Experiment:homogeneous] Correlation trend non-decreasing? YES
2025-10-23 08:46:58,993 | INFO | Summary saved to outputs\summary.json
2025-10-23 08:46:58,993 | INFO | Run complete.
