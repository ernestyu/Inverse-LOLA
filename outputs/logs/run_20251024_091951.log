2025-10-24 09:19:51,120 | INFO | Logging initialized. Log file: outputs\logs\run_20251024_091951.log
2025-10-24 09:19:51,120 | INFO | Configuration file: config.yaml
2025-10-24 09:19:51,120 | INFO | Reward families to process: heterogeneous
2025-10-24 09:19:51,120 | INFO | MA-SPI iterations=5, episodes/stage=10, episode_length=100
2025-10-24 09:19:51,120 | INFO | MA-LfL reward epochs=20000, reward batch size=8192
2025-10-24 09:19:51,120 | INFO | Log file located at outputs\logs\run_20251024_091951.log
2025-10-24 09:19:51,121 | INFO | Running experiment for reward family: heterogeneous
2025-10-24 09:19:51,121 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-24 09:19:52,031 | INFO | [MA-SPI] Starting run with 5 stages, 10 episodes/stage, episode length 100
2025-10-24 09:19:52,044 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-24 09:19:52,496 | INFO | [MA-SPI] Stage 1/5 - collected 2/10 episodes
2025-10-24 09:19:52,757 | INFO | [MA-SPI] Stage 1/5 - collected 4/10 episodes
2025-10-24 09:19:53,030 | INFO | [MA-SPI] Stage 1/5 - collected 6/10 episodes
2025-10-24 09:19:53,281 | INFO | [MA-SPI] Stage 1/5 - collected 8/10 episodes
2025-10-24 09:19:53,538 | INFO | [MA-SPI] Stage 1/5 - collected 10/10 episodes
2025-10-24 09:19:53,539 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -137.400 (std 33.539)
2025-10-24 09:19:53,539 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -114.900 (std 35.184)
2025-10-24 09:19:53,540 | INFO | [MA-SPI] Stage 1/5 - dataset size: 1000 transitions
2025-10-24 09:19:53,776 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:2.7630, A1_Q_loss:3.1812]
2025-10-24 09:19:53,862 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.3751, A1_Q_loss:1.4296]
2025-10-24 09:19:53,947 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.8376, A1_Q_loss:1.0367]
2025-10-24 09:19:54,034 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.5093, A1_Q_loss:0.7529]
2025-10-24 09:19:54,118 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4704, A1_Q_loss:0.5672]
2025-10-24 09:19:54,156 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0288, A1_Policy_loss:0.0183]
2025-10-24 09:19:54,191 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0090, A1_Policy_loss:0.0042]
2025-10-24 09:19:54,228 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0015]
2025-10-24 09:19:54,266 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0013, A1_Policy_loss:0.0006]
2025-10-24 09:19:54,304 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0002]
2025-10-24 09:19:54,305 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-24 09:19:54,305 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-24 09:19:54,619 | INFO | [MA-SPI] Stage 2/5 - collected 2/10 episodes
2025-10-24 09:19:54,940 | INFO | [MA-SPI] Stage 2/5 - collected 4/10 episodes
2025-10-24 09:19:55,258 | INFO | [MA-SPI] Stage 2/5 - collected 6/10 episodes
2025-10-24 09:19:55,538 | INFO | [MA-SPI] Stage 2/5 - collected 8/10 episodes
2025-10-24 09:19:55,827 | INFO | [MA-SPI] Stage 2/5 - collected 10/10 episodes
2025-10-24 09:19:55,829 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: 67.000 (std 29.783)
2025-10-24 09:19:55,829 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 47.100 (std 20.535)
2025-10-24 09:19:55,829 | INFO | [MA-SPI] Stage 2/5 - dataset size: 1000 transitions
2025-10-24 09:19:55,928 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:1.6607, A1_Q_loss:1.4316]
2025-10-24 09:19:56,028 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.0833, A1_Q_loss:1.1384]
2025-10-24 09:19:56,119 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.9357, A1_Q_loss:1.0149]
2025-10-24 09:19:56,215 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.8746, A1_Q_loss:0.9769]
2025-10-24 09:19:56,316 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.8530, A1_Q_loss:0.9853]
2025-10-24 09:19:56,356 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0158, A1_Policy_loss:0.0072]
2025-10-24 09:19:56,414 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0048, A1_Policy_loss:0.0025]
2025-10-24 09:19:56,458 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0020, A1_Policy_loss:0.0010]
2025-10-24 09:19:56,492 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0004]
2025-10-24 09:19:56,529 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-24 09:19:56,529 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-24 09:19:56,530 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-24 09:19:56,811 | INFO | [MA-SPI] Stage 3/5 - collected 2/10 episodes
2025-10-24 09:19:57,068 | INFO | [MA-SPI] Stage 3/5 - collected 4/10 episodes
2025-10-24 09:19:57,355 | INFO | [MA-SPI] Stage 3/5 - collected 6/10 episodes
2025-10-24 09:19:57,610 | INFO | [MA-SPI] Stage 3/5 - collected 8/10 episodes
2025-10-24 09:19:57,852 | INFO | [MA-SPI] Stage 3/5 - collected 10/10 episodes
2025-10-24 09:19:57,853 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 113.400 (std 28.051)
2025-10-24 09:19:57,854 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 109.100 (std 25.137)
2025-10-24 09:19:57,854 | INFO | [MA-SPI] Stage 3/5 - dataset size: 1000 transitions
2025-10-24 09:19:57,944 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.7991, A1_Q_loss:0.6151]
2025-10-24 09:19:58,028 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.8251, A1_Q_loss:0.5328]
2025-10-24 09:19:58,123 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.7463, A1_Q_loss:0.5244]
2025-10-24 09:19:58,220 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.7612, A1_Q_loss:0.5156]
2025-10-24 09:19:58,311 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.7643, A1_Q_loss:0.5197]
2025-10-24 09:19:58,345 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0067, A1_Policy_loss:0.0051]
2025-10-24 09:19:58,383 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0023, A1_Policy_loss:0.0019]
2025-10-24 09:19:58,419 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0007]
2025-10-24 09:19:58,453 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-24 09:19:58,492 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-24 09:19:58,492 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-24 09:19:58,492 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-24 09:19:58,758 | INFO | [MA-SPI] Stage 4/5 - collected 2/10 episodes
2025-10-24 09:19:59,042 | INFO | [MA-SPI] Stage 4/5 - collected 4/10 episodes
2025-10-24 09:19:59,337 | INFO | [MA-SPI] Stage 4/5 - collected 6/10 episodes
2025-10-24 09:19:59,615 | INFO | [MA-SPI] Stage 4/5 - collected 8/10 episodes
2025-10-24 09:19:59,898 | INFO | [MA-SPI] Stage 4/5 - collected 10/10 episodes
2025-10-24 09:19:59,898 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 112.800 (std 30.225)
2025-10-24 09:19:59,899 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 98.900 (std 33.721)
2025-10-24 09:19:59,899 | INFO | [MA-SPI] Stage 4/5 - dataset size: 1000 transitions
2025-10-24 09:20:00,001 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.5955, A1_Q_loss:0.4295]
2025-10-24 09:20:00,102 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.5255, A1_Q_loss:0.3559]
2025-10-24 09:20:00,193 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.4722, A1_Q_loss:0.3525]
2025-10-24 09:20:00,282 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.5347, A1_Q_loss:0.3298]
2025-10-24 09:20:00,368 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4735, A1_Q_loss:0.3408]
2025-10-24 09:20:00,403 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0037, A1_Policy_loss:0.0032]
2025-10-24 09:20:00,443 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0011, A1_Policy_loss:0.0010]
2025-10-24 09:20:00,478 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0005]
2025-10-24 09:20:00,517 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-24 09:20:00,554 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-24 09:20:00,554 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-24 09:20:00,554 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-24 09:20:00,866 | INFO | [MA-SPI] Stage 5/5 - collected 2/10 episodes
2025-10-24 09:20:01,180 | INFO | [MA-SPI] Stage 5/5 - collected 4/10 episodes
2025-10-24 09:20:01,484 | INFO | [MA-SPI] Stage 5/5 - collected 6/10 episodes
2025-10-24 09:20:01,792 | INFO | [MA-SPI] Stage 5/5 - collected 8/10 episodes
2025-10-24 09:20:02,111 | INFO | [MA-SPI] Stage 5/5 - collected 10/10 episodes
2025-10-24 09:20:02,113 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 115.500 (std 18.720)
2025-10-24 09:20:02,113 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 110.000 (std 23.422)
2025-10-24 09:20:02,113 | INFO | [MA-SPI] Stage 5/5 - dataset size: 1000 transitions
2025-10-24 09:20:02,218 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.5018, A1_Q_loss:0.4675]
2025-10-24 09:20:02,332 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.4171, A1_Q_loss:0.4131]
2025-10-24 09:20:02,442 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.4285, A1_Q_loss:0.3537]
2025-10-24 09:20:02,527 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.4103, A1_Q_loss:0.4335]
2025-10-24 09:20:02,639 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4163, A1_Q_loss:0.4042]
2025-10-24 09:20:02,676 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0023, A1_Policy_loss:0.0031]
2025-10-24 09:20:02,714 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0012]
2025-10-24 09:20:02,750 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0005]
2025-10-24 09:20:02,786 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0002]
2025-10-24 09:20:02,823 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-24 09:20:02,823 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-24 09:20:02,858 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-24 09:20:02,858 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-24 09:20:02,858 | INFO | [MA-LfL] Estimating policies...
2025-10-24 09:20:02,858 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-24 09:20:02,879 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 2/10 epochs completed (loss=3.2695, baseline=1.6094)
2025-10-24 09:20:02,884 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 4/10 epochs completed (loss=1.4244, baseline=1.6094)
2025-10-24 09:20:02,888 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 6/10 epochs completed (loss=1.2134, baseline=1.6094)
2025-10-24 09:20:02,891 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 8/10 epochs completed (loss=1.1068, baseline=1.6094)
2025-10-24 09:20:02,896 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.0913, baseline=1.6094)
2025-10-24 09:20:02,903 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 2/10 epochs completed (loss=3.0694, baseline=1.6094)
2025-10-24 09:20:02,907 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 4/10 epochs completed (loss=1.4800, baseline=1.6094)
2025-10-24 09:20:02,912 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 6/10 epochs completed (loss=1.2070, baseline=1.6094)
2025-10-24 09:20:02,919 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 8/10 epochs completed (loss=1.1019, baseline=1.6094)
2025-10-24 09:20:02,925 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.0798, baseline=1.6094)
2025-10-24 09:20:02,925 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-24 09:20:02,933 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 2/10 epochs completed (loss=3.1231, baseline=1.6094)
2025-10-24 09:20:02,939 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 4/10 epochs completed (loss=2.5654, baseline=1.6094)
2025-10-24 09:20:02,946 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 6/10 epochs completed (loss=1.2076, baseline=1.6094)
2025-10-24 09:20:02,953 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 8/10 epochs completed (loss=1.0764, baseline=1.6094)
2025-10-24 09:20:02,959 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=0.9976, baseline=1.6094)
2025-10-24 09:20:02,966 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 2/10 epochs completed (loss=2.4523, baseline=1.6094)
2025-10-24 09:20:02,971 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 4/10 epochs completed (loss=1.2198, baseline=1.6094)
2025-10-24 09:20:02,976 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 6/10 epochs completed (loss=1.0589, baseline=1.6094)
2025-10-24 09:20:02,980 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 8/10 epochs completed (loss=1.0233, baseline=1.6094)
2025-10-24 09:20:02,986 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=0.9760, baseline=1.6094)
2025-10-24 09:20:02,986 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-24 09:20:02,995 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 2/10 epochs completed (loss=2.6041, baseline=1.6094)
2025-10-24 09:20:03,003 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 4/10 epochs completed (loss=1.7274, baseline=1.6094)
2025-10-24 09:20:03,010 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 6/10 epochs completed (loss=1.1143, baseline=1.6094)
2025-10-24 09:20:03,015 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 8/10 epochs completed (loss=1.0074, baseline=1.6094)
2025-10-24 09:20:03,021 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=0.9835, baseline=1.6094)
2025-10-24 09:20:03,028 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 2/10 epochs completed (loss=5.7030, baseline=1.6094)
2025-10-24 09:20:03,032 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 4/10 epochs completed (loss=1.6001, baseline=1.6094)
2025-10-24 09:20:03,037 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 6/10 epochs completed (loss=1.2568, baseline=1.6094)
2025-10-24 09:20:03,043 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 8/10 epochs completed (loss=1.0344, baseline=1.6094)
2025-10-24 09:20:03,048 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0029, baseline=1.6094)
2025-10-24 09:20:03,048 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-24 09:20:03,054 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 2/10 epochs completed (loss=2.8728, baseline=1.6094)
2025-10-24 09:20:03,059 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 4/10 epochs completed (loss=1.6201, baseline=1.6094)
2025-10-24 09:20:03,065 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 6/10 epochs completed (loss=1.2387, baseline=1.6094)
2025-10-24 09:20:03,072 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 8/10 epochs completed (loss=1.1303, baseline=1.6094)
2025-10-24 09:20:03,077 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0035, baseline=1.6094)
2025-10-24 09:20:03,084 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 2/10 epochs completed (loss=2.9283, baseline=1.6094)
2025-10-24 09:20:03,088 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 4/10 epochs completed (loss=1.4339, baseline=1.6094)
2025-10-24 09:20:03,092 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 6/10 epochs completed (loss=1.0704, baseline=1.6094)
2025-10-24 09:20:03,096 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 8/10 epochs completed (loss=1.0526, baseline=1.6094)
2025-10-24 09:20:03,101 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0177, baseline=1.6094)
2025-10-24 09:20:03,101 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-24 09:20:03,107 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 2/10 epochs completed (loss=3.1318, baseline=1.6094)
2025-10-24 09:20:03,111 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 4/10 epochs completed (loss=1.6561, baseline=1.6094)
2025-10-24 09:20:03,116 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 6/10 epochs completed (loss=1.0889, baseline=1.6094)
2025-10-24 09:20:03,122 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 8/10 epochs completed (loss=1.0369, baseline=1.6094)
2025-10-24 09:20:03,128 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0083, baseline=1.6094)
2025-10-24 09:20:03,135 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 2/10 epochs completed (loss=3.7079, baseline=1.6094)
2025-10-24 09:20:03,140 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 4/10 epochs completed (loss=1.5068, baseline=1.6094)
2025-10-24 09:20:03,144 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 6/10 epochs completed (loss=1.1110, baseline=1.6094)
2025-10-24 09:20:03,148 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 8/10 epochs completed (loss=1.0331, baseline=1.6094)
2025-10-24 09:20:03,152 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0069, baseline=1.6094)
2025-10-24 09:20:03,152 | INFO | [MA-LfL] Computing reward targets...
2025-10-24 09:20:03,153 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-24 09:20:03,470 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-24 09:20:03,778 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-24 09:20:04,115 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-24 09:20:04,456 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-24 09:20:04,825 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-24 09:20:05,200 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-24 09:20:05,617 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-24 09:20:06,023 | INFO | [MA-LfL] Learning rewards...
2025-10-24 09:20:06,028 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=4000 (batch=1024, epochs=20000, reward_lr=1.00e-03, shaping_lr=1.00e-05)
