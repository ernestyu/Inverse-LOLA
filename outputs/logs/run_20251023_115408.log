2025-10-23 11:54:08,094 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_115408.log
2025-10-23 11:54:08,094 | INFO | Configuration file: config.yaml
2025-10-23 11:54:08,095 | INFO | Reward families to process: heterogeneous
2025-10-23 11:54:08,095 | INFO | MA-SPI iterations=10, episodes/stage=30, episode_length=100
2025-10-23 11:54:08,095 | INFO | MA-LfL reward epochs=2000, reward batch size=8192
2025-10-23 11:54:08,095 | INFO | Log file located at outputs\logs\run_20251023_115408.log
2025-10-23 11:54:08,096 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 11:54:08,096 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 11:54:08,961 | INFO | [MA-SPI] Starting run with 10 stages, 30 episodes/stage, episode length 100
2025-10-23 11:54:08,972 | INFO | [MA-SPI] Stage 1/10 - collecting trajectories...
2025-10-23 11:54:09,937 | INFO | [MA-SPI] Stage 1/10 - collected 6/30 episodes
2025-10-23 11:54:10,720 | INFO | [MA-SPI] Stage 1/10 - collected 12/30 episodes
2025-10-23 11:54:11,481 | INFO | [MA-SPI] Stage 1/10 - collected 18/30 episodes
2025-10-23 11:54:12,261 | INFO | [MA-SPI] Stage 1/10 - collected 24/30 episodes
2025-10-23 11:54:13,071 | INFO | [MA-SPI] Stage 1/10 - collected 30/30 episodes
2025-10-23 11:54:13,074 | INFO | [MA-SPI] Stage 1/10 - Agent 0 avg episode reward: -133.567 (std 31.196)
2025-10-23 11:54:13,074 | INFO | [MA-SPI] Stage 1/10 - Agent 1 avg episode reward: -113.300 (std 31.693)
2025-10-23 11:54:13,074 | INFO | [MA-SPI] Stage 1/10 - dataset size: 3000 transitions
2025-10-23 11:54:13,318 | INFO | [MA-SPI] Stage 1/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:3.0577, A1_Q_loss:3.0181]
2025-10-23 11:54:13,405 | INFO | [MA-SPI] Stage 1/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:1.5579, A1_Q_loss:1.4081]
2025-10-23 11:54:13,487 | INFO | [MA-SPI] Stage 1/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:1.1305, A1_Q_loss:0.7885]
2025-10-23 11:54:13,569 | INFO | [MA-SPI] Stage 1/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.7832, A1_Q_loss:0.6657]
2025-10-23 11:54:13,653 | INFO | [MA-SPI] Stage 1/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.6631, A1_Q_loss:0.6067]
2025-10-23 11:54:13,695 | INFO | [MA-SPI] Stage 1/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0246, A1_Policy_loss:0.0224]
2025-10-23 11:54:13,736 | INFO | [MA-SPI] Stage 1/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0081, A1_Policy_loss:0.0053]
2025-10-23 11:54:13,769 | INFO | [MA-SPI] Stage 1/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0029, A1_Policy_loss:0.0016]
2025-10-23 11:54:13,803 | INFO | [MA-SPI] Stage 1/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0006]
2025-10-23 11:54:13,837 | INFO | [MA-SPI] Stage 1/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 11:54:13,837 | INFO | [MA-SPI] Stage 1/10 - completed
2025-10-23 11:54:13,837 | INFO | [MA-SPI] Stage 2/10 - collecting trajectories...
2025-10-23 11:54:14,590 | INFO | [MA-SPI] Stage 2/10 - collected 6/30 episodes
2025-10-23 11:54:15,367 | INFO | [MA-SPI] Stage 2/10 - collected 12/30 episodes
2025-10-23 11:54:16,181 | INFO | [MA-SPI] Stage 2/10 - collected 18/30 episodes
2025-10-23 11:54:16,966 | INFO | [MA-SPI] Stage 2/10 - collected 24/30 episodes
2025-10-23 11:54:17,804 | INFO | [MA-SPI] Stage 2/10 - collected 30/30 episodes
2025-10-23 11:54:17,807 | INFO | [MA-SPI] Stage 2/10 - Agent 0 avg episode reward: 54.900 (std 37.226)
2025-10-23 11:54:17,807 | INFO | [MA-SPI] Stage 2/10 - Agent 1 avg episode reward: 59.633 (std 35.896)
2025-10-23 11:54:17,807 | INFO | [MA-SPI] Stage 2/10 - dataset size: 3000 transitions
2025-10-23 11:54:17,901 | INFO | [MA-SPI] Stage 2/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:1.7503, A1_Q_loss:1.1955]
2025-10-23 11:54:17,997 | INFO | [MA-SPI] Stage 2/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.8051, A1_Q_loss:1.0462]
2025-10-23 11:54:18,094 | INFO | [MA-SPI] Stage 2/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.7919, A1_Q_loss:0.9814]
2025-10-23 11:54:18,179 | INFO | [MA-SPI] Stage 2/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.7450, A1_Q_loss:0.9524]
2025-10-23 11:54:18,266 | INFO | [MA-SPI] Stage 2/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.7436, A1_Q_loss:0.9499]
2025-10-23 11:54:18,301 | INFO | [MA-SPI] Stage 2/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0128, A1_Policy_loss:0.0057]
2025-10-23 11:54:18,342 | INFO | [MA-SPI] Stage 2/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0028]
2025-10-23 11:54:18,379 | INFO | [MA-SPI] Stage 2/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0014, A1_Policy_loss:0.0008]
2025-10-23 11:54:18,414 | INFO | [MA-SPI] Stage 2/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0003]
2025-10-23 11:54:18,451 | INFO | [MA-SPI] Stage 2/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 11:54:18,451 | INFO | [MA-SPI] Stage 2/10 - completed
2025-10-23 11:54:18,451 | INFO | [MA-SPI] Stage 3/10 - collecting trajectories...
2025-10-23 11:54:19,260 | INFO | [MA-SPI] Stage 3/10 - collected 6/30 episodes
2025-10-23 11:54:20,106 | INFO | [MA-SPI] Stage 3/10 - collected 12/30 episodes
2025-10-23 11:54:20,944 | INFO | [MA-SPI] Stage 3/10 - collected 18/30 episodes
2025-10-23 11:54:21,858 | INFO | [MA-SPI] Stage 3/10 - collected 24/30 episodes
2025-10-23 11:54:22,694 | INFO | [MA-SPI] Stage 3/10 - collected 30/30 episodes
2025-10-23 11:54:22,695 | INFO | [MA-SPI] Stage 3/10 - Agent 0 avg episode reward: 110.600 (std 18.804)
2025-10-23 11:54:22,697 | INFO | [MA-SPI] Stage 3/10 - Agent 1 avg episode reward: 106.733 (std 20.258)
2025-10-23 11:54:22,697 | INFO | [MA-SPI] Stage 3/10 - dataset size: 3000 transitions
2025-10-23 11:54:22,804 | INFO | [MA-SPI] Stage 3/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.6757, A1_Q_loss:0.5499]
2025-10-23 11:54:22,896 | INFO | [MA-SPI] Stage 3/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.6097, A1_Q_loss:0.3913]
2025-10-23 11:54:22,987 | INFO | [MA-SPI] Stage 3/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.6006, A1_Q_loss:0.3474]
2025-10-23 11:54:23,080 | INFO | [MA-SPI] Stage 3/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.5920, A1_Q_loss:0.3565]
2025-10-23 11:54:23,166 | INFO | [MA-SPI] Stage 3/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.6041, A1_Q_loss:0.3335]
2025-10-23 11:54:23,203 | INFO | [MA-SPI] Stage 3/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0041, A1_Policy_loss:0.0031]
2025-10-23 11:54:23,240 | INFO | [MA-SPI] Stage 3/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0018, A1_Policy_loss:0.0012]
2025-10-23 11:54:23,280 | INFO | [MA-SPI] Stage 3/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0004]
2025-10-23 11:54:23,314 | INFO | [MA-SPI] Stage 3/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0002]
2025-10-23 11:54:23,350 | INFO | [MA-SPI] Stage 3/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 11:54:23,351 | INFO | [MA-SPI] Stage 3/10 - completed
2025-10-23 11:54:23,351 | INFO | [MA-SPI] Stage 4/10 - collecting trajectories...
2025-10-23 11:54:24,105 | INFO | [MA-SPI] Stage 4/10 - collected 6/30 episodes
2025-10-23 11:54:24,886 | INFO | [MA-SPI] Stage 4/10 - collected 12/30 episodes
2025-10-23 11:54:25,714 | INFO | [MA-SPI] Stage 4/10 - collected 18/30 episodes
2025-10-23 11:54:26,563 | INFO | [MA-SPI] Stage 4/10 - collected 24/30 episodes
2025-10-23 11:54:27,444 | INFO | [MA-SPI] Stage 4/10 - collected 30/30 episodes
2025-10-23 11:54:27,446 | INFO | [MA-SPI] Stage 4/10 - Agent 0 avg episode reward: 109.200 (std 21.564)
2025-10-23 11:54:27,446 | INFO | [MA-SPI] Stage 4/10 - Agent 1 avg episode reward: 106.567 (std 19.626)
2025-10-23 11:54:27,446 | INFO | [MA-SPI] Stage 4/10 - dataset size: 3000 transitions
2025-10-23 11:54:27,546 | INFO | [MA-SPI] Stage 4/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.5164, A1_Q_loss:0.5827]
2025-10-23 11:54:27,648 | INFO | [MA-SPI] Stage 4/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.5028, A1_Q_loss:0.5341]
2025-10-23 11:54:27,757 | INFO | [MA-SPI] Stage 4/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.5019, A1_Q_loss:0.5360]
2025-10-23 11:54:27,854 | INFO | [MA-SPI] Stage 4/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.4935, A1_Q_loss:0.5250]
2025-10-23 11:54:27,945 | INFO | [MA-SPI] Stage 4/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.4896, A1_Q_loss:0.5301]
2025-10-23 11:54:27,984 | INFO | [MA-SPI] Stage 4/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0027, A1_Policy_loss:0.0033]
2025-10-23 11:54:28,019 | INFO | [MA-SPI] Stage 4/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0011]
2025-10-23 11:54:28,053 | INFO | [MA-SPI] Stage 4/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0003]
2025-10-23 11:54:28,089 | INFO | [MA-SPI] Stage 4/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 11:54:28,125 | INFO | [MA-SPI] Stage 4/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 11:54:28,125 | INFO | [MA-SPI] Stage 4/10 - completed
2025-10-23 11:54:28,125 | INFO | [MA-SPI] Stage 5/10 - collecting trajectories...
2025-10-23 11:54:28,931 | INFO | [MA-SPI] Stage 5/10 - collected 6/30 episodes
2025-10-23 11:54:29,727 | INFO | [MA-SPI] Stage 5/10 - collected 12/30 episodes
2025-10-23 11:54:30,547 | INFO | [MA-SPI] Stage 5/10 - collected 18/30 episodes
2025-10-23 11:54:31,395 | INFO | [MA-SPI] Stage 5/10 - collected 24/30 episodes
2025-10-23 11:54:32,204 | INFO | [MA-SPI] Stage 5/10 - collected 30/30 episodes
2025-10-23 11:54:32,206 | INFO | [MA-SPI] Stage 5/10 - Agent 0 avg episode reward: 109.267 (std 17.497)
2025-10-23 11:54:32,206 | INFO | [MA-SPI] Stage 5/10 - Agent 1 avg episode reward: 111.200 (std 18.251)
2025-10-23 11:54:32,207 | INFO | [MA-SPI] Stage 5/10 - dataset size: 3000 transitions
2025-10-23 11:54:32,313 | INFO | [MA-SPI] Stage 5/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.4865, A1_Q_loss:0.4253]
2025-10-23 11:54:32,411 | INFO | [MA-SPI] Stage 5/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.4779, A1_Q_loss:0.4123]
2025-10-23 11:54:32,501 | INFO | [MA-SPI] Stage 5/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.4571, A1_Q_loss:0.3895]
2025-10-23 11:54:32,588 | INFO | [MA-SPI] Stage 5/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.4505, A1_Q_loss:0.3861]
2025-10-23 11:54:32,682 | INFO | [MA-SPI] Stage 5/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.4563, A1_Q_loss:0.4015]
2025-10-23 11:54:32,720 | INFO | [MA-SPI] Stage 5/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0026, A1_Policy_loss:0.0029]
2025-10-23 11:54:32,755 | INFO | [MA-SPI] Stage 5/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0011, A1_Policy_loss:0.0011]
2025-10-23 11:54:32,788 | INFO | [MA-SPI] Stage 5/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0004]
2025-10-23 11:54:32,825 | INFO | [MA-SPI] Stage 5/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 11:54:32,860 | INFO | [MA-SPI] Stage 5/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 11:54:32,860 | INFO | [MA-SPI] Stage 5/10 - completed
2025-10-23 11:54:32,860 | INFO | [MA-SPI] Stage 6/10 - collecting trajectories...
2025-10-23 11:54:33,625 | INFO | [MA-SPI] Stage 6/10 - collected 6/30 episodes
2025-10-23 11:54:34,412 | INFO | [MA-SPI] Stage 6/10 - collected 12/30 episodes
2025-10-23 11:54:35,225 | INFO | [MA-SPI] Stage 6/10 - collected 18/30 episodes
2025-10-23 11:54:36,052 | INFO | [MA-SPI] Stage 6/10 - collected 24/30 episodes
2025-10-23 11:54:36,871 | INFO | [MA-SPI] Stage 6/10 - collected 30/30 episodes
2025-10-23 11:54:36,873 | INFO | [MA-SPI] Stage 6/10 - Agent 0 avg episode reward: 98.100 (std 18.698)
2025-10-23 11:54:36,873 | INFO | [MA-SPI] Stage 6/10 - Agent 1 avg episode reward: 98.033 (std 20.129)
2025-10-23 11:54:36,874 | INFO | [MA-SPI] Stage 6/10 - dataset size: 3000 transitions
2025-10-23 11:54:36,977 | INFO | [MA-SPI] Stage 6/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.5747, A1_Q_loss:0.5661]
2025-10-23 11:54:37,069 | INFO | [MA-SPI] Stage 6/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.5238, A1_Q_loss:0.5464]
2025-10-23 11:54:37,166 | INFO | [MA-SPI] Stage 6/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.5213, A1_Q_loss:0.5300]
2025-10-23 11:54:37,254 | INFO | [MA-SPI] Stage 6/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.5072, A1_Q_loss:0.5262]
2025-10-23 11:54:37,342 | INFO | [MA-SPI] Stage 6/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.5019, A1_Q_loss:0.5169]
2025-10-23 11:54:37,380 | INFO | [MA-SPI] Stage 6/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0030, A1_Policy_loss:0.0037]
2025-10-23 11:54:37,414 | INFO | [MA-SPI] Stage 6/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0009, A1_Policy_loss:0.0013]
2025-10-23 11:54:37,452 | INFO | [MA-SPI] Stage 6/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0005]
2025-10-23 11:54:37,491 | INFO | [MA-SPI] Stage 6/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 11:54:37,525 | INFO | [MA-SPI] Stage 6/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 11:54:37,525 | INFO | [MA-SPI] Stage 6/10 - completed
2025-10-23 11:54:37,525 | INFO | [MA-SPI] Stage 7/10 - collecting trajectories...
2025-10-23 11:54:38,324 | INFO | [MA-SPI] Stage 7/10 - collected 6/30 episodes
2025-10-23 11:54:39,080 | INFO | [MA-SPI] Stage 7/10 - collected 12/30 episodes
2025-10-23 11:54:39,846 | INFO | [MA-SPI] Stage 7/10 - collected 18/30 episodes
2025-10-23 11:54:40,645 | INFO | [MA-SPI] Stage 7/10 - collected 24/30 episodes
2025-10-23 11:54:41,439 | INFO | [MA-SPI] Stage 7/10 - collected 30/30 episodes
2025-10-23 11:54:41,441 | INFO | [MA-SPI] Stage 7/10 - Agent 0 avg episode reward: 109.500 (std 18.523)
2025-10-23 11:54:41,441 | INFO | [MA-SPI] Stage 7/10 - Agent 1 avg episode reward: 106.433 (std 16.194)
2025-10-23 11:54:41,441 | INFO | [MA-SPI] Stage 7/10 - dataset size: 3000 transitions
2025-10-23 11:54:41,535 | INFO | [MA-SPI] Stage 7/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.5350, A1_Q_loss:0.4035]
2025-10-23 11:54:41,630 | INFO | [MA-SPI] Stage 7/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.4985, A1_Q_loss:0.3672]
2025-10-23 11:54:41,723 | INFO | [MA-SPI] Stage 7/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.4852, A1_Q_loss:0.3599]
2025-10-23 11:54:41,809 | INFO | [MA-SPI] Stage 7/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.5027, A1_Q_loss:0.3389]
2025-10-23 11:54:41,890 | INFO | [MA-SPI] Stage 7/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.4899, A1_Q_loss:0.3658]
2025-10-23 11:54:41,926 | INFO | [MA-SPI] Stage 7/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0022, A1_Policy_loss:0.0032]
2025-10-23 11:54:41,963 | INFO | [MA-SPI] Stage 7/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0009, A1_Policy_loss:0.0011]
2025-10-23 11:54:41,999 | INFO | [MA-SPI] Stage 7/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0004]
2025-10-23 11:54:42,038 | INFO | [MA-SPI] Stage 7/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 11:54:42,072 | INFO | [MA-SPI] Stage 7/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 11:54:42,072 | INFO | [MA-SPI] Stage 7/10 - completed
2025-10-23 11:54:42,072 | INFO | [MA-SPI] Stage 8/10 - collecting trajectories...
2025-10-23 11:54:42,836 | INFO | [MA-SPI] Stage 8/10 - collected 6/30 episodes
2025-10-23 11:54:43,583 | INFO | [MA-SPI] Stage 8/10 - collected 12/30 episodes
2025-10-23 11:54:44,333 | INFO | [MA-SPI] Stage 8/10 - collected 18/30 episodes
2025-10-23 11:54:45,138 | INFO | [MA-SPI] Stage 8/10 - collected 24/30 episodes
2025-10-23 11:54:45,958 | INFO | [MA-SPI] Stage 8/10 - collected 30/30 episodes
2025-10-23 11:54:45,961 | INFO | [MA-SPI] Stage 8/10 - Agent 0 avg episode reward: 107.200 (std 18.862)
2025-10-23 11:54:45,961 | INFO | [MA-SPI] Stage 8/10 - Agent 1 avg episode reward: 106.667 (std 18.659)
2025-10-23 11:54:45,961 | INFO | [MA-SPI] Stage 8/10 - dataset size: 3000 transitions
2025-10-23 11:54:46,062 | INFO | [MA-SPI] Stage 8/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.5409, A1_Q_loss:0.4858]
2025-10-23 11:54:46,151 | INFO | [MA-SPI] Stage 8/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.4898, A1_Q_loss:0.5252]
2025-10-23 11:54:46,246 | INFO | [MA-SPI] Stage 8/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.4823, A1_Q_loss:0.4348]
2025-10-23 11:54:46,332 | INFO | [MA-SPI] Stage 8/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.4734, A1_Q_loss:0.4499]
2025-10-23 11:54:46,418 | INFO | [MA-SPI] Stage 8/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.4792, A1_Q_loss:0.4445]
2025-10-23 11:54:46,457 | INFO | [MA-SPI] Stage 8/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0038, A1_Policy_loss:0.0027]
2025-10-23 11:54:46,490 | INFO | [MA-SPI] Stage 8/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0016, A1_Policy_loss:0.0011]
2025-10-23 11:54:46,527 | INFO | [MA-SPI] Stage 8/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0004]
2025-10-23 11:54:46,564 | INFO | [MA-SPI] Stage 8/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0002]
2025-10-23 11:54:46,599 | INFO | [MA-SPI] Stage 8/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 11:54:46,599 | INFO | [MA-SPI] Stage 8/10 - completed
2025-10-23 11:54:46,599 | INFO | [MA-SPI] Stage 9/10 - collecting trajectories...
2025-10-23 11:54:47,367 | INFO | [MA-SPI] Stage 9/10 - collected 6/30 episodes
2025-10-23 11:54:48,141 | INFO | [MA-SPI] Stage 9/10 - collected 12/30 episodes
2025-10-23 11:54:48,916 | INFO | [MA-SPI] Stage 9/10 - collected 18/30 episodes
2025-10-23 11:54:49,698 | INFO | [MA-SPI] Stage 9/10 - collected 24/30 episodes
2025-10-23 11:54:50,498 | INFO | [MA-SPI] Stage 9/10 - collected 30/30 episodes
2025-10-23 11:54:50,499 | INFO | [MA-SPI] Stage 9/10 - Agent 0 avg episode reward: 104.633 (std 14.945)
2025-10-23 11:54:50,500 | INFO | [MA-SPI] Stage 9/10 - Agent 1 avg episode reward: 105.900 (std 15.986)
2025-10-23 11:54:50,500 | INFO | [MA-SPI] Stage 9/10 - dataset size: 3000 transitions
2025-10-23 11:54:50,608 | INFO | [MA-SPI] Stage 9/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.4845, A1_Q_loss:0.5711]
2025-10-23 11:54:50,706 | INFO | [MA-SPI] Stage 9/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.4387, A1_Q_loss:0.5797]
2025-10-23 11:54:50,795 | INFO | [MA-SPI] Stage 9/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.4319, A1_Q_loss:0.5452]
2025-10-23 11:54:50,890 | INFO | [MA-SPI] Stage 9/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.4200, A1_Q_loss:0.5482]
2025-10-23 11:54:50,981 | INFO | [MA-SPI] Stage 9/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.4245, A1_Q_loss:0.5485]
2025-10-23 11:54:51,020 | INFO | [MA-SPI] Stage 9/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0020, A1_Policy_loss:0.0021]
2025-10-23 11:54:51,064 | INFO | [MA-SPI] Stage 9/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0008]
2025-10-23 11:54:51,103 | INFO | [MA-SPI] Stage 9/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0003]
2025-10-23 11:54:51,143 | INFO | [MA-SPI] Stage 9/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 11:54:51,179 | INFO | [MA-SPI] Stage 9/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-23 11:54:51,179 | INFO | [MA-SPI] Stage 9/10 - completed
2025-10-23 11:54:51,179 | INFO | [MA-SPI] Stage 10/10 - collecting trajectories...
2025-10-23 11:54:51,958 | INFO | [MA-SPI] Stage 10/10 - collected 6/30 episodes
2025-10-23 11:54:52,711 | INFO | [MA-SPI] Stage 10/10 - collected 12/30 episodes
2025-10-23 11:54:53,504 | INFO | [MA-SPI] Stage 10/10 - collected 18/30 episodes
2025-10-23 11:54:54,338 | INFO | [MA-SPI] Stage 10/10 - collected 24/30 episodes
2025-10-23 11:54:55,153 | INFO | [MA-SPI] Stage 10/10 - collected 30/30 episodes
2025-10-23 11:54:55,155 | INFO | [MA-SPI] Stage 10/10 - Agent 0 avg episode reward: 108.300 (std 26.073)
2025-10-23 11:54:55,155 | INFO | [MA-SPI] Stage 10/10 - Agent 1 avg episode reward: 105.533 (std 21.227)
2025-10-23 11:54:55,155 | INFO | [MA-SPI] Stage 10/10 - dataset size: 3000 transitions
2025-10-23 11:54:55,255 | INFO | [MA-SPI] Stage 10/10 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.6051, A1_Q_loss:0.5454]
2025-10-23 11:54:55,346 | INFO | [MA-SPI] Stage 10/10 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.5638, A1_Q_loss:0.5024]
2025-10-23 11:54:55,439 | INFO | [MA-SPI] Stage 10/10 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.5689, A1_Q_loss:0.5252]
2025-10-23 11:54:55,521 | INFO | [MA-SPI] Stage 10/10 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.5585, A1_Q_loss:0.4994]
2025-10-23 11:54:55,608 | INFO | [MA-SPI] Stage 10/10 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.5703, A1_Q_loss:0.5175]
2025-10-23 11:54:55,645 | INFO | [MA-SPI] Stage 10/10 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0022, A1_Policy_loss:0.0026]
2025-10-23 11:54:55,680 | INFO | [MA-SPI] Stage 10/10 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0009, A1_Policy_loss:0.0009]
2025-10-23 11:54:55,717 | INFO | [MA-SPI] Stage 10/10 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0003]
2025-10-23 11:54:55,752 | INFO | [MA-SPI] Stage 10/10 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 11:54:55,785 | INFO | [MA-SPI] Stage 10/10 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 11:54:55,786 | INFO | [MA-SPI] Stage 10/10 - completed
2025-10-23 11:54:55,960 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 11:54:55,960 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 11:54:55,960 | INFO | [MA-LfL] Estimating policies...
2025-10-23 11:54:55,960 | INFO | [MA-LfL][Policy] Stage 1/10 - preparing data
2025-10-23 11:54:56,012 | INFO | [MA-LfL][Policy] Stage 1/10 - Agent 0: 10/10 epochs completed (loss=1.1227, baseline=1.6094)
2025-10-23 11:54:56,034 | INFO | [MA-LfL][Policy] Stage 1/10 - Agent 1: 10/10 epochs completed (loss=1.1188, baseline=1.6094)
2025-10-23 11:54:56,035 | INFO | [MA-LfL][Policy] Stage 2/10 - preparing data
2025-10-23 11:54:56,060 | INFO | [MA-LfL][Policy] Stage 2/10 - Agent 0: 10/10 epochs completed (loss=1.0337, baseline=1.6094)
2025-10-23 11:54:56,079 | INFO | [MA-LfL][Policy] Stage 2/10 - Agent 1: 10/10 epochs completed (loss=1.0383, baseline=1.6094)
2025-10-23 11:54:56,080 | INFO | [MA-LfL][Policy] Stage 3/10 - preparing data
2025-10-23 11:54:56,105 | INFO | [MA-LfL][Policy] Stage 3/10 - Agent 0: 10/10 epochs completed (loss=1.0249, baseline=1.6094)
2025-10-23 11:54:56,136 | INFO | [MA-LfL][Policy] Stage 3/10 - Agent 1: 10/10 epochs completed (loss=1.0304, baseline=1.6094)
2025-10-23 11:54:56,137 | INFO | [MA-LfL][Policy] Stage 4/10 - preparing data
2025-10-23 11:54:56,167 | INFO | [MA-LfL][Policy] Stage 4/10 - Agent 0: 10/10 epochs completed (loss=1.0741, baseline=1.6094)
2025-10-23 11:54:56,200 | INFO | [MA-LfL][Policy] Stage 4/10 - Agent 1: 10/10 epochs completed (loss=1.0651, baseline=1.6094)
2025-10-23 11:54:56,201 | INFO | [MA-LfL][Policy] Stage 5/10 - preparing data
2025-10-23 11:54:56,232 | INFO | [MA-LfL][Policy] Stage 5/10 - Agent 0: 10/10 epochs completed (loss=1.0274, baseline=1.6094)
2025-10-23 11:54:56,259 | INFO | [MA-LfL][Policy] Stage 5/10 - Agent 1: 10/10 epochs completed (loss=1.0784, baseline=1.6094)
2025-10-23 11:54:56,260 | INFO | [MA-LfL][Policy] Stage 6/10 - preparing data
2025-10-23 11:54:56,284 | INFO | [MA-LfL][Policy] Stage 6/10 - Agent 0: 10/10 epochs completed (loss=1.0710, baseline=1.6094)
2025-10-23 11:54:56,307 | INFO | [MA-LfL][Policy] Stage 6/10 - Agent 1: 10/10 epochs completed (loss=1.0562, baseline=1.6094)
2025-10-23 11:54:56,307 | INFO | [MA-LfL][Policy] Stage 7/10 - preparing data
2025-10-23 11:54:56,331 | INFO | [MA-LfL][Policy] Stage 7/10 - Agent 0: 10/10 epochs completed (loss=1.0438, baseline=1.6094)
2025-10-23 11:54:56,355 | INFO | [MA-LfL][Policy] Stage 7/10 - Agent 1: 10/10 epochs completed (loss=1.0988, baseline=1.6094)
2025-10-23 11:54:56,355 | INFO | [MA-LfL][Policy] Stage 8/10 - preparing data
2025-10-23 11:54:56,378 | INFO | [MA-LfL][Policy] Stage 8/10 - Agent 0: 10/10 epochs completed (loss=1.0423, baseline=1.6094)
2025-10-23 11:54:56,403 | INFO | [MA-LfL][Policy] Stage 8/10 - Agent 1: 10/10 epochs completed (loss=1.0553, baseline=1.6094)
2025-10-23 11:54:56,405 | INFO | [MA-LfL][Policy] Stage 9/10 - preparing data
2025-10-23 11:54:56,441 | INFO | [MA-LfL][Policy] Stage 9/10 - Agent 0: 10/10 epochs completed (loss=1.0725, baseline=1.6094)
2025-10-23 11:54:56,467 | INFO | [MA-LfL][Policy] Stage 9/10 - Agent 1: 10/10 epochs completed (loss=1.0512, baseline=1.6094)
2025-10-23 11:54:56,468 | INFO | [MA-LfL][Policy] Stage 10/10 - preparing data
2025-10-23 11:54:56,492 | INFO | [MA-LfL][Policy] Stage 10/10 - Agent 0: 10/10 epochs completed (loss=1.0871, baseline=1.6094)
2025-10-23 11:54:56,522 | INFO | [MA-LfL][Policy] Stage 10/10 - Agent 1: 10/10 epochs completed (loss=1.0441, baseline=1.6094)
2025-10-23 11:54:56,523 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 11:54:56,523 | INFO | [MA-LfL][Targets] Stage 1/9 - Agent 0
2025-10-23 11:54:56,861 | INFO | [MA-LfL][Targets] Stage 1/9 - Agent 1
2025-10-23 11:54:57,181 | INFO | [MA-LfL][Targets] Stage 2/9 - Agent 0
2025-10-23 11:54:57,493 | INFO | [MA-LfL][Targets] Stage 2/9 - Agent 1
2025-10-23 11:54:57,841 | INFO | [MA-LfL][Targets] Stage 3/9 - Agent 0
2025-10-23 11:54:58,237 | INFO | [MA-LfL][Targets] Stage 3/9 - Agent 1
2025-10-23 11:54:58,602 | INFO | [MA-LfL][Targets] Stage 4/9 - Agent 0
2025-10-23 11:54:58,967 | INFO | [MA-LfL][Targets] Stage 4/9 - Agent 1
2025-10-23 11:54:59,336 | INFO | [MA-LfL][Targets] Stage 5/9 - Agent 0
2025-10-23 11:54:59,723 | INFO | [MA-LfL][Targets] Stage 5/9 - Agent 1
2025-10-23 11:55:00,099 | INFO | [MA-LfL][Targets] Stage 6/9 - Agent 0
2025-10-23 11:55:00,478 | INFO | [MA-LfL][Targets] Stage 6/9 - Agent 1
2025-10-23 11:55:00,865 | INFO | [MA-LfL][Targets] Stage 7/9 - Agent 0
2025-10-23 11:55:01,251 | INFO | [MA-LfL][Targets] Stage 7/9 - Agent 1
2025-10-23 11:55:01,642 | INFO | [MA-LfL][Targets] Stage 8/9 - Agent 0
2025-10-23 11:55:02,022 | INFO | [MA-LfL][Targets] Stage 8/9 - Agent 1
2025-10-23 11:55:02,426 | INFO | [MA-LfL][Targets] Stage 9/9 - Agent 0
2025-10-23 11:55:02,855 | INFO | [MA-LfL][Targets] Stage 9/9 - Agent 1
2025-10-23 11:55:03,256 | INFO | [MA-LfL] Learning rewards...
2025-10-23 11:55:03,278 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=27000 (batch=8192, epochs=2000)
2025-10-23 11:55:20,785 | INFO | [MA-LfL][Reward] Agent 0 - 200/2000 epochs completed (latest loss=0.6835)
2025-10-23 11:55:37,648 | INFO | [MA-LfL][Reward] Agent 0 - 400/2000 epochs completed (latest loss=0.6701)
2025-10-23 11:55:56,245 | INFO | [MA-LfL][Reward] Agent 0 - 600/2000 epochs completed (latest loss=0.6693)
2025-10-23 11:56:14,484 | INFO | [MA-LfL][Reward] Agent 0 - 800/2000 epochs completed (latest loss=0.6595)
2025-10-23 11:56:33,199 | INFO | [MA-LfL][Reward] Agent 0 - 1000/2000 epochs completed (latest loss=0.6620)
2025-10-23 11:56:51,348 | INFO | [MA-LfL][Reward] Agent 0 - 1200/2000 epochs completed (latest loss=0.6729)
2025-10-23 11:57:10,095 | INFO | [MA-LfL][Reward] Agent 0 - 1400/2000 epochs completed (latest loss=0.6639)
2025-10-23 11:57:28,656 | INFO | [MA-LfL][Reward] Agent 0 - 1600/2000 epochs completed (latest loss=0.6634)
2025-10-23 11:57:47,111 | INFO | [MA-LfL][Reward] Agent 0 - 1800/2000 epochs completed (latest loss=0.6703)
2025-10-23 11:58:05,094 | INFO | [MA-LfL][Reward] Agent 0 - 2000/2000 epochs completed (latest loss=0.6695)
2025-10-23 11:58:05,113 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=27000 (batch=8192, epochs=2000)
2025-10-23 11:58:23,688 | INFO | [MA-LfL][Reward] Agent 1 - 200/2000 epochs completed (latest loss=0.8107)
2025-10-23 11:58:42,372 | INFO | [MA-LfL][Reward] Agent 1 - 400/2000 epochs completed (latest loss=0.8096)
2025-10-23 11:59:00,333 | INFO | [MA-LfL][Reward] Agent 1 - 600/2000 epochs completed (latest loss=0.7964)
2025-10-23 11:59:27,963 | INFO | [MA-LfL][Reward] Agent 1 - 800/2000 epochs completed (latest loss=0.7764)
2025-10-23 11:59:46,489 | INFO | [MA-LfL][Reward] Agent 1 - 1000/2000 epochs completed (latest loss=0.7744)
2025-10-23 12:00:05,918 | INFO | [MA-LfL][Reward] Agent 1 - 1200/2000 epochs completed (latest loss=0.7862)
2025-10-23 12:00:35,162 | INFO | [MA-LfL][Reward] Agent 1 - 1400/2000 epochs completed (latest loss=0.7761)
2025-10-23 12:00:56,733 | INFO | [MA-LfL][Reward] Agent 1 - 1600/2000 epochs completed (latest loss=0.7859)
2025-10-23 12:01:14,507 | INFO | [MA-LfL][Reward] Agent 1 - 1800/2000 epochs completed (latest loss=0.7767)
2025-10-23 12:01:31,694 | INFO | [MA-LfL][Reward] Agent 1 - 2000/2000 epochs completed (latest loss=0.7895)
2025-10-23 12:01:31,694 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 12:01:32,579 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 12:01:32,579 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 12:01:32,579 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: 0.0989 | Spearman: 0.1209
2025-10-23 12:01:32,579 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: 0.0858 | Spearman: 0.1192
2025-10-23 12:01:32,579 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2, 3, 4, 5, 6, 7, 8, 9
2025-10-23 12:01:32,579 | INFO | [Experiment:heterogeneous] Trend Pearson: 0.3006, 0.2823, 0.2156, 0.1397, 0.2661, 0.1819, 0.1778, 0.2402, 0.2071
2025-10-23 12:01:32,579 | INFO | [Experiment:heterogeneous] Trend Spearman: 0.2021, 0.2499, 0.2505, 0.1867, 0.2342, 0.1802, 0.2074, 0.2087, 0.1593
2025-10-23 12:01:32,580 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 12:01:32,580 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 12:01:32,580 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 12:01:32,582 | INFO | Summary saved to outputs\summary.json
2025-10-23 12:01:32,582 | INFO | Run complete.
