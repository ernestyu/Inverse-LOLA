2025-10-24 13:23:19,533 | INFO | Logging initialized. Log file: outputs\logs\run_20251024_132319.log
2025-10-24 13:23:19,533 | INFO | Configuration file: config.yaml
2025-10-24 13:23:19,533 | INFO | Reward families to process: heterogeneous
2025-10-24 13:23:19,533 | INFO | MA-SPI iterations=3, episodes/stage=10, episode_length=100
2025-10-24 13:23:19,534 | INFO | MA-LfL reward epochs=2000, reward batch size=8192
2025-10-24 13:23:19,534 | INFO | Log file located at outputs\logs\run_20251024_132319.log
2025-10-24 13:23:19,534 | INFO | Running experiment for reward family: heterogeneous
2025-10-24 13:23:19,534 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-24 13:23:20,338 | INFO | [MA-SPI] Starting run with 3 stages, 10 episodes/stage, episode length 100
2025-10-24 13:23:20,350 | INFO | [MA-SPI] Stage 1/3 - collecting trajectories...
2025-10-24 13:23:20,792 | INFO | [MA-SPI] Stage 1/3 - collected 2/10 episodes
2025-10-24 13:23:21,057 | INFO | [MA-SPI] Stage 1/3 - collected 4/10 episodes
2025-10-24 13:23:21,314 | INFO | [MA-SPI] Stage 1/3 - collected 6/10 episodes
2025-10-24 13:23:21,571 | INFO | [MA-SPI] Stage 1/3 - collected 8/10 episodes
2025-10-24 13:23:21,835 | INFO | [MA-SPI] Stage 1/3 - collected 10/10 episodes
2025-10-24 13:23:21,836 | INFO | [MA-SPI] Stage 1/3 - Agent 0 avg episode reward: -137.400 (std 33.539)
2025-10-24 13:23:21,836 | INFO | [MA-SPI] Stage 1/3 - Agent 1 avg episode reward: -114.900 (std 35.184)
2025-10-24 13:23:21,836 | INFO | [MA-SPI] Stage 1/3 - dataset size: 1000 transitions
2025-10-24 13:23:22,061 | INFO | [MA-SPI] Stage 1/3 - Q updates 20/100 (current batch 1000) [A0_Q_loss:2.7630, A1_Q_loss:3.1812]
2025-10-24 13:23:22,144 | INFO | [MA-SPI] Stage 1/3 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.3751, A1_Q_loss:1.4296]
2025-10-24 13:23:22,223 | INFO | [MA-SPI] Stage 1/3 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.8376, A1_Q_loss:1.0367]
2025-10-24 13:23:22,303 | INFO | [MA-SPI] Stage 1/3 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.5093, A1_Q_loss:0.7529]
2025-10-24 13:23:22,385 | INFO | [MA-SPI] Stage 1/3 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4704, A1_Q_loss:0.5672]
2025-10-24 13:23:22,421 | INFO | [MA-SPI] Stage 1/3 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0288, A1_Policy_loss:0.0183]
2025-10-24 13:23:22,452 | INFO | [MA-SPI] Stage 1/3 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0090, A1_Policy_loss:0.0042]
2025-10-24 13:23:22,486 | INFO | [MA-SPI] Stage 1/3 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0015]
2025-10-24 13:23:22,519 | INFO | [MA-SPI] Stage 1/3 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0013, A1_Policy_loss:0.0006]
2025-10-24 13:23:22,554 | INFO | [MA-SPI] Stage 1/3 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0002]
2025-10-24 13:23:22,555 | INFO | [MA-SPI] Stage 1/3 - completed
2025-10-24 13:23:22,555 | INFO | [MA-SPI] Stage 2/3 - collecting trajectories...
2025-10-24 13:23:22,820 | INFO | [MA-SPI] Stage 2/3 - collected 2/10 episodes
2025-10-24 13:23:23,103 | INFO | [MA-SPI] Stage 2/3 - collected 4/10 episodes
2025-10-24 13:23:23,363 | INFO | [MA-SPI] Stage 2/3 - collected 6/10 episodes
2025-10-24 13:23:23,617 | INFO | [MA-SPI] Stage 2/3 - collected 8/10 episodes
2025-10-24 13:23:23,880 | INFO | [MA-SPI] Stage 2/3 - collected 10/10 episodes
2025-10-24 13:23:23,881 | INFO | [MA-SPI] Stage 2/3 - Agent 0 avg episode reward: 67.000 (std 29.783)
2025-10-24 13:23:23,882 | INFO | [MA-SPI] Stage 2/3 - Agent 1 avg episode reward: 47.100 (std 20.535)
2025-10-24 13:23:23,882 | INFO | [MA-SPI] Stage 2/3 - dataset size: 1000 transitions
2025-10-24 13:23:23,993 | INFO | [MA-SPI] Stage 2/3 - Q updates 20/100 (current batch 1000) [A0_Q_loss:1.6607, A1_Q_loss:1.4316]
2025-10-24 13:23:24,077 | INFO | [MA-SPI] Stage 2/3 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.0833, A1_Q_loss:1.1384]
2025-10-24 13:23:24,159 | INFO | [MA-SPI] Stage 2/3 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.9357, A1_Q_loss:1.0149]
2025-10-24 13:23:24,237 | INFO | [MA-SPI] Stage 2/3 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.8746, A1_Q_loss:0.9769]
2025-10-24 13:23:24,314 | INFO | [MA-SPI] Stage 2/3 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.8530, A1_Q_loss:0.9853]
2025-10-24 13:23:24,348 | INFO | [MA-SPI] Stage 2/3 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0158, A1_Policy_loss:0.0072]
2025-10-24 13:23:24,380 | INFO | [MA-SPI] Stage 2/3 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0048, A1_Policy_loss:0.0025]
2025-10-24 13:23:24,414 | INFO | [MA-SPI] Stage 2/3 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0020, A1_Policy_loss:0.0010]
2025-10-24 13:23:24,446 | INFO | [MA-SPI] Stage 2/3 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0004]
2025-10-24 13:23:24,479 | INFO | [MA-SPI] Stage 2/3 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-24 13:23:24,479 | INFO | [MA-SPI] Stage 2/3 - completed
2025-10-24 13:23:24,479 | INFO | [MA-SPI] Stage 3/3 - collecting trajectories...
2025-10-24 13:23:24,752 | INFO | [MA-SPI] Stage 3/3 - collected 2/10 episodes
2025-10-24 13:23:25,056 | INFO | [MA-SPI] Stage 3/3 - collected 4/10 episodes
2025-10-24 13:23:25,333 | INFO | [MA-SPI] Stage 3/3 - collected 6/10 episodes
2025-10-24 13:23:25,597 | INFO | [MA-SPI] Stage 3/3 - collected 8/10 episodes
2025-10-24 13:23:25,857 | INFO | [MA-SPI] Stage 3/3 - collected 10/10 episodes
2025-10-24 13:23:25,859 | INFO | [MA-SPI] Stage 3/3 - Agent 0 avg episode reward: 113.400 (std 28.051)
2025-10-24 13:23:25,859 | INFO | [MA-SPI] Stage 3/3 - Agent 1 avg episode reward: 109.100 (std 25.137)
2025-10-24 13:23:25,859 | INFO | [MA-SPI] Stage 3/3 - dataset size: 1000 transitions
2025-10-24 13:23:25,940 | INFO | [MA-SPI] Stage 3/3 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.7991, A1_Q_loss:0.6151]
2025-10-24 13:23:26,021 | INFO | [MA-SPI] Stage 3/3 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.8251, A1_Q_loss:0.5328]
2025-10-24 13:23:26,100 | INFO | [MA-SPI] Stage 3/3 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.7463, A1_Q_loss:0.5244]
2025-10-24 13:23:26,181 | INFO | [MA-SPI] Stage 3/3 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.7612, A1_Q_loss:0.5156]
2025-10-24 13:23:26,257 | INFO | [MA-SPI] Stage 3/3 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.7643, A1_Q_loss:0.5197]
2025-10-24 13:23:26,291 | INFO | [MA-SPI] Stage 3/3 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0067, A1_Policy_loss:0.0051]
2025-10-24 13:23:26,325 | INFO | [MA-SPI] Stage 3/3 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0023, A1_Policy_loss:0.0019]
2025-10-24 13:23:26,358 | INFO | [MA-SPI] Stage 3/3 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0007]
2025-10-24 13:23:26,390 | INFO | [MA-SPI] Stage 3/3 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-24 13:23:26,424 | INFO | [MA-SPI] Stage 3/3 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-24 13:23:26,424 | INFO | [MA-SPI] Stage 3/3 - completed
2025-10-24 13:23:26,445 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-24 13:23:26,446 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-24 13:23:26,446 | INFO | [MA-LfL] Estimating policies...
2025-10-24 13:23:26,446 | INFO | [MA-LfL][Policy] Stage 1/3 - preparing data
2025-10-24 13:23:26,469 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 2/10 epochs completed (loss=3.2695, baseline=1.6094)
2025-10-24 13:23:26,473 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 4/10 epochs completed (loss=1.4244, baseline=1.6094)
2025-10-24 13:23:26,476 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 6/10 epochs completed (loss=1.2134, baseline=1.6094)
2025-10-24 13:23:26,483 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 8/10 epochs completed (loss=1.1068, baseline=1.6094)
2025-10-24 13:23:26,487 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 10/10 epochs completed (loss=1.0913, baseline=1.6094)
2025-10-24 13:23:26,492 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 2/10 epochs completed (loss=3.0694, baseline=1.6094)
2025-10-24 13:23:26,496 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 4/10 epochs completed (loss=1.4800, baseline=1.6094)
2025-10-24 13:23:26,503 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 6/10 epochs completed (loss=1.2070, baseline=1.6094)
2025-10-24 13:23:26,507 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 8/10 epochs completed (loss=1.1019, baseline=1.6094)
2025-10-24 13:23:26,511 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 10/10 epochs completed (loss=1.0798, baseline=1.6094)
2025-10-24 13:23:26,512 | INFO | [MA-LfL][Policy] Stage 2/3 - preparing data
2025-10-24 13:23:26,519 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 2/10 epochs completed (loss=3.1231, baseline=1.6094)
2025-10-24 13:23:26,525 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 4/10 epochs completed (loss=2.5654, baseline=1.6094)
2025-10-24 13:23:26,529 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 6/10 epochs completed (loss=1.2076, baseline=1.6094)
2025-10-24 13:23:26,533 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 8/10 epochs completed (loss=1.0764, baseline=1.6094)
2025-10-24 13:23:26,538 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 10/10 epochs completed (loss=0.9976, baseline=1.6094)
2025-10-24 13:23:26,542 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 2/10 epochs completed (loss=2.4523, baseline=1.6094)
2025-10-24 13:23:26,546 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 4/10 epochs completed (loss=1.2198, baseline=1.6094)
2025-10-24 13:23:26,552 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 6/10 epochs completed (loss=1.0589, baseline=1.6094)
2025-10-24 13:23:26,555 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 8/10 epochs completed (loss=1.0233, baseline=1.6094)
2025-10-24 13:23:26,559 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 10/10 epochs completed (loss=0.9760, baseline=1.6094)
2025-10-24 13:23:26,560 | INFO | [MA-LfL][Policy] Stage 3/3 - preparing data
2025-10-24 13:23:26,567 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 2/10 epochs completed (loss=2.6041, baseline=1.6094)
2025-10-24 13:23:26,572 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 4/10 epochs completed (loss=1.7274, baseline=1.6094)
2025-10-24 13:23:26,576 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 6/10 epochs completed (loss=1.1143, baseline=1.6094)
2025-10-24 13:23:26,580 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 8/10 epochs completed (loss=1.0074, baseline=1.6094)
2025-10-24 13:23:26,584 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 10/10 epochs completed (loss=0.9835, baseline=1.6094)
2025-10-24 13:23:26,589 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 2/10 epochs completed (loss=5.7030, baseline=1.6094)
2025-10-24 13:23:26,594 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 4/10 epochs completed (loss=1.6001, baseline=1.6094)
2025-10-24 13:23:26,598 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 6/10 epochs completed (loss=1.2568, baseline=1.6094)
2025-10-24 13:23:26,604 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 8/10 epochs completed (loss=1.0344, baseline=1.6094)
2025-10-24 13:23:26,609 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 10/10 epochs completed (loss=1.0029, baseline=1.6094)
2025-10-24 13:23:26,609 | INFO | [MA-LfL] Computing reward targets...
2025-10-24 13:23:26,609 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 0
2025-10-24 13:23:26,985 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 1
2025-10-24 13:23:27,359 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 0
2025-10-24 13:23:27,746 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 1
2025-10-24 13:23:28,129 | INFO | [MA-LfL] Learning rewards...
2025-10-24 13:23:28,133 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=2000 (batch=1024, epochs=2000, reward_lr=5.00e-04, shaping_lr=1.00e-05)
2025-10-24 13:23:30,414 | INFO | [MA-LfL][Reward] Agent 0 - 200/2000 epochs completed (latest loss=0.4981)
2025-10-24 13:23:32,648 | INFO | [MA-LfL][Reward] Agent 0 - 400/2000 epochs completed (latest loss=0.4609)
2025-10-24 13:23:34,875 | INFO | [MA-LfL][Reward] Agent 0 - 600/2000 epochs completed (latest loss=0.4617)
2025-10-24 13:23:37,119 | INFO | [MA-LfL][Reward] Agent 0 - 800/2000 epochs completed (latest loss=0.4613)
2025-10-24 13:23:39,596 | INFO | [MA-LfL][Reward] Agent 0 - 1000/2000 epochs completed (latest loss=0.4611)
2025-10-24 13:23:41,935 | INFO | [MA-LfL][Reward] Agent 0 - 1200/2000 epochs completed (latest loss=0.4584)
2025-10-24 13:23:44,251 | INFO | [MA-LfL][Reward] Agent 0 - 1400/2000 epochs completed (latest loss=0.4544)
2025-10-24 13:23:46,605 | INFO | [MA-LfL][Reward] Agent 0 - 1600/2000 epochs completed (latest loss=0.4591)
2025-10-24 13:23:48,990 | INFO | [MA-LfL][Reward] Agent 0 - 1800/2000 epochs completed (latest loss=0.4582)
2025-10-24 13:23:51,234 | INFO | [MA-LfL][Reward] Agent 0 - 2000/2000 epochs completed (latest loss=0.4680)
2025-10-24 13:23:51,237 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=2000 (batch=1024, epochs=2000, reward_lr=5.00e-04, shaping_lr=1.00e-05)
2025-10-24 13:23:53,435 | INFO | [MA-LfL][Reward] Agent 1 - 200/2000 epochs completed (latest loss=0.2846)
2025-10-24 13:23:55,676 | INFO | [MA-LfL][Reward] Agent 1 - 400/2000 epochs completed (latest loss=0.2514)
2025-10-24 13:23:57,864 | INFO | [MA-LfL][Reward] Agent 1 - 600/2000 epochs completed (latest loss=0.2507)
2025-10-24 13:24:00,069 | INFO | [MA-LfL][Reward] Agent 1 - 800/2000 epochs completed (latest loss=0.2511)
2025-10-24 13:24:02,283 | INFO | [MA-LfL][Reward] Agent 1 - 1000/2000 epochs completed (latest loss=0.2484)
2025-10-24 13:24:04,496 | INFO | [MA-LfL][Reward] Agent 1 - 1200/2000 epochs completed (latest loss=0.2493)
2025-10-24 13:24:06,726 | INFO | [MA-LfL][Reward] Agent 1 - 1400/2000 epochs completed (latest loss=0.2495)
2025-10-24 13:24:08,914 | INFO | [MA-LfL][Reward] Agent 1 - 1600/2000 epochs completed (latest loss=0.2509)
2025-10-24 13:24:11,123 | INFO | [MA-LfL][Reward] Agent 1 - 1800/2000 epochs completed (latest loss=0.2497)
2025-10-24 13:24:13,354 | INFO | [MA-LfL][Reward] Agent 1 - 2000/2000 epochs completed (latest loss=0.2493)
2025-10-24 13:24:13,356 | INFO | [MA-LfL] Evaluating rewards (bare + shaped)...
2025-10-24 13:24:14,703 | INFO | [MA-LfL] Computing alignment metrics (R_hat + g - gamma*g' vs Y_h)...
2025-10-24 13:24:14,730 | INFO | [MA-LfL] Pipeline complete.
2025-10-24 13:24:14,730 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-24 13:24:14,732 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: -0.2194 | Spearman: -0.2045
2025-10-24 13:24:14,732 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: -0.1228 | Spearman: -0.0759
2025-10-24 13:24:14,732 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2
2025-10-24 13:24:14,732 | INFO | [Experiment:heterogeneous] Trend Pearson: -0.4034, -0.6917
2025-10-24 13:24:14,732 | INFO | [Experiment:heterogeneous] Trend Spearman: -0.4059, -0.6826
2025-10-24 13:24:14,732 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-24 13:24:14,732 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-24 13:24:14,732 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-24 13:24:14,749 | INFO | [Experiment:heterogeneous][bare] Pearson (mean): -0.1711 | Spearman (mean): -0.1402
2025-10-24 13:24:14,749 | INFO | [Experiment:heterogeneous][bare] Agent 0 - Pearson: -0.2194 | Spearman: -0.2045
2025-10-24 13:24:14,749 | INFO | [Experiment:heterogeneous][bare] Agent 1 - Pearson: -0.1228 | Spearman: -0.0759
2025-10-24 13:24:14,749 | INFO | [Experiment:heterogeneous][bare] Trend stages: 1, 2
2025-10-24 13:24:14,749 | INFO | [Experiment:heterogeneous][bare] Trend Pearson: -0.4034, -0.6917
2025-10-24 13:24:14,750 | INFO | [Experiment:heterogeneous][bare] Trend Spearman: -0.4059, -0.6826
2025-10-24 13:24:14,750 | INFO | [Experiment:heterogeneous][shaped] Pearson (mean): -0.1768 | Spearman (mean): -0.1494
2025-10-24 13:24:14,750 | INFO | [Experiment:heterogeneous][shaped] Agent 0 - Pearson: -0.2190 | Spearman: -0.2085
2025-10-24 13:24:14,750 | INFO | [Experiment:heterogeneous][shaped] Agent 1 - Pearson: -0.1346 | Spearman: -0.0902
2025-10-24 13:24:14,750 | INFO | [Experiment:heterogeneous][shaped] Trend stages: 1, 2
2025-10-24 13:24:14,750 | INFO | [Experiment:heterogeneous][shaped] Trend Pearson: -0.4034, -0.6917
2025-10-24 13:24:14,750 | INFO | [Experiment:heterogeneous][shaped] Trend Spearman: -0.4059, -0.6826
2025-10-24 13:24:14,750 | INFO | Summary saved to outputs\summary.json
2025-10-24 13:24:14,751 | INFO | Run complete.
