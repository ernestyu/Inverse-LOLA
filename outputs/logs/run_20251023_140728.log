2025-10-23 14:07:28,530 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_140728.log
2025-10-23 14:07:28,530 | INFO | Configuration file: config.yaml
2025-10-23 14:07:28,530 | INFO | Reward families to process: heterogeneous
2025-10-23 14:07:28,530 | INFO | MA-SPI iterations=5, episodes/stage=30, episode_length=100
2025-10-23 14:07:28,530 | INFO | MA-LfL reward epochs=10000, reward batch size=8192
2025-10-23 14:07:28,531 | INFO | Log file located at outputs\logs\run_20251023_140728.log
2025-10-23 14:07:28,531 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 14:07:28,532 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 14:07:29,457 | INFO | [MA-SPI] Starting run with 5 stages, 30 episodes/stage, episode length 100
2025-10-23 14:07:29,470 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-23 14:07:30,438 | INFO | [MA-SPI] Stage 1/5 - collected 6/30 episodes
2025-10-23 14:07:31,231 | INFO | [MA-SPI] Stage 1/5 - collected 12/30 episodes
2025-10-23 14:07:32,052 | INFO | [MA-SPI] Stage 1/5 - collected 18/30 episodes
2025-10-23 14:07:32,893 | INFO | [MA-SPI] Stage 1/5 - collected 24/30 episodes
2025-10-23 14:07:33,691 | INFO | [MA-SPI] Stage 1/5 - collected 30/30 episodes
2025-10-23 14:07:33,693 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -133.567 (std 31.196)
2025-10-23 14:07:33,694 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -113.300 (std 31.693)
2025-10-23 14:07:33,694 | INFO | [MA-SPI] Stage 1/5 - dataset size: 3000 transitions
2025-10-23 14:07:33,949 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 3000) [A0_Q_loss:3.0577, A1_Q_loss:3.0181]
2025-10-23 14:07:34,041 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 3000) [A0_Q_loss:1.5579, A1_Q_loss:1.4081]
2025-10-23 14:07:34,137 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 3000) [A0_Q_loss:1.1305, A1_Q_loss:0.7885]
2025-10-23 14:07:34,253 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.7832, A1_Q_loss:0.6657]
2025-10-23 14:07:34,352 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.6631, A1_Q_loss:0.6067]
2025-10-23 14:07:34,391 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0246, A1_Policy_loss:0.0224]
2025-10-23 14:07:34,426 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0081, A1_Policy_loss:0.0053]
2025-10-23 14:07:34,461 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0029, A1_Policy_loss:0.0016]
2025-10-23 14:07:34,495 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0006]
2025-10-23 14:07:34,536 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 14:07:34,536 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-23 14:07:34,536 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-23 14:07:35,326 | INFO | [MA-SPI] Stage 2/5 - collected 6/30 episodes
2025-10-23 14:07:36,068 | INFO | [MA-SPI] Stage 2/5 - collected 12/30 episodes
2025-10-23 14:07:36,872 | INFO | [MA-SPI] Stage 2/5 - collected 18/30 episodes
2025-10-23 14:07:37,678 | INFO | [MA-SPI] Stage 2/5 - collected 24/30 episodes
2025-10-23 14:07:38,491 | INFO | [MA-SPI] Stage 2/5 - collected 30/30 episodes
2025-10-23 14:07:38,494 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: 54.900 (std 37.226)
2025-10-23 14:07:38,494 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 59.633 (std 35.896)
2025-10-23 14:07:38,495 | INFO | [MA-SPI] Stage 2/5 - dataset size: 3000 transitions
2025-10-23 14:07:38,610 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 3000) [A0_Q_loss:1.7503, A1_Q_loss:1.1955]
2025-10-23 14:07:38,700 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.8051, A1_Q_loss:1.0462]
2025-10-23 14:07:38,790 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.7919, A1_Q_loss:0.9814]
2025-10-23 14:07:38,875 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.7450, A1_Q_loss:0.9524]
2025-10-23 14:07:38,960 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.7436, A1_Q_loss:0.9499]
2025-10-23 14:07:38,998 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0128, A1_Policy_loss:0.0057]
2025-10-23 14:07:39,032 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0028]
2025-10-23 14:07:39,070 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0014, A1_Policy_loss:0.0008]
2025-10-23 14:07:39,103 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0003]
2025-10-23 14:07:39,143 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 14:07:39,143 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-23 14:07:39,143 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-23 14:07:39,926 | INFO | [MA-SPI] Stage 3/5 - collected 6/30 episodes
2025-10-23 14:07:40,696 | INFO | [MA-SPI] Stage 3/5 - collected 12/30 episodes
2025-10-23 14:07:41,463 | INFO | [MA-SPI] Stage 3/5 - collected 18/30 episodes
2025-10-23 14:07:42,254 | INFO | [MA-SPI] Stage 3/5 - collected 24/30 episodes
2025-10-23 14:07:43,044 | INFO | [MA-SPI] Stage 3/5 - collected 30/30 episodes
2025-10-23 14:07:43,047 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 110.600 (std 18.804)
2025-10-23 14:07:43,047 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 106.733 (std 20.258)
2025-10-23 14:07:43,047 | INFO | [MA-SPI] Stage 3/5 - dataset size: 3000 transitions
2025-10-23 14:07:43,162 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.6757, A1_Q_loss:0.5499]
2025-10-23 14:07:43,260 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.6097, A1_Q_loss:0.3913]
2025-10-23 14:07:43,366 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.6006, A1_Q_loss:0.3474]
2025-10-23 14:07:43,460 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.5920, A1_Q_loss:0.3565]
2025-10-23 14:07:43,551 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.6041, A1_Q_loss:0.3335]
2025-10-23 14:07:43,588 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0041, A1_Policy_loss:0.0031]
2025-10-23 14:07:43,626 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0018, A1_Policy_loss:0.0012]
2025-10-23 14:07:43,662 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0004]
2025-10-23 14:07:43,699 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0002]
2025-10-23 14:07:43,734 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 14:07:43,734 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-23 14:07:43,734 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-23 14:07:44,511 | INFO | [MA-SPI] Stage 4/5 - collected 6/30 episodes
2025-10-23 14:07:45,321 | INFO | [MA-SPI] Stage 4/5 - collected 12/30 episodes
2025-10-23 14:07:46,124 | INFO | [MA-SPI] Stage 4/5 - collected 18/30 episodes
2025-10-23 14:07:46,935 | INFO | [MA-SPI] Stage 4/5 - collected 24/30 episodes
2025-10-23 14:07:47,765 | INFO | [MA-SPI] Stage 4/5 - collected 30/30 episodes
2025-10-23 14:07:47,767 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 109.200 (std 21.564)
2025-10-23 14:07:47,767 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 106.567 (std 19.626)
2025-10-23 14:07:47,767 | INFO | [MA-SPI] Stage 4/5 - dataset size: 3000 transitions
2025-10-23 14:07:47,876 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.5164, A1_Q_loss:0.5827]
2025-10-23 14:07:47,973 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.5028, A1_Q_loss:0.5341]
2025-10-23 14:07:48,077 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.5019, A1_Q_loss:0.5360]
2025-10-23 14:07:48,171 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.4935, A1_Q_loss:0.5250]
2025-10-23 14:07:48,269 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.4896, A1_Q_loss:0.5301]
2025-10-23 14:07:48,305 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0027, A1_Policy_loss:0.0033]
2025-10-23 14:07:48,342 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0011]
2025-10-23 14:07:48,383 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0003]
2025-10-23 14:07:48,420 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 14:07:48,460 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 14:07:48,461 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-23 14:07:48,461 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-23 14:07:49,262 | INFO | [MA-SPI] Stage 5/5 - collected 6/30 episodes
2025-10-23 14:07:50,032 | INFO | [MA-SPI] Stage 5/5 - collected 12/30 episodes
2025-10-23 14:07:50,827 | INFO | [MA-SPI] Stage 5/5 - collected 18/30 episodes
2025-10-23 14:07:51,623 | INFO | [MA-SPI] Stage 5/5 - collected 24/30 episodes
2025-10-23 14:07:52,431 | INFO | [MA-SPI] Stage 5/5 - collected 30/30 episodes
2025-10-23 14:07:52,434 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 109.267 (std 17.497)
2025-10-23 14:07:52,434 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 111.200 (std 18.251)
2025-10-23 14:07:52,434 | INFO | [MA-SPI] Stage 5/5 - dataset size: 3000 transitions
2025-10-23 14:07:52,534 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 3000) [A0_Q_loss:0.4865, A1_Q_loss:0.4253]
2025-10-23 14:07:52,635 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 3000) [A0_Q_loss:0.4779, A1_Q_loss:0.4123]
2025-10-23 14:07:52,726 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 3000) [A0_Q_loss:0.4571, A1_Q_loss:0.3895]
2025-10-23 14:07:52,818 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 3000) [A0_Q_loss:0.4505, A1_Q_loss:0.3861]
2025-10-23 14:07:52,905 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 3000) [A0_Q_loss:0.4563, A1_Q_loss:0.4015]
2025-10-23 14:07:52,944 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 3000) [A0_Policy_loss:0.0026, A1_Policy_loss:0.0029]
2025-10-23 14:07:52,977 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 3000) [A0_Policy_loss:0.0011, A1_Policy_loss:0.0011]
2025-10-23 14:07:53,011 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 3000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0004]
2025-10-23 14:07:53,050 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 3000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 14:07:53,115 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 3000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 14:07:53,115 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-23 14:07:53,188 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 14:07:53,189 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 14:07:53,189 | INFO | [MA-LfL] Estimating policies...
2025-10-23 14:07:53,189 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-23 14:07:53,235 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.1227, baseline=1.6094)
2025-10-23 14:07:53,259 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.1188, baseline=1.6094)
2025-10-23 14:07:53,260 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-23 14:07:53,290 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=1.0337, baseline=1.6094)
2025-10-23 14:07:53,328 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=1.0383, baseline=1.6094)
2025-10-23 14:07:53,328 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-23 14:07:53,349 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=1.0249, baseline=1.6094)
2025-10-23 14:07:53,372 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0304, baseline=1.6094)
2025-10-23 14:07:53,373 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-23 14:07:53,398 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0741, baseline=1.6094)
2025-10-23 14:07:53,421 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0651, baseline=1.6094)
2025-10-23 14:07:53,422 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-23 14:07:53,446 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0274, baseline=1.6094)
2025-10-23 14:07:53,471 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0784, baseline=1.6094)
2025-10-23 14:07:53,472 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 14:07:53,472 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-23 14:07:53,758 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-23 14:07:54,040 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-23 14:07:54,314 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-23 14:07:54,598 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-23 14:07:54,924 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-23 14:07:55,274 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-23 14:07:55,634 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-23 14:07:55,992 | INFO | [MA-LfL] Learning rewards...
2025-10-23 14:07:56,004 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=12000 (batch=8192, epochs=10000)
2025-10-23 14:08:20,174 | INFO | [MA-LfL][Reward] Agent 0 - 1000/10000 epochs completed (latest loss=0.4982)
2025-10-23 14:08:41,461 | INFO | [MA-LfL][Reward] Agent 0 - 2000/10000 epochs completed (latest loss=0.4877)
2025-10-23 14:09:02,652 | INFO | [MA-LfL][Reward] Agent 0 - 3000/10000 epochs completed (latest loss=0.4875)
2025-10-23 14:09:24,557 | INFO | [MA-LfL][Reward] Agent 0 - 4000/10000 epochs completed (latest loss=0.4896)
2025-10-23 14:09:45,773 | INFO | [MA-LfL][Reward] Agent 0 - 5000/10000 epochs completed (latest loss=0.4868)
2025-10-23 14:10:10,872 | INFO | [MA-LfL][Reward] Agent 0 - 6000/10000 epochs completed (latest loss=0.4924)
2025-10-23 14:10:35,033 | INFO | [MA-LfL][Reward] Agent 0 - 7000/10000 epochs completed (latest loss=0.4875)
2025-10-23 14:10:57,690 | INFO | [MA-LfL][Reward] Agent 0 - 8000/10000 epochs completed (latest loss=0.4898)
2025-10-23 14:11:20,734 | INFO | [MA-LfL][Reward] Agent 0 - 9000/10000 epochs completed (latest loss=0.4929)
2025-10-23 14:11:44,907 | INFO | [MA-LfL][Reward] Agent 0 - 10000/10000 epochs completed (latest loss=0.4952)
2025-10-23 14:11:44,918 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=12000 (batch=8192, epochs=10000)
2025-10-23 14:12:10,160 | INFO | [MA-LfL][Reward] Agent 1 - 1000/10000 epochs completed (latest loss=0.5470)
2025-10-23 14:12:34,863 | INFO | [MA-LfL][Reward] Agent 1 - 2000/10000 epochs completed (latest loss=0.5388)
2025-10-23 14:12:58,337 | INFO | [MA-LfL][Reward] Agent 1 - 3000/10000 epochs completed (latest loss=0.5479)
2025-10-23 14:13:22,077 | INFO | [MA-LfL][Reward] Agent 1 - 4000/10000 epochs completed (latest loss=0.5528)
2025-10-23 14:13:44,998 | INFO | [MA-LfL][Reward] Agent 1 - 5000/10000 epochs completed (latest loss=0.5476)
2025-10-23 14:14:08,354 | INFO | [MA-LfL][Reward] Agent 1 - 6000/10000 epochs completed (latest loss=0.5352)
2025-10-23 14:14:32,511 | INFO | [MA-LfL][Reward] Agent 1 - 7000/10000 epochs completed (latest loss=0.5357)
2025-10-23 14:14:55,739 | INFO | [MA-LfL][Reward] Agent 1 - 8000/10000 epochs completed (latest loss=0.5500)
2025-10-23 14:15:19,411 | INFO | [MA-LfL][Reward] Agent 1 - 9000/10000 epochs completed (latest loss=0.5471)
2025-10-23 14:15:43,441 | INFO | [MA-LfL][Reward] Agent 1 - 10000/10000 epochs completed (latest loss=0.5404)
2025-10-23 14:15:43,442 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 14:15:44,268 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 14:15:44,268 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 14:15:44,268 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: -0.0868 | Spearman: -0.0968
2025-10-23 14:15:44,268 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: -0.0435 | Spearman: -0.0463
2025-10-23 14:15:44,268 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2, 3, 4
2025-10-23 14:15:44,268 | INFO | [Experiment:heterogeneous] Trend Pearson: -0.1568, -0.4028, -0.5521, -0.4040
2025-10-23 14:15:44,268 | INFO | [Experiment:heterogeneous] Trend Spearman: -0.1636, -0.4588, -0.5177, -0.4305
2025-10-23 14:15:44,268 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 14:15:44,268 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 14:15:44,269 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 14:15:44,270 | INFO | Summary saved to outputs\summary.json
2025-10-23 14:15:44,271 | INFO | Run complete.
