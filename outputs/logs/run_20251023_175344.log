2025-10-23 17:53:44,637 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_175344.log
2025-10-23 17:53:44,637 | INFO | Configuration file: config.yaml
2025-10-23 17:53:44,638 | INFO | Reward families to process: heterogeneous
2025-10-23 17:53:44,638 | INFO | MA-SPI iterations=5, episodes/stage=9, episode_length=100
2025-10-23 17:53:44,638 | INFO | MA-LfL reward epochs=10000, reward batch size=8192
2025-10-23 17:53:44,638 | INFO | Log file located at outputs\logs\run_20251023_175344.log
2025-10-23 17:53:44,639 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 17:53:44,639 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 17:53:45,508 | INFO | [MA-SPI] Starting run with 5 stages, 9 episodes/stage, episode length 100
2025-10-23 17:53:45,510 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-23 17:53:45,854 | INFO | [MA-SPI] Stage 1/5 - collected 1/9 episodes
2025-10-23 17:53:45,983 | INFO | [MA-SPI] Stage 1/5 - collected 2/9 episodes
2025-10-23 17:53:46,138 | INFO | [MA-SPI] Stage 1/5 - collected 3/9 episodes
2025-10-23 17:53:46,291 | INFO | [MA-SPI] Stage 1/5 - collected 4/9 episodes
2025-10-23 17:53:46,426 | INFO | [MA-SPI] Stage 1/5 - collected 5/9 episodes
2025-10-23 17:53:46,574 | INFO | [MA-SPI] Stage 1/5 - collected 6/9 episodes
2025-10-23 17:53:46,708 | INFO | [MA-SPI] Stage 1/5 - collected 7/9 episodes
2025-10-23 17:53:46,845 | INFO | [MA-SPI] Stage 1/5 - collected 8/9 episodes
2025-10-23 17:53:46,969 | INFO | [MA-SPI] Stage 1/5 - collected 9/9 episodes
2025-10-23 17:53:46,970 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -138.667 (std 35.125)
2025-10-23 17:53:46,971 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -119.000 (std 34.747)
2025-10-23 17:53:46,971 | INFO | [MA-SPI] Stage 1/5 - dataset size: 900 transitions
2025-10-23 17:53:47,233 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 900) [A0_Q_loss:2.7720, A1_Q_loss:2.9384]
2025-10-23 17:53:47,318 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 900) [A0_Q_loss:1.3539, A1_Q_loss:1.3089]
2025-10-23 17:53:47,400 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 900) [A0_Q_loss:0.9742, A1_Q_loss:0.7851]
2025-10-23 17:53:47,482 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 900) [A0_Q_loss:0.7355, A1_Q_loss:0.6558]
2025-10-23 17:53:47,566 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 900) [A0_Q_loss:0.5982, A1_Q_loss:0.5545]
2025-10-23 17:53:47,606 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 900) [A0_Policy_loss:0.0227, A1_Policy_loss:0.0175]
2025-10-23 17:53:47,645 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 900) [A0_Policy_loss:0.0059, A1_Policy_loss:0.0036]
2025-10-23 17:53:47,682 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 900) [A0_Policy_loss:0.0021, A1_Policy_loss:0.0013]
2025-10-23 17:53:47,720 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 900) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0005]
2025-10-23 17:53:47,759 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 900) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 17:53:47,759 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-23 17:53:47,759 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-23 17:53:47,918 | INFO | [MA-SPI] Stage 2/5 - collected 1/9 episodes
2025-10-23 17:53:48,042 | INFO | [MA-SPI] Stage 2/5 - collected 2/9 episodes
2025-10-23 17:53:48,165 | INFO | [MA-SPI] Stage 2/5 - collected 3/9 episodes
2025-10-23 17:53:48,288 | INFO | [MA-SPI] Stage 2/5 - collected 4/9 episodes
2025-10-23 17:53:48,427 | INFO | [MA-SPI] Stage 2/5 - collected 5/9 episodes
2025-10-23 17:53:48,557 | INFO | [MA-SPI] Stage 2/5 - collected 6/9 episodes
2025-10-23 17:53:48,711 | INFO | [MA-SPI] Stage 2/5 - collected 7/9 episodes
2025-10-23 17:53:48,903 | INFO | [MA-SPI] Stage 2/5 - collected 8/9 episodes
2025-10-23 17:53:49,042 | INFO | [MA-SPI] Stage 2/5 - collected 9/9 episodes
2025-10-23 17:53:49,043 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: -2.000 (std 27.350)
2025-10-23 17:53:49,044 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 11.222 (std 28.786)
2025-10-23 17:53:49,044 | INFO | [MA-SPI] Stage 2/5 - dataset size: 900 transitions
2025-10-23 17:53:49,131 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 900) [A0_Q_loss:2.3199, A1_Q_loss:1.6735]
2025-10-23 17:53:49,213 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 900) [A0_Q_loss:1.1393, A1_Q_loss:1.0827]
2025-10-23 17:53:49,294 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 900) [A0_Q_loss:1.1761, A1_Q_loss:0.9729]
2025-10-23 17:53:49,377 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 900) [A0_Q_loss:0.8326, A1_Q_loss:1.0660]
2025-10-23 17:53:49,458 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 900) [A0_Q_loss:0.7380, A1_Q_loss:1.1275]
2025-10-23 17:53:49,497 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 900) [A0_Policy_loss:0.0241, A1_Policy_loss:0.0123]
2025-10-23 17:53:49,532 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 900) [A0_Policy_loss:0.0083, A1_Policy_loss:0.0034]
2025-10-23 17:53:49,567 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 900) [A0_Policy_loss:0.0028, A1_Policy_loss:0.0012]
2025-10-23 17:53:49,601 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 900) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0005]
2025-10-23 17:53:49,638 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 900) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0002]
2025-10-23 17:53:49,638 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-23 17:53:49,638 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-23 17:53:49,778 | INFO | [MA-SPI] Stage 3/5 - collected 1/9 episodes
2025-10-23 17:53:49,911 | INFO | [MA-SPI] Stage 3/5 - collected 2/9 episodes
2025-10-23 17:53:50,051 | INFO | [MA-SPI] Stage 3/5 - collected 3/9 episodes
2025-10-23 17:53:50,176 | INFO | [MA-SPI] Stage 3/5 - collected 4/9 episodes
2025-10-23 17:53:50,297 | INFO | [MA-SPI] Stage 3/5 - collected 5/9 episodes
2025-10-23 17:53:50,423 | INFO | [MA-SPI] Stage 3/5 - collected 6/9 episodes
2025-10-23 17:53:50,582 | INFO | [MA-SPI] Stage 3/5 - collected 7/9 episodes
2025-10-23 17:53:50,729 | INFO | [MA-SPI] Stage 3/5 - collected 8/9 episodes
2025-10-23 17:53:50,865 | INFO | [MA-SPI] Stage 3/5 - collected 9/9 episodes
2025-10-23 17:53:50,867 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 79.889 (std 29.255)
2025-10-23 17:53:50,867 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 93.333 (std 29.687)
2025-10-23 17:53:50,867 | INFO | [MA-SPI] Stage 3/5 - dataset size: 900 transitions
2025-10-23 17:53:50,970 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 900) [A0_Q_loss:0.7450, A1_Q_loss:1.2945]
2025-10-23 17:53:51,057 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 900) [A0_Q_loss:0.4830, A1_Q_loss:0.8119]
2025-10-23 17:53:51,147 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 900) [A0_Q_loss:0.4590, A1_Q_loss:0.7021]
2025-10-23 17:53:51,237 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 900) [A0_Q_loss:0.4548, A1_Q_loss:0.6756]
2025-10-23 17:53:51,329 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 900) [A0_Q_loss:0.4551, A1_Q_loss:0.6756]
2025-10-23 17:53:51,370 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 900) [A0_Policy_loss:0.0136, A1_Policy_loss:0.0084]
2025-10-23 17:53:51,413 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 900) [A0_Policy_loss:0.0039, A1_Policy_loss:0.0027]
2025-10-23 17:53:51,454 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 900) [A0_Policy_loss:0.0013, A1_Policy_loss:0.0011]
2025-10-23 17:53:51,492 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 900) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0005]
2025-10-23 17:53:51,533 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 900) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 17:53:51,534 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-23 17:53:51,534 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-23 17:53:51,694 | INFO | [MA-SPI] Stage 4/5 - collected 1/9 episodes
2025-10-23 17:53:51,891 | INFO | [MA-SPI] Stage 4/5 - collected 2/9 episodes
2025-10-23 17:53:52,061 | INFO | [MA-SPI] Stage 4/5 - collected 3/9 episodes
2025-10-23 17:53:52,216 | INFO | [MA-SPI] Stage 4/5 - collected 4/9 episodes
2025-10-23 17:53:52,374 | INFO | [MA-SPI] Stage 4/5 - collected 5/9 episodes
2025-10-23 17:53:52,520 | INFO | [MA-SPI] Stage 4/5 - collected 6/9 episodes
2025-10-23 17:53:52,668 | INFO | [MA-SPI] Stage 4/5 - collected 7/9 episodes
2025-10-23 17:53:52,825 | INFO | [MA-SPI] Stage 4/5 - collected 8/9 episodes
2025-10-23 17:53:52,979 | INFO | [MA-SPI] Stage 4/5 - collected 9/9 episodes
2025-10-23 17:53:52,980 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 97.444 (std 22.950)
2025-10-23 17:53:52,981 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 101.889 (std 17.426)
2025-10-23 17:53:52,981 | INFO | [MA-SPI] Stage 4/5 - dataset size: 900 transitions
2025-10-23 17:53:53,089 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 900) [A0_Q_loss:0.4246, A1_Q_loss:0.5864]
2025-10-23 17:53:53,182 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 900) [A0_Q_loss:0.3827, A1_Q_loss:0.5533]
2025-10-23 17:53:53,284 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 900) [A0_Q_loss:0.3619, A1_Q_loss:0.5502]
2025-10-23 17:53:53,383 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 900) [A0_Q_loss:0.3581, A1_Q_loss:0.5494]
2025-10-23 17:53:53,482 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 900) [A0_Q_loss:0.3603, A1_Q_loss:0.5605]
2025-10-23 17:53:53,525 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 900) [A0_Policy_loss:0.0026, A1_Policy_loss:0.0063]
2025-10-23 17:53:53,569 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 900) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0023]
2025-10-23 17:53:53,616 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 900) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0007]
2025-10-23 17:53:53,658 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 900) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0003]
2025-10-23 17:53:53,698 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 900) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 17:53:53,698 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-23 17:53:53,698 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-23 17:53:53,844 | INFO | [MA-SPI] Stage 5/5 - collected 1/9 episodes
2025-10-23 17:53:53,987 | INFO | [MA-SPI] Stage 5/5 - collected 2/9 episodes
2025-10-23 17:53:54,132 | INFO | [MA-SPI] Stage 5/5 - collected 3/9 episodes
2025-10-23 17:53:54,282 | INFO | [MA-SPI] Stage 5/5 - collected 4/9 episodes
2025-10-23 17:53:54,436 | INFO | [MA-SPI] Stage 5/5 - collected 5/9 episodes
2025-10-23 17:53:54,632 | INFO | [MA-SPI] Stage 5/5 - collected 6/9 episodes
2025-10-23 17:53:54,782 | INFO | [MA-SPI] Stage 5/5 - collected 7/9 episodes
2025-10-23 17:53:54,926 | INFO | [MA-SPI] Stage 5/5 - collected 8/9 episodes
2025-10-23 17:53:55,085 | INFO | [MA-SPI] Stage 5/5 - collected 9/9 episodes
2025-10-23 17:53:55,086 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 109.444 (std 37.191)
2025-10-23 17:53:55,087 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 102.111 (std 36.428)
2025-10-23 17:53:55,087 | INFO | [MA-SPI] Stage 5/5 - dataset size: 900 transitions
2025-10-23 17:53:55,200 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 900) [A0_Q_loss:0.6135, A1_Q_loss:0.4793]
2025-10-23 17:53:55,312 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 900) [A0_Q_loss:0.5061, A1_Q_loss:0.4738]
2025-10-23 17:53:55,428 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 900) [A0_Q_loss:0.4733, A1_Q_loss:0.4498]
2025-10-23 17:53:55,524 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 900) [A0_Q_loss:0.4662, A1_Q_loss:0.4488]
2025-10-23 17:53:55,618 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 900) [A0_Q_loss:0.4906, A1_Q_loss:0.4420]
2025-10-23 17:53:55,663 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 900) [A0_Policy_loss:0.0033, A1_Policy_loss:0.0051]
2025-10-23 17:53:55,704 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 900) [A0_Policy_loss:0.0012, A1_Policy_loss:0.0018]
2025-10-23 17:53:55,749 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 900) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0007]
2025-10-23 17:53:55,788 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 900) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0002]
2025-10-23 17:53:55,842 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 900) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-23 17:53:55,842 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-23 17:53:55,875 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 17:53:55,875 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 17:53:55,876 | INFO | [MA-LfL] Estimating policies...
2025-10-23 17:53:55,876 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-23 17:53:55,931 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.0840, baseline=1.6094)
2025-10-23 17:53:55,970 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.0563, baseline=1.6094)
2025-10-23 17:53:55,970 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-23 17:53:56,007 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=0.9703, baseline=1.6094)
2025-10-23 17:53:56,040 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=0.9989, baseline=1.6094)
2025-10-23 17:53:56,041 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-23 17:53:56,073 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=0.9868, baseline=1.6094)
2025-10-23 17:53:56,107 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0008, baseline=1.6094)
2025-10-23 17:53:56,107 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-23 17:53:56,145 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0308, baseline=1.6094)
2025-10-23 17:53:56,175 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0214, baseline=1.6094)
2025-10-23 17:53:56,177 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-23 17:53:56,224 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0094, baseline=1.6094)
2025-10-23 17:53:56,265 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0028, baseline=1.6094)
2025-10-23 17:53:56,266 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 17:53:56,266 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-23 17:53:56,712 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-23 17:53:57,136 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-23 17:53:57,651 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-23 17:53:58,101 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-23 17:53:58,566 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-23 17:53:59,004 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-23 17:53:59,476 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-23 17:53:59,968 | INFO | [MA-LfL] Learning rewards...
2025-10-23 17:53:59,976 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=3600 (batch=3600, epochs=10000)
2025-10-23 17:54:11,342 | INFO | [MA-LfL][Reward] Agent 0 - 1000/10000 epochs completed (latest loss=0.6290)
2025-10-23 17:54:23,287 | INFO | [MA-LfL][Reward] Agent 0 - 2000/10000 epochs completed (latest loss=0.6233)
2025-10-23 17:54:34,867 | INFO | [MA-LfL][Reward] Agent 0 - 3000/10000 epochs completed (latest loss=0.6233)
2025-10-23 17:54:46,457 | INFO | [MA-LfL][Reward] Agent 0 - 4000/10000 epochs completed (latest loss=0.6233)
2025-10-23 17:54:57,993 | INFO | [MA-LfL][Reward] Agent 0 - 5000/10000 epochs completed (latest loss=0.6303)
2025-10-23 17:55:09,425 | INFO | [MA-LfL][Reward] Agent 0 - 6000/10000 epochs completed (latest loss=0.6234)
2025-10-23 17:55:21,185 | INFO | [MA-LfL][Reward] Agent 0 - 7000/10000 epochs completed (latest loss=0.6250)
2025-10-23 17:55:32,351 | INFO | [MA-LfL][Reward] Agent 0 - 8000/10000 epochs completed (latest loss=0.6234)
2025-10-23 17:55:44,449 | INFO | [MA-LfL][Reward] Agent 0 - 9000/10000 epochs completed (latest loss=0.6233)
2025-10-23 17:55:57,162 | INFO | [MA-LfL][Reward] Agent 0 - 10000/10000 epochs completed (latest loss=0.6233)
2025-10-23 17:55:57,167 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=3600 (batch=3600, epochs=10000)
2025-10-23 17:56:08,826 | INFO | [MA-LfL][Reward] Agent 1 - 1000/10000 epochs completed (latest loss=0.5796)
2025-10-23 17:56:19,895 | INFO | [MA-LfL][Reward] Agent 1 - 2000/10000 epochs completed (latest loss=0.5794)
2025-10-23 17:56:32,246 | INFO | [MA-LfL][Reward] Agent 1 - 3000/10000 epochs completed (latest loss=0.5794)
2025-10-23 17:56:44,832 | INFO | [MA-LfL][Reward] Agent 1 - 4000/10000 epochs completed (latest loss=0.5797)
2025-10-23 17:56:56,678 | INFO | [MA-LfL][Reward] Agent 1 - 5000/10000 epochs completed (latest loss=0.5794)
2025-10-23 17:57:08,301 | INFO | [MA-LfL][Reward] Agent 1 - 6000/10000 epochs completed (latest loss=0.5794)
2025-10-23 17:57:20,222 | INFO | [MA-LfL][Reward] Agent 1 - 7000/10000 epochs completed (latest loss=0.5928)
2025-10-23 17:57:32,105 | INFO | [MA-LfL][Reward] Agent 1 - 8000/10000 epochs completed (latest loss=0.5794)
2025-10-23 17:57:47,400 | INFO | [MA-LfL][Reward] Agent 1 - 9000/10000 epochs completed (latest loss=0.5799)
2025-10-23 17:58:02,062 | INFO | [MA-LfL][Reward] Agent 1 - 10000/10000 epochs completed (latest loss=0.5795)
2025-10-23 17:58:02,063 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 17:58:02,942 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 17:58:02,942 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 17:58:02,942 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: 0.0793 | Spearman: 0.0807
2025-10-23 17:58:02,942 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: 0.1304 | Spearman: 0.1465
2025-10-23 17:58:02,942 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2, 3, 4
2025-10-23 17:58:02,942 | INFO | [Experiment:heterogeneous] Trend Pearson: 0.3200, 0.6452, 0.6213, 0.6039
2025-10-23 17:58:02,943 | INFO | [Experiment:heterogeneous] Trend Spearman: 0.3214, 0.6884, 0.6404, 0.7530
2025-10-23 17:58:02,943 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 17:58:02,943 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 17:58:02,943 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 17:58:02,944 | INFO | Summary saved to outputs\summary.json
2025-10-23 17:58:02,944 | INFO | Run complete.
