2025-10-23 08:51:55,444 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_085155.log
2025-10-23 08:51:55,444 | INFO | Configuration file: config.yaml
2025-10-23 08:51:55,444 | INFO | Reward families to process: heterogeneous
2025-10-23 08:51:55,444 | INFO | MA-SPI iterations=3, episodes/stage=50, episode_length=100
2025-10-23 08:51:55,444 | INFO | MA-LfL reward epochs=1000, reward batch size=8192
2025-10-23 08:51:55,444 | INFO | Log file located at outputs\logs\run_20251023_085155.log
2025-10-23 08:51:55,445 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 08:51:55,445 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 08:51:56,238 | INFO | [MA-SPI] Starting run with 3 stages, 50 episodes/stage, episode length 100
2025-10-23 08:51:56,251 | INFO | [MA-SPI] Stage 1/3 - collecting trajectories...
2025-10-23 08:51:57,793 | INFO | [MA-SPI] Stage 1/3 - collected 10/50 episodes
2025-10-23 08:51:59,210 | INFO | [MA-SPI] Stage 1/3 - collected 20/50 episodes
2025-10-23 08:52:00,616 | INFO | [MA-SPI] Stage 1/3 - collected 30/50 episodes
2025-10-23 08:52:01,987 | INFO | [MA-SPI] Stage 1/3 - collected 40/50 episodes
2025-10-23 08:52:03,359 | INFO | [MA-SPI] Stage 1/3 - collected 50/50 episodes
2025-10-23 08:52:03,363 | INFO | [MA-SPI] Stage 1/3 - Agent 0 avg episode reward: -131.960 (std 30.728)
2025-10-23 08:52:03,363 | INFO | [MA-SPI] Stage 1/3 - Agent 1 avg episode reward: -111.860 (std 30.364)
2025-10-23 08:52:03,364 | INFO | [MA-SPI] Stage 1/3 - dataset size: 5000 transitions
2025-10-23 08:52:03,679 | INFO | [MA-SPI] Stage 1/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:2.9560, A1_Q_loss:3.1497]
2025-10-23 08:52:03,804 | INFO | [MA-SPI] Stage 1/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:1.6531, A1_Q_loss:1.6196]
2025-10-23 08:52:03,898 | INFO | [MA-SPI] Stage 1/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:1.1931, A1_Q_loss:0.8657]
2025-10-23 08:52:03,999 | INFO | [MA-SPI] Stage 1/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.8032, A1_Q_loss:0.6951]
2025-10-23 08:52:04,099 | INFO | [MA-SPI] Stage 1/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.7046, A1_Q_loss:0.6365]
2025-10-23 08:52:04,144 | INFO | [MA-SPI] Stage 1/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0265, A1_Policy_loss:0.0204]
2025-10-23 08:52:04,188 | INFO | [MA-SPI] Stage 1/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0082, A1_Policy_loss:0.0053]
2025-10-23 08:52:04,228 | INFO | [MA-SPI] Stage 1/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0026, A1_Policy_loss:0.0018]
2025-10-23 08:52:04,271 | INFO | [MA-SPI] Stage 1/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0007]
2025-10-23 08:52:04,310 | INFO | [MA-SPI] Stage 1/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 08:52:04,310 | INFO | [MA-SPI] Stage 1/3 - completed
2025-10-23 08:52:04,312 | INFO | [MA-SPI] Stage 2/3 - collecting trajectories...
2025-10-23 08:52:05,695 | INFO | [MA-SPI] Stage 2/3 - collected 10/50 episodes
2025-10-23 08:52:07,076 | INFO | [MA-SPI] Stage 2/3 - collected 20/50 episodes
2025-10-23 08:52:08,601 | INFO | [MA-SPI] Stage 2/3 - collected 30/50 episodes
2025-10-23 08:52:10,097 | INFO | [MA-SPI] Stage 2/3 - collected 40/50 episodes
2025-10-23 08:52:11,648 | INFO | [MA-SPI] Stage 2/3 - collected 50/50 episodes
2025-10-23 08:52:11,651 | INFO | [MA-SPI] Stage 2/3 - Agent 0 avg episode reward: 66.200 (std 33.308)
2025-10-23 08:52:11,652 | INFO | [MA-SPI] Stage 2/3 - Agent 1 avg episode reward: 67.920 (std 33.636)
2025-10-23 08:52:11,652 | INFO | [MA-SPI] Stage 2/3 - dataset size: 5000 transitions
2025-10-23 08:52:11,817 | INFO | [MA-SPI] Stage 2/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:1.6941, A1_Q_loss:1.2148]
2025-10-23 08:52:11,966 | INFO | [MA-SPI] Stage 2/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.9297, A1_Q_loss:0.9250]
2025-10-23 08:52:12,075 | INFO | [MA-SPI] Stage 2/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.8398, A1_Q_loss:0.8679]
2025-10-23 08:52:12,200 | INFO | [MA-SPI] Stage 2/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.8066, A1_Q_loss:0.8577]
2025-10-23 08:52:12,308 | INFO | [MA-SPI] Stage 2/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.7975, A1_Q_loss:0.8459]
2025-10-23 08:52:12,355 | INFO | [MA-SPI] Stage 2/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0074, A1_Policy_loss:0.0056]
2025-10-23 08:52:12,404 | INFO | [MA-SPI] Stage 2/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0022, A1_Policy_loss:0.0019]
2025-10-23 08:52:12,447 | INFO | [MA-SPI] Stage 2/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0009, A1_Policy_loss:0.0008]
2025-10-23 08:52:12,494 | INFO | [MA-SPI] Stage 2/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 08:52:12,536 | INFO | [MA-SPI] Stage 2/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 08:52:12,536 | INFO | [MA-SPI] Stage 2/3 - completed
2025-10-23 08:52:12,536 | INFO | [MA-SPI] Stage 3/3 - collecting trajectories...
2025-10-23 08:52:13,990 | INFO | [MA-SPI] Stage 3/3 - collected 10/50 episodes
2025-10-23 08:52:15,457 | INFO | [MA-SPI] Stage 3/3 - collected 20/50 episodes
2025-10-23 08:52:16,998 | INFO | [MA-SPI] Stage 3/3 - collected 30/50 episodes
2025-10-23 08:52:18,476 | INFO | [MA-SPI] Stage 3/3 - collected 40/50 episodes
2025-10-23 08:52:19,962 | INFO | [MA-SPI] Stage 3/3 - collected 50/50 episodes
2025-10-23 08:52:19,965 | INFO | [MA-SPI] Stage 3/3 - Agent 0 avg episode reward: 107.200 (std 21.972)
2025-10-23 08:52:19,965 | INFO | [MA-SPI] Stage 3/3 - Agent 1 avg episode reward: 109.680 (std 22.438)
2025-10-23 08:52:19,965 | INFO | [MA-SPI] Stage 3/3 - dataset size: 5000 transitions
2025-10-23 08:52:20,137 | INFO | [MA-SPI] Stage 3/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.5561, A1_Q_loss:0.4463]
2025-10-23 08:52:20,254 | INFO | [MA-SPI] Stage 3/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.4792, A1_Q_loss:0.4420]
2025-10-23 08:52:20,372 | INFO | [MA-SPI] Stage 3/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.4450, A1_Q_loss:0.4431]
2025-10-23 08:52:20,480 | INFO | [MA-SPI] Stage 3/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.4415, A1_Q_loss:0.4455]
2025-10-23 08:52:20,595 | INFO | [MA-SPI] Stage 3/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.4531, A1_Q_loss:0.4270]
2025-10-23 08:52:20,640 | INFO | [MA-SPI] Stage 3/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0031, A1_Policy_loss:0.0027]
2025-10-23 08:52:20,686 | INFO | [MA-SPI] Stage 3/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0011]
2025-10-23 08:52:20,732 | INFO | [MA-SPI] Stage 3/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0004]
2025-10-23 08:52:20,773 | INFO | [MA-SPI] Stage 3/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 08:52:20,814 | INFO | [MA-SPI] Stage 3/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 08:52:20,814 | INFO | [MA-SPI] Stage 3/3 - completed
2025-10-23 08:52:20,883 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 08:52:20,883 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 08:52:20,883 | INFO | [MA-LfL] Estimating policies...
2025-10-23 08:52:20,883 | INFO | [MA-LfL][Policy] Stage 1/3 - preparing data
2025-10-23 08:52:20,922 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 10/10 epochs completed (loss=1.1252, baseline=1.6094)
2025-10-23 08:52:20,956 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 10/10 epochs completed (loss=1.1199, baseline=1.6094)
2025-10-23 08:52:20,957 | INFO | [MA-LfL][Policy] Stage 2/3 - preparing data
2025-10-23 08:52:20,996 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 10/10 epochs completed (loss=1.0687, baseline=1.6094)
2025-10-23 08:52:21,056 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 10/10 epochs completed (loss=1.0781, baseline=1.6094)
2025-10-23 08:52:21,057 | INFO | [MA-LfL][Policy] Stage 3/3 - preparing data
2025-10-23 08:52:21,100 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 10/10 epochs completed (loss=1.0409, baseline=1.6094)
2025-10-23 08:52:21,130 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 10/10 epochs completed (loss=1.0714, baseline=1.6094)
2025-10-23 08:52:21,131 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 08:52:21,131 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 0
2025-10-23 08:52:21,455 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 1
2025-10-23 08:52:21,779 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 0
2025-10-23 08:52:22,113 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 1
2025-10-23 08:52:22,483 | INFO | [MA-LfL] Learning rewards...
2025-10-23 08:52:22,497 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=10000 (batch=8192, epochs=1000)
2025-10-23 08:52:23,997 | INFO | [MA-LfL][Reward] Agent 0 - 100/1000 epochs completed (latest loss=0.2856)
2025-10-23 08:52:25,595 | INFO | [MA-LfL][Reward] Agent 0 - 200/1000 epochs completed (latest loss=0.2646)
2025-10-23 08:52:27,030 | INFO | [MA-LfL][Reward] Agent 0 - 300/1000 epochs completed (latest loss=0.2476)
2025-10-23 08:52:28,371 | INFO | [MA-LfL][Reward] Agent 0 - 400/1000 epochs completed (latest loss=0.2618)
2025-10-23 08:52:29,729 | INFO | [MA-LfL][Reward] Agent 0 - 500/1000 epochs completed (latest loss=0.2639)
2025-10-23 08:52:31,006 | INFO | [MA-LfL][Reward] Agent 0 - 600/1000 epochs completed (latest loss=0.2582)
2025-10-23 08:52:32,334 | INFO | [MA-LfL][Reward] Agent 0 - 700/1000 epochs completed (latest loss=0.2614)
2025-10-23 08:52:33,584 | INFO | [MA-LfL][Reward] Agent 0 - 800/1000 epochs completed (latest loss=0.2607)
2025-10-23 08:52:34,862 | INFO | [MA-LfL][Reward] Agent 0 - 900/1000 epochs completed (latest loss=0.2702)
2025-10-23 08:52:36,170 | INFO | [MA-LfL][Reward] Agent 0 - 1000/1000 epochs completed (latest loss=0.2514)
2025-10-23 08:52:36,181 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=10000 (batch=8192, epochs=1000)
2025-10-23 08:52:37,539 | INFO | [MA-LfL][Reward] Agent 1 - 100/1000 epochs completed (latest loss=0.2687)
2025-10-23 08:52:38,870 | INFO | [MA-LfL][Reward] Agent 1 - 200/1000 epochs completed (latest loss=0.2435)
2025-10-23 08:52:40,233 | INFO | [MA-LfL][Reward] Agent 1 - 300/1000 epochs completed (latest loss=0.2406)
2025-10-23 08:52:41,618 | INFO | [MA-LfL][Reward] Agent 1 - 400/1000 epochs completed (latest loss=0.2434)
2025-10-23 08:52:43,018 | INFO | [MA-LfL][Reward] Agent 1 - 500/1000 epochs completed (latest loss=0.2380)
2025-10-23 08:52:44,366 | INFO | [MA-LfL][Reward] Agent 1 - 600/1000 epochs completed (latest loss=0.2362)
2025-10-23 08:52:45,630 | INFO | [MA-LfL][Reward] Agent 1 - 700/1000 epochs completed (latest loss=0.2405)
2025-10-23 08:52:46,890 | INFO | [MA-LfL][Reward] Agent 1 - 800/1000 epochs completed (latest loss=0.2274)
2025-10-23 08:52:48,179 | INFO | [MA-LfL][Reward] Agent 1 - 900/1000 epochs completed (latest loss=0.2327)
2025-10-23 08:52:49,503 | INFO | [MA-LfL][Reward] Agent 1 - 1000/1000 epochs completed (latest loss=0.2381)
2025-10-23 08:52:49,504 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 08:52:50,221 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 08:52:50,221 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 08:52:50,222 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: 0.0491 | Spearman: 0.0391
2025-10-23 08:52:50,222 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: 0.1450 | Spearman: 0.1498
2025-10-23 08:52:50,222 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2
2025-10-23 08:52:50,222 | INFO | [Experiment:heterogeneous] Trend Pearson: -0.3362, -0.3297
2025-10-23 08:52:50,222 | INFO | [Experiment:heterogeneous] Trend Spearman: -0.1983, -0.2349
2025-10-23 08:52:50,222 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 08:52:50,222 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 08:52:50,222 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 08:52:50,223 | INFO | Summary saved to outputs\summary.json
2025-10-23 08:52:50,223 | INFO | Run complete.
