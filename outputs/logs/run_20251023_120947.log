2025-10-23 12:09:47,278 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_120947.log
2025-10-23 12:09:47,278 | INFO | Configuration file: config.yaml
2025-10-23 12:09:47,278 | INFO | Reward families to process: heterogeneous
2025-10-23 12:09:47,279 | INFO | MA-SPI iterations=5, episodes/stage=100, episode_length=100
2025-10-23 12:09:47,279 | INFO | MA-LfL reward epochs=5000, reward batch size=8192
2025-10-23 12:09:47,279 | INFO | Log file located at outputs\logs\run_20251023_120947.log
2025-10-23 12:09:47,279 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 12:09:47,279 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 12:09:48,196 | INFO | [MA-SPI] Starting run with 5 stages, 100 episodes/stage, episode length 100
2025-10-23 12:09:48,207 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-23 12:09:51,148 | INFO | [MA-SPI] Stage 1/5 - collected 20/100 episodes
2025-10-23 12:09:54,073 | INFO | [MA-SPI] Stage 1/5 - collected 40/100 episodes
2025-10-23 12:09:56,857 | INFO | [MA-SPI] Stage 1/5 - collected 60/100 episodes
2025-10-23 12:09:59,796 | INFO | [MA-SPI] Stage 1/5 - collected 80/100 episodes
2025-10-23 12:10:02,762 | INFO | [MA-SPI] Stage 1/5 - collected 100/100 episodes
2025-10-23 12:10:02,769 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -130.810 (std 30.603)
2025-10-23 12:10:02,770 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -111.500 (std 29.767)
2025-10-23 12:10:02,770 | INFO | [MA-SPI] Stage 1/5 - dataset size: 10000 transitions
2025-10-23 12:10:03,058 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:2.9532, A1_Q_loss:3.0349]
2025-10-23 12:10:03,165 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:1.5996, A1_Q_loss:1.5540]
2025-10-23 12:10:03,281 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:1.1587, A1_Q_loss:0.9111]
2025-10-23 12:10:03,386 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.8103, A1_Q_loss:0.7258]
2025-10-23 12:10:03,488 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.7092, A1_Q_loss:0.6651]
2025-10-23 12:10:03,547 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0284, A1_Policy_loss:0.0197]
2025-10-23 12:10:03,592 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0096, A1_Policy_loss:0.0057]
2025-10-23 12:10:03,639 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0030, A1_Policy_loss:0.0019]
2025-10-23 12:10:03,685 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0008]
2025-10-23 12:10:03,734 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 12:10:03,734 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-23 12:10:03,734 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-23 12:10:06,610 | INFO | [MA-SPI] Stage 2/5 - collected 20/100 episodes
2025-10-23 12:10:09,641 | INFO | [MA-SPI] Stage 2/5 - collected 40/100 episodes
2025-10-23 12:10:12,613 | INFO | [MA-SPI] Stage 2/5 - collected 60/100 episodes
2025-10-23 12:10:15,560 | INFO | [MA-SPI] Stage 2/5 - collected 80/100 episodes
2025-10-23 12:10:18,467 | INFO | [MA-SPI] Stage 2/5 - collected 100/100 episodes
2025-10-23 12:10:18,473 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: 59.550 (std 30.611)
2025-10-23 12:10:18,474 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 58.910 (std 32.400)
2025-10-23 12:10:18,474 | INFO | [MA-SPI] Stage 2/5 - dataset size: 10000 transitions
2025-10-23 12:10:18,757 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:1.7410, A1_Q_loss:1.1429]
2025-10-23 12:10:18,860 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:1.0265, A1_Q_loss:0.9945]
2025-10-23 12:10:18,968 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:0.9206, A1_Q_loss:0.9546]
2025-10-23 12:10:19,077 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.9075, A1_Q_loss:0.9180]
2025-10-23 12:10:19,184 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.9079, A1_Q_loss:0.9297]
2025-10-23 12:10:19,227 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0096, A1_Policy_loss:0.0046]
2025-10-23 12:10:19,279 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0020]
2025-10-23 12:10:19,321 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0007]
2025-10-23 12:10:19,365 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0002]
2025-10-23 12:10:19,409 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 12:10:19,409 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-23 12:10:19,409 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-23 12:10:22,012 | INFO | [MA-SPI] Stage 3/5 - collected 20/100 episodes
2025-10-23 12:10:24,808 | INFO | [MA-SPI] Stage 3/5 - collected 40/100 episodes
2025-10-23 12:10:27,691 | INFO | [MA-SPI] Stage 3/5 - collected 60/100 episodes
2025-10-23 12:10:30,415 | INFO | [MA-SPI] Stage 3/5 - collected 80/100 episodes
2025-10-23 12:10:33,313 | INFO | [MA-SPI] Stage 3/5 - collected 100/100 episodes
2025-10-23 12:10:33,320 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 106.840 (std 18.388)
2025-10-23 12:10:33,320 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 109.720 (std 19.309)
2025-10-23 12:10:33,320 | INFO | [MA-SPI] Stage 3/5 - dataset size: 10000 transitions
2025-10-23 12:10:33,575 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:0.6031, A1_Q_loss:0.4942]
2025-10-23 12:10:33,690 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:0.4664, A1_Q_loss:0.4508]
2025-10-23 12:10:33,801 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:0.4646, A1_Q_loss:0.4492]
2025-10-23 12:10:33,910 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.4668, A1_Q_loss:0.4423]
2025-10-23 12:10:34,020 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.4600, A1_Q_loss:0.4507]
2025-10-23 12:10:34,063 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0016, A1_Policy_loss:0.0014]
2025-10-23 12:10:34,106 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0005]
2025-10-23 12:10:34,148 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 12:10:34,190 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 12:10:34,227 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 12:10:34,227 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-23 12:10:34,228 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-23 12:10:36,888 | INFO | [MA-SPI] Stage 4/5 - collected 20/100 episodes
2025-10-23 12:10:39,672 | INFO | [MA-SPI] Stage 4/5 - collected 40/100 episodes
2025-10-23 12:10:42,662 | INFO | [MA-SPI] Stage 4/5 - collected 60/100 episodes
2025-10-23 12:10:45,531 | INFO | [MA-SPI] Stage 4/5 - collected 80/100 episodes
2025-10-23 12:10:48,343 | INFO | [MA-SPI] Stage 4/5 - collected 100/100 episodes
2025-10-23 12:10:48,349 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 104.610 (std 19.486)
2025-10-23 12:10:48,350 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 104.200 (std 20.012)
2025-10-23 12:10:48,350 | INFO | [MA-SPI] Stage 4/5 - dataset size: 10000 transitions
2025-10-23 12:10:48,576 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:0.5298, A1_Q_loss:0.5414]
2025-10-23 12:10:48,684 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:0.5108, A1_Q_loss:0.5266]
2025-10-23 12:10:48,817 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:0.5072, A1_Q_loss:0.5224]
2025-10-23 12:10:48,932 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.5018, A1_Q_loss:0.5228]
2025-10-23 12:10:49,036 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.4949, A1_Q_loss:0.5241]
2025-10-23 12:10:49,074 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0012, A1_Policy_loss:0.0009]
2025-10-23 12:10:49,113 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0003]
2025-10-23 12:10:49,158 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 12:10:49,204 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:-0.0000]
2025-10-23 12:10:49,242 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0000, A1_Policy_loss:-0.0001]
2025-10-23 12:10:49,242 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-23 12:10:49,242 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-23 12:10:52,052 | INFO | [MA-SPI] Stage 5/5 - collected 20/100 episodes
2025-10-23 12:10:54,913 | INFO | [MA-SPI] Stage 5/5 - collected 40/100 episodes
2025-10-23 12:10:57,741 | INFO | [MA-SPI] Stage 5/5 - collected 60/100 episodes
2025-10-23 12:11:00,539 | INFO | [MA-SPI] Stage 5/5 - collected 80/100 episodes
2025-10-23 12:11:03,363 | INFO | [MA-SPI] Stage 5/5 - collected 100/100 episodes
2025-10-23 12:11:03,369 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 107.680 (std 20.327)
2025-10-23 12:11:03,369 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 111.910 (std 19.662)
2025-10-23 12:11:03,370 | INFO | [MA-SPI] Stage 5/5 - dataset size: 10000 transitions
2025-10-23 12:11:03,589 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:0.4856, A1_Q_loss:0.5079]
2025-10-23 12:11:03,697 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:0.4692, A1_Q_loss:0.4855]
2025-10-23 12:11:03,792 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:0.4618, A1_Q_loss:0.5048]
2025-10-23 12:11:03,899 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.4793, A1_Q_loss:0.4972]
2025-10-23 12:11:04,009 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.4722, A1_Q_loss:0.4934]
2025-10-23 12:11:04,050 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0011]
2025-10-23 12:11:04,090 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 12:11:04,128 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 12:11:04,167 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 12:11:04,205 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0000, A1_Policy_loss:-0.0000]
2025-10-23 12:11:04,205 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-23 12:11:04,404 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 12:11:04,405 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 12:11:04,405 | INFO | [MA-LfL] Estimating policies...
2025-10-23 12:11:04,405 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-23 12:11:04,473 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.1124, baseline=1.6094)
2025-10-23 12:11:04,527 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.1084, baseline=1.6094)
2025-10-23 12:11:04,527 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-23 12:11:04,585 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=1.0431, baseline=1.6094)
2025-10-23 12:11:04,636 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=1.0823, baseline=1.6094)
2025-10-23 12:11:04,637 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-23 12:11:04,698 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=1.0478, baseline=1.6094)
2025-10-23 12:11:04,755 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0606, baseline=1.6094)
2025-10-23 12:11:04,756 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-23 12:11:04,801 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0550, baseline=1.6094)
2025-10-23 12:11:04,846 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0799, baseline=1.6094)
2025-10-23 12:11:04,847 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-23 12:11:04,902 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0665, baseline=1.6094)
2025-10-23 12:11:04,955 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0193, baseline=1.6094)
2025-10-23 12:11:04,956 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 12:11:04,956 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-23 12:11:05,275 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-23 12:11:05,563 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-23 12:11:05,867 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-23 12:11:06,197 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-23 12:11:06,570 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-23 12:11:06,935 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-23 12:11:07,298 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-23 12:11:07,681 | INFO | [MA-LfL] Learning rewards...
2025-10-23 12:11:07,714 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=40000 (batch=8192, epochs=5000)
2025-10-23 12:11:39,328 | INFO | [MA-LfL][Reward] Agent 0 - 500/5000 epochs completed (latest loss=0.3847)
2025-10-23 12:12:09,406 | INFO | [MA-LfL][Reward] Agent 0 - 1000/5000 epochs completed (latest loss=0.3837)
2025-10-23 12:12:40,132 | INFO | [MA-LfL][Reward] Agent 0 - 1500/5000 epochs completed (latest loss=0.3853)
2025-10-23 12:13:10,488 | INFO | [MA-LfL][Reward] Agent 0 - 2000/5000 epochs completed (latest loss=0.3800)
2025-10-23 12:13:40,566 | INFO | [MA-LfL][Reward] Agent 0 - 2500/5000 epochs completed (latest loss=0.3807)
2025-10-23 12:14:11,808 | INFO | [MA-LfL][Reward] Agent 0 - 3000/5000 epochs completed (latest loss=0.3795)
2025-10-23 12:14:41,968 | INFO | [MA-LfL][Reward] Agent 0 - 3500/5000 epochs completed (latest loss=0.3793)
2025-10-23 12:15:13,881 | INFO | [MA-LfL][Reward] Agent 0 - 4000/5000 epochs completed (latest loss=0.3803)
2025-10-23 12:15:46,275 | INFO | [MA-LfL][Reward] Agent 0 - 4500/5000 epochs completed (latest loss=0.3799)
2025-10-23 12:16:19,121 | INFO | [MA-LfL][Reward] Agent 0 - 5000/5000 epochs completed (latest loss=0.3800)
2025-10-23 12:16:19,149 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=40000 (batch=8192, epochs=5000)
2025-10-23 12:16:50,562 | INFO | [MA-LfL][Reward] Agent 1 - 500/5000 epochs completed (latest loss=0.3806)
2025-10-23 12:17:18,492 | INFO | [MA-LfL][Reward] Agent 1 - 1000/5000 epochs completed (latest loss=0.3771)
2025-10-23 12:17:50,106 | INFO | [MA-LfL][Reward] Agent 1 - 1500/5000 epochs completed (latest loss=0.3775)
2025-10-23 12:18:20,040 | INFO | [MA-LfL][Reward] Agent 1 - 2000/5000 epochs completed (latest loss=0.3756)
2025-10-23 12:18:50,830 | INFO | [MA-LfL][Reward] Agent 1 - 2500/5000 epochs completed (latest loss=0.3754)
2025-10-23 12:19:21,243 | INFO | [MA-LfL][Reward] Agent 1 - 3000/5000 epochs completed (latest loss=0.3758)
2025-10-23 12:19:50,731 | INFO | [MA-LfL][Reward] Agent 1 - 3500/5000 epochs completed (latest loss=0.3778)
2025-10-23 12:20:20,331 | INFO | [MA-LfL][Reward] Agent 1 - 4000/5000 epochs completed (latest loss=0.3751)
2025-10-23 12:20:49,406 | INFO | [MA-LfL][Reward] Agent 1 - 4500/5000 epochs completed (latest loss=0.3755)
2025-10-23 12:21:19,035 | INFO | [MA-LfL][Reward] Agent 1 - 5000/5000 epochs completed (latest loss=0.3754)
2025-10-23 12:21:19,036 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 12:21:20,768 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 12:21:20,768 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 12:21:20,769 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: -0.0123 | Spearman: 0.0005
2025-10-23 12:21:20,769 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: -0.0629 | Spearman: -0.0585
2025-10-23 12:21:20,769 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2, 3, 4
2025-10-23 12:21:20,769 | INFO | [Experiment:heterogeneous] Trend Pearson: 0.3139, 0.3748, 0.3614, 0.3470
2025-10-23 12:21:20,769 | INFO | [Experiment:heterogeneous] Trend Spearman: 0.2042, 0.3044, 0.2782, 0.2799
2025-10-23 12:21:20,770 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 12:21:20,770 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 12:21:20,770 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 12:21:20,773 | INFO | Summary saved to outputs\summary.json
2025-10-23 12:21:20,774 | INFO | Run complete.
