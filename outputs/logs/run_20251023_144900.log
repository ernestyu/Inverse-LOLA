2025-10-23 14:49:00,433 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_144900.log
2025-10-23 14:49:00,433 | INFO | Configuration file: config.yaml
2025-10-23 14:49:00,434 | INFO | Reward families to process: heterogeneous
2025-10-23 14:49:00,434 | INFO | MA-SPI iterations=5, episodes/stage=100, episode_length=100
2025-10-23 14:49:00,434 | INFO | MA-LfL reward epochs=10000, reward batch size=8192
2025-10-23 14:49:00,434 | INFO | Log file located at outputs\logs\run_20251023_144900.log
2025-10-23 14:49:00,434 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 14:49:00,434 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 14:49:01,340 | INFO | [MA-SPI] Starting run with 5 stages, 100 episodes/stage, episode length 100
2025-10-23 14:49:01,353 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-23 14:49:04,308 | INFO | [MA-SPI] Stage 1/5 - collected 20/100 episodes
2025-10-23 14:49:06,928 | INFO | [MA-SPI] Stage 1/5 - collected 40/100 episodes
2025-10-23 14:49:09,778 | INFO | [MA-SPI] Stage 1/5 - collected 60/100 episodes
2025-10-23 14:49:12,792 | INFO | [MA-SPI] Stage 1/5 - collected 80/100 episodes
2025-10-23 14:49:15,543 | INFO | [MA-SPI] Stage 1/5 - collected 100/100 episodes
2025-10-23 14:49:15,550 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -130.810 (std 30.603)
2025-10-23 14:49:15,550 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -111.500 (std 29.767)
2025-10-23 14:49:15,550 | INFO | [MA-SPI] Stage 1/5 - dataset size: 10000 transitions
2025-10-23 14:49:15,843 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:2.9532, A1_Q_loss:3.0349]
2025-10-23 14:49:15,958 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:1.5996, A1_Q_loss:1.5540]
2025-10-23 14:49:16,062 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:1.1587, A1_Q_loss:0.9111]
2025-10-23 14:49:16,181 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.8103, A1_Q_loss:0.7258]
2025-10-23 14:49:16,290 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.7092, A1_Q_loss:0.6651]
2025-10-23 14:49:16,339 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0284, A1_Policy_loss:0.0197]
2025-10-23 14:49:16,383 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0096, A1_Policy_loss:0.0057]
2025-10-23 14:49:16,429 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0030, A1_Policy_loss:0.0019]
2025-10-23 14:49:16,477 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0008]
2025-10-23 14:49:16,522 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 14:49:16,523 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-23 14:49:16,523 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-23 14:49:19,193 | INFO | [MA-SPI] Stage 2/5 - collected 20/100 episodes
2025-10-23 14:49:22,248 | INFO | [MA-SPI] Stage 2/5 - collected 40/100 episodes
2025-10-23 14:49:25,236 | INFO | [MA-SPI] Stage 2/5 - collected 60/100 episodes
2025-10-23 14:49:28,284 | INFO | [MA-SPI] Stage 2/5 - collected 80/100 episodes
2025-10-23 14:49:31,337 | INFO | [MA-SPI] Stage 2/5 - collected 100/100 episodes
2025-10-23 14:49:31,345 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: 59.550 (std 30.611)
2025-10-23 14:49:31,345 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 58.910 (std 32.400)
2025-10-23 14:49:31,345 | INFO | [MA-SPI] Stage 2/5 - dataset size: 10000 transitions
2025-10-23 14:49:31,534 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:1.7410, A1_Q_loss:1.1429]
2025-10-23 14:49:31,669 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:1.0265, A1_Q_loss:0.9945]
2025-10-23 14:49:31,800 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:0.9206, A1_Q_loss:0.9546]
2025-10-23 14:49:31,933 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.9075, A1_Q_loss:0.9180]
2025-10-23 14:49:32,057 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.9079, A1_Q_loss:0.9297]
2025-10-23 14:49:32,103 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0096, A1_Policy_loss:0.0046]
2025-10-23 14:49:32,180 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0020]
2025-10-23 14:49:32,229 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0007]
2025-10-23 14:49:32,273 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0002]
2025-10-23 14:49:32,322 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 14:49:32,322 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-23 14:49:32,322 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-23 14:49:35,206 | INFO | [MA-SPI] Stage 3/5 - collected 20/100 episodes
2025-10-23 14:49:38,244 | INFO | [MA-SPI] Stage 3/5 - collected 40/100 episodes
2025-10-23 14:49:41,184 | INFO | [MA-SPI] Stage 3/5 - collected 60/100 episodes
2025-10-23 14:49:44,350 | INFO | [MA-SPI] Stage 3/5 - collected 80/100 episodes
2025-10-23 14:49:47,270 | INFO | [MA-SPI] Stage 3/5 - collected 100/100 episodes
2025-10-23 14:49:47,276 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 106.840 (std 18.388)
2025-10-23 14:49:47,277 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 109.720 (std 19.309)
2025-10-23 14:49:47,278 | INFO | [MA-SPI] Stage 3/5 - dataset size: 10000 transitions
2025-10-23 14:49:47,491 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:0.6031, A1_Q_loss:0.4942]
2025-10-23 14:49:47,613 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:0.4664, A1_Q_loss:0.4508]
2025-10-23 14:49:47,746 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:0.4646, A1_Q_loss:0.4492]
2025-10-23 14:49:47,885 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.4668, A1_Q_loss:0.4423]
2025-10-23 14:49:48,002 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.4600, A1_Q_loss:0.4507]
2025-10-23 14:49:48,046 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0016, A1_Policy_loss:0.0014]
2025-10-23 14:49:48,087 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0005]
2025-10-23 14:49:48,132 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 14:49:48,174 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 14:49:48,219 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 14:49:48,219 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-23 14:49:48,219 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-23 14:49:50,973 | INFO | [MA-SPI] Stage 4/5 - collected 20/100 episodes
2025-10-23 14:49:53,747 | INFO | [MA-SPI] Stage 4/5 - collected 40/100 episodes
2025-10-23 14:49:56,617 | INFO | [MA-SPI] Stage 4/5 - collected 60/100 episodes
2025-10-23 14:49:59,559 | INFO | [MA-SPI] Stage 4/5 - collected 80/100 episodes
2025-10-23 14:50:02,327 | INFO | [MA-SPI] Stage 4/5 - collected 100/100 episodes
2025-10-23 14:50:02,335 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 104.610 (std 19.486)
2025-10-23 14:50:02,335 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 104.200 (std 20.012)
2025-10-23 14:50:02,335 | INFO | [MA-SPI] Stage 4/5 - dataset size: 10000 transitions
2025-10-23 14:50:02,499 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:0.5298, A1_Q_loss:0.5414]
2025-10-23 14:50:02,631 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:0.5108, A1_Q_loss:0.5266]
2025-10-23 14:50:02,746 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:0.5072, A1_Q_loss:0.5224]
2025-10-23 14:50:02,859 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.5018, A1_Q_loss:0.5228]
2025-10-23 14:50:02,986 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.4949, A1_Q_loss:0.5241]
2025-10-23 14:50:03,025 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0012, A1_Policy_loss:0.0009]
2025-10-23 14:50:03,071 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0003]
2025-10-23 14:50:03,113 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 14:50:03,151 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:-0.0000]
2025-10-23 14:50:03,189 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0000, A1_Policy_loss:-0.0001]
2025-10-23 14:50:03,189 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-23 14:50:03,189 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-23 14:50:05,987 | INFO | [MA-SPI] Stage 5/5 - collected 20/100 episodes
2025-10-23 14:50:08,767 | INFO | [MA-SPI] Stage 5/5 - collected 40/100 episodes
2025-10-23 14:50:11,565 | INFO | [MA-SPI] Stage 5/5 - collected 60/100 episodes
2025-10-23 14:50:14,504 | INFO | [MA-SPI] Stage 5/5 - collected 80/100 episodes
2025-10-23 14:50:17,504 | INFO | [MA-SPI] Stage 5/5 - collected 100/100 episodes
2025-10-23 14:50:17,510 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 107.680 (std 20.327)
2025-10-23 14:50:17,511 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 111.910 (std 19.662)
2025-10-23 14:50:17,511 | INFO | [MA-SPI] Stage 5/5 - dataset size: 10000 transitions
2025-10-23 14:50:17,711 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 10000) [A0_Q_loss:0.4856, A1_Q_loss:0.5079]
2025-10-23 14:50:17,833 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 10000) [A0_Q_loss:0.4692, A1_Q_loss:0.4855]
2025-10-23 14:50:17,934 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 10000) [A0_Q_loss:0.4618, A1_Q_loss:0.5048]
2025-10-23 14:50:18,058 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 10000) [A0_Q_loss:0.4793, A1_Q_loss:0.4972]
2025-10-23 14:50:18,177 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 10000) [A0_Q_loss:0.4722, A1_Q_loss:0.4934]
2025-10-23 14:50:18,224 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 10000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0011]
2025-10-23 14:50:18,268 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 10000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 14:50:18,316 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 14:50:18,363 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 10000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 14:50:18,410 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 10000) [A0_Policy_loss:0.0000, A1_Policy_loss:-0.0000]
2025-10-23 14:50:18,410 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-23 14:50:18,612 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 14:50:18,612 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 14:50:18,612 | INFO | [MA-LfL] Estimating policies...
2025-10-23 14:50:18,612 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-23 14:50:18,680 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.1124, baseline=1.6094)
2025-10-23 14:50:18,726 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.1084, baseline=1.6094)
2025-10-23 14:50:18,727 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-23 14:50:18,776 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=1.0431, baseline=1.6094)
2025-10-23 14:50:18,824 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=1.0823, baseline=1.6094)
2025-10-23 14:50:18,825 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-23 14:50:18,886 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=1.0478, baseline=1.6094)
2025-10-23 14:50:18,943 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0606, baseline=1.6094)
2025-10-23 14:50:18,944 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-23 14:50:19,000 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0550, baseline=1.6094)
2025-10-23 14:50:19,061 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0799, baseline=1.6094)
2025-10-23 14:50:19,061 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-23 14:50:19,121 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0665, baseline=1.6094)
2025-10-23 14:50:19,164 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0193, baseline=1.6094)
2025-10-23 14:50:19,165 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 14:50:19,165 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-23 14:50:19,490 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-23 14:50:19,861 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-23 14:50:20,173 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-23 14:50:20,551 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-23 14:50:20,940 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-23 14:50:21,280 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-23 14:50:21,624 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-23 14:50:22,004 | INFO | [MA-LfL] Learning rewards...
2025-10-23 14:50:22,036 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=40000 (batch=8192, epochs=10000)
2025-10-23 14:51:20,270 | INFO | [MA-LfL][Reward] Agent 0 - 1000/10000 epochs completed (latest loss=0.3922)
2025-10-23 14:52:22,564 | INFO | [MA-LfL][Reward] Agent 0 - 2000/10000 epochs completed (latest loss=0.3891)
2025-10-23 14:53:29,586 | INFO | [MA-LfL][Reward] Agent 0 - 3000/10000 epochs completed (latest loss=0.3888)
2025-10-23 14:54:35,473 | INFO | [MA-LfL][Reward] Agent 0 - 4000/10000 epochs completed (latest loss=0.3892)
2025-10-23 14:55:39,481 | INFO | [MA-LfL][Reward] Agent 0 - 5000/10000 epochs completed (latest loss=0.3887)
2025-10-23 14:56:44,043 | INFO | [MA-LfL][Reward] Agent 0 - 6000/10000 epochs completed (latest loss=0.3887)
2025-10-23 14:57:47,558 | INFO | [MA-LfL][Reward] Agent 0 - 7000/10000 epochs completed (latest loss=0.3876)
2025-10-23 14:58:51,755 | INFO | [MA-LfL][Reward] Agent 0 - 8000/10000 epochs completed (latest loss=0.3881)
2025-10-23 14:59:56,681 | INFO | [MA-LfL][Reward] Agent 0 - 9000/10000 epochs completed (latest loss=0.3871)
2025-10-23 15:02:03,724 | INFO | [MA-LfL][Reward] Agent 0 - 10000/10000 epochs completed (latest loss=0.3871)
2025-10-23 15:02:03,812 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=40000 (batch=8192, epochs=10000)
2025-10-23 15:03:32,022 | INFO | [MA-LfL][Reward] Agent 1 - 1000/10000 epochs completed (latest loss=0.3891)
2025-10-23 15:04:36,686 | INFO | [MA-LfL][Reward] Agent 1 - 2000/10000 epochs completed (latest loss=0.3880)
2025-10-23 15:05:44,473 | INFO | [MA-LfL][Reward] Agent 1 - 3000/10000 epochs completed (latest loss=0.3852)
2025-10-23 15:07:49,714 | INFO | [MA-LfL][Reward] Agent 1 - 4000/10000 epochs completed (latest loss=0.3852)
2025-10-23 15:09:28,356 | INFO | [MA-LfL][Reward] Agent 1 - 5000/10000 epochs completed (latest loss=0.3853)
2025-10-23 15:10:27,942 | INFO | [MA-LfL][Reward] Agent 1 - 6000/10000 epochs completed (latest loss=0.3831)
2025-10-23 15:11:27,595 | INFO | [MA-LfL][Reward] Agent 1 - 7000/10000 epochs completed (latest loss=0.3828)
2025-10-23 15:12:29,422 | INFO | [MA-LfL][Reward] Agent 1 - 8000/10000 epochs completed (latest loss=0.3832)
2025-10-23 15:13:28,858 | INFO | [MA-LfL][Reward] Agent 1 - 9000/10000 epochs completed (latest loss=0.3824)
2025-10-23 15:14:32,834 | INFO | [MA-LfL][Reward] Agent 1 - 10000/10000 epochs completed (latest loss=0.3826)
2025-10-23 15:14:32,834 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 15:14:33,674 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 15:14:33,675 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 15:14:33,675 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: 0.0118 | Spearman: 0.0229
2025-10-23 15:14:33,676 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: -0.0168 | Spearman: -0.0170
2025-10-23 15:14:33,676 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2, 3, 4
2025-10-23 15:14:33,676 | INFO | [Experiment:heterogeneous] Trend Pearson: 0.0615, 0.2392, 0.1609, 0.1876
2025-10-23 15:14:33,676 | INFO | [Experiment:heterogeneous] Trend Spearman: 0.1166, 0.3115, 0.2120, 0.3085
2025-10-23 15:14:33,676 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 15:14:33,676 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 15:14:33,676 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 15:14:33,678 | INFO | Summary saved to outputs\summary.json
2025-10-23 15:14:33,679 | INFO | Run complete.
