2025-10-23 13:06:00,112 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_130600.log
2025-10-23 13:06:00,112 | INFO | Configuration file: config.yaml
2025-10-23 13:06:00,112 | INFO | Reward families to process: heterogeneous
2025-10-23 13:06:00,113 | INFO | MA-SPI iterations=5, episodes/stage=400, episode_length=100
2025-10-23 13:06:00,113 | INFO | MA-LfL reward epochs=10000, reward batch size=8192
2025-10-23 13:06:00,113 | INFO | Log file located at outputs\logs\run_20251023_130600.log
2025-10-23 13:06:00,113 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 13:06:00,113 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 13:06:00,965 | INFO | [MA-SPI] Starting run with 5 stages, 400 episodes/stage, episode length 100
2025-10-23 13:06:00,966 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-23 13:06:12,060 | INFO | [MA-SPI] Stage 1/5 - collected 80/400 episodes
2025-10-23 13:06:23,701 | INFO | [MA-SPI] Stage 1/5 - collected 160/400 episodes
2025-10-23 13:06:35,646 | INFO | [MA-SPI] Stage 1/5 - collected 240/400 episodes
2025-10-23 13:06:47,933 | INFO | [MA-SPI] Stage 1/5 - collected 320/400 episodes
2025-10-23 13:06:59,654 | INFO | [MA-SPI] Stage 1/5 - collected 400/400 episodes
2025-10-23 13:06:59,681 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -131.827 (std 31.787)
2025-10-23 13:06:59,681 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -109.620 (std 31.745)
2025-10-23 13:06:59,681 | INFO | [MA-SPI] Stage 1/5 - dataset size: 40000 transitions
2025-10-23 13:06:59,973 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:2.9166, A1_Q_loss:2.9914]
2025-10-23 13:07:00,116 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:1.6013, A1_Q_loss:1.7216]
2025-10-23 13:07:00,234 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:1.2944, A1_Q_loss:0.9172]
2025-10-23 13:07:00,350 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.9712, A1_Q_loss:0.7593]
2025-10-23 13:07:00,463 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:0.8938, A1_Q_loss:0.6921]
2025-10-23 13:07:00,512 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0237, A1_Policy_loss:0.0188]
2025-10-23 13:07:00,559 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0080, A1_Policy_loss:0.0063]
2025-10-23 13:07:00,605 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0024, A1_Policy_loss:0.0017]
2025-10-23 13:07:00,647 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0006]
2025-10-23 13:07:00,691 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 13:07:00,691 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-23 13:07:00,692 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-23 13:07:12,076 | INFO | [MA-SPI] Stage 2/5 - collected 80/400 episodes
2025-10-23 13:07:23,598 | INFO | [MA-SPI] Stage 2/5 - collected 160/400 episodes
2025-10-23 13:07:34,982 | INFO | [MA-SPI] Stage 2/5 - collected 240/400 episodes
2025-10-23 13:07:46,177 | INFO | [MA-SPI] Stage 2/5 - collected 320/400 episodes
2025-10-23 13:07:57,889 | INFO | [MA-SPI] Stage 2/5 - collected 400/400 episodes
2025-10-23 13:07:57,916 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: 50.453 (std 30.897)
2025-10-23 13:07:57,917 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 58.530 (std 30.257)
2025-10-23 13:07:57,918 | INFO | [MA-SPI] Stage 2/5 - dataset size: 40000 transitions
2025-10-23 13:07:58,176 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:2.0702, A1_Q_loss:1.5339]
2025-10-23 13:07:58,296 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:1.1187, A1_Q_loss:1.0984]
2025-10-23 13:07:58,423 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:1.0280, A1_Q_loss:1.0293]
2025-10-23 13:07:58,541 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.9747, A1_Q_loss:0.9879]
2025-10-23 13:07:58,668 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:1.0133, A1_Q_loss:1.0148]
2025-10-23 13:07:58,715 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0077, A1_Policy_loss:0.0040]
2025-10-23 13:07:58,762 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0025, A1_Policy_loss:0.0013]
2025-10-23 13:07:58,808 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0011, A1_Policy_loss:0.0006]
2025-10-23 13:07:58,855 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 13:07:58,903 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 13:07:58,903 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-23 13:07:58,903 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-23 13:08:10,291 | INFO | [MA-SPI] Stage 3/5 - collected 80/400 episodes
2025-10-23 13:08:21,076 | INFO | [MA-SPI] Stage 3/5 - collected 160/400 episodes
2025-10-23 13:08:31,789 | INFO | [MA-SPI] Stage 3/5 - collected 240/400 episodes
2025-10-23 13:08:42,821 | INFO | [MA-SPI] Stage 3/5 - collected 320/400 episodes
2025-10-23 13:08:53,948 | INFO | [MA-SPI] Stage 3/5 - collected 400/400 episodes
2025-10-23 13:08:53,974 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 106.078 (std 20.165)
2025-10-23 13:08:53,975 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 109.295 (std 20.279)
2025-10-23 13:08:53,975 | INFO | [MA-SPI] Stage 3/5 - dataset size: 40000 transitions
2025-10-23 13:08:54,106 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:0.5673, A1_Q_loss:0.5221]
2025-10-23 13:08:54,231 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:0.4809, A1_Q_loss:0.5056]
2025-10-23 13:08:54,340 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:0.4946, A1_Q_loss:0.4631]
2025-10-23 13:08:54,449 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.4961, A1_Q_loss:0.4732]
2025-10-23 13:08:54,559 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:0.4707, A1_Q_loss:0.4937]
2025-10-23 13:08:54,603 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0007]
2025-10-23 13:08:54,647 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 13:08:54,691 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 13:08:54,734 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 13:08:54,776 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0000]
2025-10-23 13:08:54,776 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-23 13:08:54,776 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-23 13:09:05,485 | INFO | [MA-SPI] Stage 4/5 - collected 80/400 episodes
2025-10-23 13:09:17,100 | INFO | [MA-SPI] Stage 4/5 - collected 160/400 episodes
2025-10-23 13:09:28,637 | INFO | [MA-SPI] Stage 4/5 - collected 240/400 episodes
2025-10-23 13:09:39,912 | INFO | [MA-SPI] Stage 4/5 - collected 320/400 episodes
2025-10-23 13:09:51,417 | INFO | [MA-SPI] Stage 4/5 - collected 400/400 episodes
2025-10-23 13:09:51,442 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 109.108 (std 19.885)
2025-10-23 13:09:51,443 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 108.520 (std 20.660)
2025-10-23 13:09:51,443 | INFO | [MA-SPI] Stage 4/5 - dataset size: 40000 transitions
2025-10-23 13:09:51,586 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:0.4752, A1_Q_loss:0.4915]
2025-10-23 13:09:51,716 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:0.4766, A1_Q_loss:0.4987]
2025-10-23 13:09:51,840 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:0.4660, A1_Q_loss:0.5193]
2025-10-23 13:09:51,953 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.4978, A1_Q_loss:0.5169]
2025-10-23 13:09:52,070 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:0.4611, A1_Q_loss:0.5293]
2025-10-23 13:09:52,117 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0014]
2025-10-23 13:09:52,163 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0006]
2025-10-23 13:09:52,211 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 13:09:52,257 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 13:09:52,301 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:-0.0000]
2025-10-23 13:09:52,301 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-23 13:09:52,301 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-23 13:10:03,598 | INFO | [MA-SPI] Stage 5/5 - collected 80/400 episodes
2025-10-23 13:10:15,267 | INFO | [MA-SPI] Stage 5/5 - collected 160/400 episodes
2025-10-23 13:10:26,920 | INFO | [MA-SPI] Stage 5/5 - collected 240/400 episodes
2025-10-23 13:10:39,191 | INFO | [MA-SPI] Stage 5/5 - collected 320/400 episodes
2025-10-23 13:10:51,397 | INFO | [MA-SPI] Stage 5/5 - collected 400/400 episodes
2025-10-23 13:10:51,422 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 106.222 (std 20.781)
2025-10-23 13:10:51,422 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 106.085 (std 20.891)
2025-10-23 13:10:51,422 | INFO | [MA-SPI] Stage 5/5 - dataset size: 40000 transitions
2025-10-23 13:10:51,696 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:0.5072, A1_Q_loss:0.4697]
2025-10-23 13:10:51,828 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:0.5058, A1_Q_loss:0.5172]
2025-10-23 13:10:51,944 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:0.5066, A1_Q_loss:0.5469]
2025-10-23 13:10:52,077 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.4650, A1_Q_loss:0.5000]
2025-10-23 13:10:52,189 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:0.4785, A1_Q_loss:0.5379]
2025-10-23 13:10:52,240 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0011]
2025-10-23 13:10:52,292 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0002]
2025-10-23 13:10:52,336 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-23 13:10:52,378 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:-0.0000]
2025-10-23 13:10:52,424 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:-0.0000]
2025-10-23 13:10:52,424 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-23 13:10:53,200 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 13:10:53,200 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 13:10:53,200 | INFO | [MA-LfL] Estimating policies...
2025-10-23 13:10:53,200 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-23 13:10:53,359 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.1124, baseline=1.6094)
2025-10-23 13:10:53,479 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.1056, baseline=1.6094)
2025-10-23 13:10:53,479 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-23 13:10:53,639 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=1.0708, baseline=1.6094)
2025-10-23 13:10:53,797 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=1.0578, baseline=1.6094)
2025-10-23 13:10:53,798 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-23 13:10:53,975 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=1.0430, baseline=1.6094)
2025-10-23 13:10:54,112 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0615, baseline=1.6094)
2025-10-23 13:10:54,112 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-23 13:10:54,308 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0474, baseline=1.6094)
2025-10-23 13:10:54,470 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0197, baseline=1.6094)
2025-10-23 13:10:54,470 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-23 13:10:54,601 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0064, baseline=1.6094)
2025-10-23 13:10:54,717 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0126, baseline=1.6094)
2025-10-23 13:10:54,717 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 13:10:54,717 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-23 13:10:55,083 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-23 13:10:55,438 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-23 13:10:55,869 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-23 13:10:56,267 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-23 13:10:56,672 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-23 13:10:57,050 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-23 13:10:57,426 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-23 13:10:57,833 | INFO | [MA-LfL] Learning rewards...
2025-10-23 13:10:57,922 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=160000 (batch=8192, epochs=10000)
