2025-10-23 08:16:04,226 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_081604.log
2025-10-23 08:16:04,226 | INFO | Configuration file: config.yaml
2025-10-23 08:16:04,226 | INFO | Reward families to process: homogeneous
2025-10-23 08:16:04,226 | INFO | MA-SPI iterations=3, episodes/stage=50, episode_length=100
2025-10-23 08:16:04,227 | INFO | MA-LfL reward epochs=1000, reward batch size=512
2025-10-23 08:16:04,227 | INFO | Log file located at outputs\logs\run_20251023_081604.log
2025-10-23 08:16:04,227 | INFO | Running experiment for reward family: homogeneous
2025-10-23 08:16:04,227 | INFO | [Experiment:homogeneous] Starting MA-SPI...
2025-10-23 08:16:05,078 | INFO | [MA-SPI] Starting run with 3 stages, 50 episodes/stage, episode length 100
2025-10-23 08:16:05,092 | INFO | [MA-SPI] Stage 1/3 - collecting trajectories...
2025-10-23 08:16:06,616 | INFO | [MA-SPI] Stage 1/3 - collected 10/50 episodes
2025-10-23 08:16:07,976 | INFO | [MA-SPI] Stage 1/3 - collected 20/50 episodes
2025-10-23 08:16:09,414 | INFO | [MA-SPI] Stage 1/3 - collected 30/50 episodes
2025-10-23 08:16:10,736 | INFO | [MA-SPI] Stage 1/3 - collected 40/50 episodes
2025-10-23 08:16:12,114 | INFO | [MA-SPI] Stage 1/3 - collected 50/50 episodes
2025-10-23 08:16:12,118 | INFO | [MA-SPI] Stage 1/3 - Agent 0 avg episode reward: -431.120 (std 24.046)
2025-10-23 08:16:12,118 | INFO | [MA-SPI] Stage 1/3 - Agent 1 avg episode reward: -411.020 (std 20.728)
2025-10-23 08:16:12,118 | INFO | [MA-SPI] Stage 1/3 - dataset size: 5000 transitions
2025-10-23 08:16:12,460 | INFO | [MA-SPI] Stage 1/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.8595, A1_Q_loss:0.8045]
2025-10-23 08:16:12,620 | INFO | [MA-SPI] Stage 1/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.5710, A1_Q_loss:0.6775]
2025-10-23 08:16:12,738 | INFO | [MA-SPI] Stage 1/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.5431, A1_Q_loss:0.6820]
2025-10-23 08:16:12,834 | INFO | [MA-SPI] Stage 1/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.5438, A1_Q_loss:0.6869]
2025-10-23 08:16:12,940 | INFO | [MA-SPI] Stage 1/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.5496, A1_Q_loss:0.6791]
2025-10-23 08:16:12,986 | INFO | [MA-SPI] Stage 1/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0172, A1_Policy_loss:0.0109]
2025-10-23 08:16:13,026 | INFO | [MA-SPI] Stage 1/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0054, A1_Policy_loss:0.0025]
2025-10-23 08:16:13,068 | INFO | [MA-SPI] Stage 1/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0018, A1_Policy_loss:0.0008]
2025-10-23 08:16:13,107 | INFO | [MA-SPI] Stage 1/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0003]
2025-10-23 08:16:13,148 | INFO | [MA-SPI] Stage 1/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-23 08:16:13,148 | INFO | [MA-SPI] Stage 1/3 - completed
2025-10-23 08:16:13,149 | INFO | [MA-SPI] Stage 2/3 - collecting trajectories...
2025-10-23 08:16:14,540 | INFO | [MA-SPI] Stage 2/3 - collected 10/50 episodes
2025-10-23 08:16:15,895 | INFO | [MA-SPI] Stage 2/3 - collected 20/50 episodes
2025-10-23 08:16:17,318 | INFO | [MA-SPI] Stage 2/3 - collected 30/50 episodes
2025-10-23 08:16:18,711 | INFO | [MA-SPI] Stage 2/3 - collected 40/50 episodes
2025-10-23 08:16:20,091 | INFO | [MA-SPI] Stage 2/3 - collected 50/50 episodes
2025-10-23 08:16:20,095 | INFO | [MA-SPI] Stage 2/3 - Agent 0 avg episode reward: -291.700 (std 20.339)
2025-10-23 08:16:20,095 | INFO | [MA-SPI] Stage 2/3 - Agent 1 avg episode reward: -295.360 (std 25.351)
2025-10-23 08:16:20,095 | INFO | [MA-SPI] Stage 2/3 - dataset size: 5000 transitions
2025-10-23 08:16:20,238 | INFO | [MA-SPI] Stage 2/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.8117, A1_Q_loss:0.6364]
2025-10-23 08:16:20,347 | INFO | [MA-SPI] Stage 2/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.5547, A1_Q_loss:0.5128]
2025-10-23 08:16:20,448 | INFO | [MA-SPI] Stage 2/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.5357, A1_Q_loss:0.4947]
2025-10-23 08:16:20,548 | INFO | [MA-SPI] Stage 2/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.5447, A1_Q_loss:0.4828]
2025-10-23 08:16:20,656 | INFO | [MA-SPI] Stage 2/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.5380, A1_Q_loss:0.4893]
2025-10-23 08:16:20,695 | INFO | [MA-SPI] Stage 2/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0066, A1_Policy_loss:0.0045]
2025-10-23 08:16:20,735 | INFO | [MA-SPI] Stage 2/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0018, A1_Policy_loss:0.0016]
2025-10-23 08:16:20,772 | INFO | [MA-SPI] Stage 2/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0005]
2025-10-23 08:16:20,811 | INFO | [MA-SPI] Stage 2/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 08:16:20,852 | INFO | [MA-SPI] Stage 2/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-23 08:16:20,853 | INFO | [MA-SPI] Stage 2/3 - completed
2025-10-23 08:16:20,853 | INFO | [MA-SPI] Stage 3/3 - collecting trajectories...
2025-10-23 08:16:22,147 | INFO | [MA-SPI] Stage 3/3 - collected 10/50 episodes
2025-10-23 08:16:23,465 | INFO | [MA-SPI] Stage 3/3 - collected 20/50 episodes
2025-10-23 08:16:24,767 | INFO | [MA-SPI] Stage 3/3 - collected 30/50 episodes
2025-10-23 08:16:26,142 | INFO | [MA-SPI] Stage 3/3 - collected 40/50 episodes
2025-10-23 08:16:27,521 | INFO | [MA-SPI] Stage 3/3 - collected 50/50 episodes
2025-10-23 08:16:27,525 | INFO | [MA-SPI] Stage 3/3 - Agent 0 avg episode reward: -271.440 (std 20.730)
2025-10-23 08:16:27,525 | INFO | [MA-SPI] Stage 3/3 - Agent 1 avg episode reward: -273.380 (std 19.942)
2025-10-23 08:16:27,525 | INFO | [MA-SPI] Stage 3/3 - dataset size: 5000 transitions
2025-10-23 08:16:27,676 | INFO | [MA-SPI] Stage 3/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.4339, A1_Q_loss:0.4916]
2025-10-23 08:16:27,772 | INFO | [MA-SPI] Stage 3/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.4292, A1_Q_loss:0.4625]
2025-10-23 08:16:27,865 | INFO | [MA-SPI] Stage 3/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.4230, A1_Q_loss:0.4694]
2025-10-23 08:16:27,959 | INFO | [MA-SPI] Stage 3/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.4223, A1_Q_loss:0.4646]
2025-10-23 08:16:28,055 | INFO | [MA-SPI] Stage 3/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.4217, A1_Q_loss:0.4658]
2025-10-23 08:16:28,098 | INFO | [MA-SPI] Stage 3/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0024, A1_Policy_loss:0.0028]
2025-10-23 08:16:28,140 | INFO | [MA-SPI] Stage 3/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0008]
2025-10-23 08:16:28,180 | INFO | [MA-SPI] Stage 3/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0003]
2025-10-23 08:16:28,217 | INFO | [MA-SPI] Stage 3/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-23 08:16:28,260 | INFO | [MA-SPI] Stage 3/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:-0.0001, A1_Policy_loss:0.0000]
2025-10-23 08:16:28,260 | INFO | [MA-SPI] Stage 3/3 - completed
2025-10-23 08:16:28,329 | INFO | [Experiment:homogeneous] MA-SPI completed. Artifacts saved to outputs\homogeneous\ma_spi
2025-10-23 08:16:28,329 | INFO | [Experiment:homogeneous] Starting MA-LfL...
2025-10-23 08:16:28,329 | INFO | [MA-LfL] Estimating policies...
2025-10-23 08:16:28,329 | INFO | [MA-LfL][Policy] Stage 1/3 - preparing data
2025-10-23 08:16:28,366 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 10/10 epochs completed (loss=1.1252, baseline=1.6094)
2025-10-23 08:16:28,389 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 10/10 epochs completed (loss=1.1199, baseline=1.6094)
2025-10-23 08:16:28,390 | INFO | [MA-LfL][Policy] Stage 2/3 - preparing data
2025-10-23 08:16:28,416 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 10/10 epochs completed (loss=1.0980, baseline=1.6094)
2025-10-23 08:16:28,444 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 10/10 epochs completed (loss=1.0973, baseline=1.6094)
2025-10-23 08:16:28,444 | INFO | [MA-LfL][Policy] Stage 3/3 - preparing data
2025-10-23 08:16:28,473 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 10/10 epochs completed (loss=1.0654, baseline=1.6094)
2025-10-23 08:16:28,499 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 10/10 epochs completed (loss=1.0732, baseline=1.6094)
2025-10-23 08:16:28,500 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 08:16:28,500 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 0
2025-10-23 08:16:28,799 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 1
2025-10-23 08:16:29,087 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 0
2025-10-23 08:16:29,397 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 1
2025-10-23 08:16:29,724 | INFO | [MA-LfL] Learning rewards...
2025-10-23 08:16:29,738 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=10000 (batch=512, epochs=1000)
2025-10-23 08:25:40,775 | INFO | [MA-LfL][Reward] Agent 0 - 100/1000 epochs completed (latest loss=0.1587)
