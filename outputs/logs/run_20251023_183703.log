2025-10-23 18:37:03,126 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_183703.log
2025-10-23 18:37:03,126 | INFO | Configuration file: config.yaml
2025-10-23 18:37:03,126 | INFO | Reward families to process: heterogeneous
2025-10-23 18:37:03,126 | INFO | MA-SPI iterations=3, episodes/stage=10, episode_length=100
2025-10-23 18:37:03,126 | INFO | MA-LfL reward epochs=10000, reward batch size=8192
2025-10-23 18:37:03,127 | INFO | Log file located at outputs\logs\run_20251023_183703.log
2025-10-23 18:37:03,127 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 18:37:03,127 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 18:37:03,936 | INFO | [MA-SPI] Starting run with 3 stages, 10 episodes/stage, episode length 100
2025-10-23 18:37:03,939 | INFO | [MA-SPI] Stage 1/3 - collecting trajectories...
2025-10-23 18:37:04,359 | INFO | [MA-SPI] Stage 1/3 - collected 2/10 episodes
2025-10-23 18:37:04,633 | INFO | [MA-SPI] Stage 1/3 - collected 4/10 episodes
2025-10-23 18:37:04,887 | INFO | [MA-SPI] Stage 1/3 - collected 6/10 episodes
2025-10-23 18:37:05,138 | INFO | [MA-SPI] Stage 1/3 - collected 8/10 episodes
2025-10-23 18:37:05,394 | INFO | [MA-SPI] Stage 1/3 - collected 10/10 episodes
2025-10-23 18:37:05,396 | INFO | [MA-SPI] Stage 1/3 - Agent 0 avg episode reward: -137.400 (std 33.539)
2025-10-23 18:37:05,396 | INFO | [MA-SPI] Stage 1/3 - Agent 1 avg episode reward: -114.900 (std 35.184)
2025-10-23 18:37:05,396 | INFO | [MA-SPI] Stage 1/3 - dataset size: 1000 transitions
2025-10-23 18:37:05,647 | INFO | [MA-SPI] Stage 1/3 - Q updates 20/100 (current batch 1000) [A0_Q_loss:2.7630, A1_Q_loss:3.1812]
2025-10-23 18:37:05,744 | INFO | [MA-SPI] Stage 1/3 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.3751, A1_Q_loss:1.4296]
2025-10-23 18:37:05,856 | INFO | [MA-SPI] Stage 1/3 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.8376, A1_Q_loss:1.0367]
2025-10-23 18:37:05,969 | INFO | [MA-SPI] Stage 1/3 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.5093, A1_Q_loss:0.7529]
2025-10-23 18:37:06,077 | INFO | [MA-SPI] Stage 1/3 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4704, A1_Q_loss:0.5672]
2025-10-23 18:37:06,123 | INFO | [MA-SPI] Stage 1/3 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0288, A1_Policy_loss:0.0183]
2025-10-23 18:37:06,162 | INFO | [MA-SPI] Stage 1/3 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0090, A1_Policy_loss:0.0042]
2025-10-23 18:37:06,202 | INFO | [MA-SPI] Stage 1/3 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0015]
2025-10-23 18:37:06,245 | INFO | [MA-SPI] Stage 1/3 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0013, A1_Policy_loss:0.0006]
2025-10-23 18:37:06,294 | INFO | [MA-SPI] Stage 1/3 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0002]
2025-10-23 18:37:06,294 | INFO | [MA-SPI] Stage 1/3 - completed
2025-10-23 18:37:06,294 | INFO | [MA-SPI] Stage 2/3 - collecting trajectories...
2025-10-23 18:37:06,627 | INFO | [MA-SPI] Stage 2/3 - collected 2/10 episodes
2025-10-23 18:37:06,895 | INFO | [MA-SPI] Stage 2/3 - collected 4/10 episodes
2025-10-23 18:37:07,166 | INFO | [MA-SPI] Stage 2/3 - collected 6/10 episodes
2025-10-23 18:37:07,453 | INFO | [MA-SPI] Stage 2/3 - collected 8/10 episodes
2025-10-23 18:37:07,793 | INFO | [MA-SPI] Stage 2/3 - collected 10/10 episodes
2025-10-23 18:37:07,794 | INFO | [MA-SPI] Stage 2/3 - Agent 0 avg episode reward: 67.000 (std 29.783)
2025-10-23 18:37:07,794 | INFO | [MA-SPI] Stage 2/3 - Agent 1 avg episode reward: 47.100 (std 20.535)
2025-10-23 18:37:07,794 | INFO | [MA-SPI] Stage 2/3 - dataset size: 1000 transitions
2025-10-23 18:37:07,891 | INFO | [MA-SPI] Stage 2/3 - Q updates 20/100 (current batch 1000) [A0_Q_loss:1.6607, A1_Q_loss:1.4316]
2025-10-23 18:37:07,997 | INFO | [MA-SPI] Stage 2/3 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.0833, A1_Q_loss:1.1384]
2025-10-23 18:37:08,092 | INFO | [MA-SPI] Stage 2/3 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.9357, A1_Q_loss:1.0149]
2025-10-23 18:37:08,181 | INFO | [MA-SPI] Stage 2/3 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.8746, A1_Q_loss:0.9769]
2025-10-23 18:37:08,278 | INFO | [MA-SPI] Stage 2/3 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.8530, A1_Q_loss:0.9853]
2025-10-23 18:37:08,316 | INFO | [MA-SPI] Stage 2/3 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0158, A1_Policy_loss:0.0072]
2025-10-23 18:37:08,353 | INFO | [MA-SPI] Stage 2/3 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0048, A1_Policy_loss:0.0025]
2025-10-23 18:37:08,390 | INFO | [MA-SPI] Stage 2/3 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0020, A1_Policy_loss:0.0010]
2025-10-23 18:37:08,427 | INFO | [MA-SPI] Stage 2/3 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0004]
2025-10-23 18:37:08,463 | INFO | [MA-SPI] Stage 2/3 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 18:37:08,463 | INFO | [MA-SPI] Stage 2/3 - completed
2025-10-23 18:37:08,463 | INFO | [MA-SPI] Stage 3/3 - collecting trajectories...
2025-10-23 18:37:08,738 | INFO | [MA-SPI] Stage 3/3 - collected 2/10 episodes
2025-10-23 18:37:09,004 | INFO | [MA-SPI] Stage 3/3 - collected 4/10 episodes
2025-10-23 18:37:09,281 | INFO | [MA-SPI] Stage 3/3 - collected 6/10 episodes
2025-10-23 18:37:09,535 | INFO | [MA-SPI] Stage 3/3 - collected 8/10 episodes
2025-10-23 18:37:09,801 | INFO | [MA-SPI] Stage 3/3 - collected 10/10 episodes
2025-10-23 18:37:09,802 | INFO | [MA-SPI] Stage 3/3 - Agent 0 avg episode reward: 113.400 (std 28.051)
2025-10-23 18:37:09,802 | INFO | [MA-SPI] Stage 3/3 - Agent 1 avg episode reward: 109.100 (std 25.137)
2025-10-23 18:37:09,802 | INFO | [MA-SPI] Stage 3/3 - dataset size: 1000 transitions
2025-10-23 18:37:09,895 | INFO | [MA-SPI] Stage 3/3 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.7991, A1_Q_loss:0.6151]
2025-10-23 18:37:09,986 | INFO | [MA-SPI] Stage 3/3 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.8251, A1_Q_loss:0.5328]
2025-10-23 18:37:10,073 | INFO | [MA-SPI] Stage 3/3 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.7463, A1_Q_loss:0.5244]
2025-10-23 18:37:10,164 | INFO | [MA-SPI] Stage 3/3 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.7612, A1_Q_loss:0.5156]
2025-10-23 18:37:10,249 | INFO | [MA-SPI] Stage 3/3 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.7643, A1_Q_loss:0.5197]
2025-10-23 18:37:10,287 | INFO | [MA-SPI] Stage 3/3 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0067, A1_Policy_loss:0.0051]
2025-10-23 18:37:10,324 | INFO | [MA-SPI] Stage 3/3 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0023, A1_Policy_loss:0.0019]
2025-10-23 18:37:10,359 | INFO | [MA-SPI] Stage 3/3 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0007]
2025-10-23 18:37:10,395 | INFO | [MA-SPI] Stage 3/3 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 18:37:10,429 | INFO | [MA-SPI] Stage 3/3 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 18:37:10,429 | INFO | [MA-SPI] Stage 3/3 - completed
2025-10-23 18:37:10,453 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 18:37:10,453 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 18:37:10,453 | INFO | [MA-LfL] Estimating policies...
2025-10-23 18:37:10,454 | INFO | [MA-LfL][Policy] Stage 1/3 - preparing data
2025-10-23 18:37:10,497 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 10/10 epochs completed (loss=1.0913, baseline=1.6094)
2025-10-23 18:37:10,526 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 10/10 epochs completed (loss=1.0798, baseline=1.6094)
2025-10-23 18:37:10,527 | INFO | [MA-LfL][Policy] Stage 2/3 - preparing data
2025-10-23 18:37:10,563 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 10/10 epochs completed (loss=0.9976, baseline=1.6094)
2025-10-23 18:37:10,602 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 10/10 epochs completed (loss=0.9760, baseline=1.6094)
2025-10-23 18:37:10,604 | INFO | [MA-LfL][Policy] Stage 3/3 - preparing data
2025-10-23 18:37:10,647 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 10/10 epochs completed (loss=0.9835, baseline=1.6094)
2025-10-23 18:37:10,676 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 10/10 epochs completed (loss=1.0029, baseline=1.6094)
2025-10-23 18:37:10,677 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 18:37:10,677 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 0
2025-10-23 18:37:11,032 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 1
2025-10-23 18:37:11,381 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 0
2025-10-23 18:37:11,747 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 1
2025-10-23 18:37:12,133 | INFO | [MA-LfL] Learning rewards...
2025-10-23 18:37:12,138 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=2000 (batch=2000, epochs=10000)
2025-10-23 18:37:18,658 | INFO | [MA-LfL][Reward] Agent 0 - 1000/10000 epochs completed (latest loss=0.3453)
2025-10-23 18:37:24,750 | INFO | [MA-LfL][Reward] Agent 0 - 2000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:37:30,675 | INFO | [MA-LfL][Reward] Agent 0 - 3000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:37:36,253 | INFO | [MA-LfL][Reward] Agent 0 - 4000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:37:42,195 | INFO | [MA-LfL][Reward] Agent 0 - 5000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:37:48,472 | INFO | [MA-LfL][Reward] Agent 0 - 6000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:37:54,643 | INFO | [MA-LfL][Reward] Agent 0 - 7000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:38:00,775 | INFO | [MA-LfL][Reward] Agent 0 - 8000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:38:06,731 | INFO | [MA-LfL][Reward] Agent 0 - 9000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:38:12,807 | INFO | [MA-LfL][Reward] Agent 0 - 10000/10000 epochs completed (latest loss=0.3449)
2025-10-23 18:38:12,811 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=2000 (batch=2000, epochs=10000)
2025-10-23 18:38:18,715 | INFO | [MA-LfL][Reward] Agent 1 - 1000/10000 epochs completed (latest loss=0.1794)
2025-10-23 18:38:24,863 | INFO | [MA-LfL][Reward] Agent 1 - 2000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:38:31,489 | INFO | [MA-LfL][Reward] Agent 1 - 3000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:38:37,699 | INFO | [MA-LfL][Reward] Agent 1 - 4000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:38:43,973 | INFO | [MA-LfL][Reward] Agent 1 - 5000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:38:49,944 | INFO | [MA-LfL][Reward] Agent 1 - 6000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:38:56,105 | INFO | [MA-LfL][Reward] Agent 1 - 7000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:39:02,056 | INFO | [MA-LfL][Reward] Agent 1 - 8000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:39:08,168 | INFO | [MA-LfL][Reward] Agent 1 - 9000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:39:14,136 | INFO | [MA-LfL][Reward] Agent 1 - 10000/10000 epochs completed (latest loss=0.1792)
2025-10-23 18:39:14,137 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 18:39:14,907 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 18:39:14,907 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 18:39:14,907 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: 0.2191 | Spearman: 0.2107
2025-10-23 18:39:14,908 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: 0.1445 | Spearman: 0.1282
2025-10-23 18:39:14,908 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2
2025-10-23 18:39:14,908 | INFO | [Experiment:heterogeneous] Trend Pearson: 0.4034, 0.6917
2025-10-23 18:39:14,909 | INFO | [Experiment:heterogeneous] Trend Spearman: 0.4059, 0.6826
2025-10-23 18:39:14,909 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 18:39:14,910 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 18:39:14,910 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? YES
2025-10-23 18:39:14,912 | INFO | Summary saved to outputs\summary.json
2025-10-23 18:39:14,912 | INFO | Run complete.
