2025-10-23 09:49:43,948 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_094943.log
2025-10-23 09:49:43,948 | INFO | Configuration file: config.yaml
2025-10-23 09:49:43,948 | INFO | Reward families to process: heterogeneous
2025-10-23 09:49:43,948 | INFO | MA-SPI iterations=3, episodes/stage=50, episode_length=100
2025-10-23 09:49:43,949 | INFO | MA-LfL reward epochs=2000, reward batch size=8192
2025-10-23 09:49:43,949 | INFO | Log file located at outputs\logs\run_20251023_094943.log
2025-10-23 09:49:43,949 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 09:49:43,949 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 09:49:45,161 | INFO | [MA-SPI] Starting run with 3 stages, 50 episodes/stage, episode length 100
2025-10-23 09:49:45,163 | INFO | [MA-SPI] Stage 1/3 - collecting trajectories...
2025-10-23 09:49:46,752 | INFO | [MA-SPI] Stage 1/3 - collected 10/50 episodes
2025-10-23 09:49:48,089 | INFO | [MA-SPI] Stage 1/3 - collected 20/50 episodes
2025-10-23 09:49:49,479 | INFO | [MA-SPI] Stage 1/3 - collected 30/50 episodes
2025-10-23 09:49:50,789 | INFO | [MA-SPI] Stage 1/3 - collected 40/50 episodes
2025-10-23 09:49:52,232 | INFO | [MA-SPI] Stage 1/3 - collected 50/50 episodes
2025-10-23 09:49:52,235 | INFO | [MA-SPI] Stage 1/3 - Agent 0 avg episode reward: -131.960 (std 30.728)
2025-10-23 09:49:52,235 | INFO | [MA-SPI] Stage 1/3 - Agent 1 avg episode reward: -111.860 (std 30.364)
2025-10-23 09:49:52,236 | INFO | [MA-SPI] Stage 1/3 - dataset size: 5000 transitions
2025-10-23 09:49:52,555 | INFO | [MA-SPI] Stage 1/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:2.9560, A1_Q_loss:3.1497]
2025-10-23 09:49:52,701 | INFO | [MA-SPI] Stage 1/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:1.6531, A1_Q_loss:1.6196]
2025-10-23 09:49:52,824 | INFO | [MA-SPI] Stage 1/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:1.1931, A1_Q_loss:0.8657]
2025-10-23 09:49:52,930 | INFO | [MA-SPI] Stage 1/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.8032, A1_Q_loss:0.6951]
2025-10-23 09:49:53,021 | INFO | [MA-SPI] Stage 1/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.7046, A1_Q_loss:0.6365]
2025-10-23 09:49:53,065 | INFO | [MA-SPI] Stage 1/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0265, A1_Policy_loss:0.0204]
2025-10-23 09:49:53,114 | INFO | [MA-SPI] Stage 1/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0082, A1_Policy_loss:0.0053]
2025-10-23 09:49:53,160 | INFO | [MA-SPI] Stage 1/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0026, A1_Policy_loss:0.0018]
2025-10-23 09:49:53,201 | INFO | [MA-SPI] Stage 1/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0007]
2025-10-23 09:49:53,248 | INFO | [MA-SPI] Stage 1/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 09:49:53,248 | INFO | [MA-SPI] Stage 1/3 - completed
2025-10-23 09:49:53,248 | INFO | [MA-SPI] Stage 2/3 - collecting trajectories...
2025-10-23 09:49:54,641 | INFO | [MA-SPI] Stage 2/3 - collected 10/50 episodes
2025-10-23 09:49:55,980 | INFO | [MA-SPI] Stage 2/3 - collected 20/50 episodes
2025-10-23 09:49:57,376 | INFO | [MA-SPI] Stage 2/3 - collected 30/50 episodes
2025-10-23 09:49:58,786 | INFO | [MA-SPI] Stage 2/3 - collected 40/50 episodes
2025-10-23 09:50:00,181 | INFO | [MA-SPI] Stage 2/3 - collected 50/50 episodes
2025-10-23 09:50:00,185 | INFO | [MA-SPI] Stage 2/3 - Agent 0 avg episode reward: 66.200 (std 33.308)
2025-10-23 09:50:00,185 | INFO | [MA-SPI] Stage 2/3 - Agent 1 avg episode reward: 67.920 (std 33.636)
2025-10-23 09:50:00,185 | INFO | [MA-SPI] Stage 2/3 - dataset size: 5000 transitions
2025-10-23 09:50:00,354 | INFO | [MA-SPI] Stage 2/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:1.6941, A1_Q_loss:1.2148]
2025-10-23 09:50:00,466 | INFO | [MA-SPI] Stage 2/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.9297, A1_Q_loss:0.9250]
2025-10-23 09:50:00,586 | INFO | [MA-SPI] Stage 2/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.8398, A1_Q_loss:0.8679]
2025-10-23 09:50:00,704 | INFO | [MA-SPI] Stage 2/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.8066, A1_Q_loss:0.8577]
2025-10-23 09:50:00,812 | INFO | [MA-SPI] Stage 2/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.7975, A1_Q_loss:0.8459]
2025-10-23 09:50:00,867 | INFO | [MA-SPI] Stage 2/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0074, A1_Policy_loss:0.0056]
2025-10-23 09:50:00,910 | INFO | [MA-SPI] Stage 2/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0022, A1_Policy_loss:0.0019]
2025-10-23 09:50:00,950 | INFO | [MA-SPI] Stage 2/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0009, A1_Policy_loss:0.0008]
2025-10-23 09:50:00,987 | INFO | [MA-SPI] Stage 2/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 09:50:01,030 | INFO | [MA-SPI] Stage 2/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 09:50:01,030 | INFO | [MA-SPI] Stage 2/3 - completed
2025-10-23 09:50:01,030 | INFO | [MA-SPI] Stage 3/3 - collecting trajectories...
2025-10-23 09:50:02,442 | INFO | [MA-SPI] Stage 3/3 - collected 10/50 episodes
2025-10-23 09:50:03,955 | INFO | [MA-SPI] Stage 3/3 - collected 20/50 episodes
2025-10-23 09:50:05,508 | INFO | [MA-SPI] Stage 3/3 - collected 30/50 episodes
2025-10-23 09:50:06,905 | INFO | [MA-SPI] Stage 3/3 - collected 40/50 episodes
2025-10-23 09:50:08,318 | INFO | [MA-SPI] Stage 3/3 - collected 50/50 episodes
2025-10-23 09:50:08,321 | INFO | [MA-SPI] Stage 3/3 - Agent 0 avg episode reward: 107.200 (std 21.972)
2025-10-23 09:50:08,321 | INFO | [MA-SPI] Stage 3/3 - Agent 1 avg episode reward: 109.680 (std 22.438)
2025-10-23 09:50:08,321 | INFO | [MA-SPI] Stage 3/3 - dataset size: 5000 transitions
2025-10-23 09:50:08,510 | INFO | [MA-SPI] Stage 3/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.5561, A1_Q_loss:0.4463]
2025-10-23 09:50:08,626 | INFO | [MA-SPI] Stage 3/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.4792, A1_Q_loss:0.4420]
2025-10-23 09:50:08,736 | INFO | [MA-SPI] Stage 3/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.4450, A1_Q_loss:0.4431]
2025-10-23 09:50:08,843 | INFO | [MA-SPI] Stage 3/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.4415, A1_Q_loss:0.4455]
2025-10-23 09:50:08,954 | INFO | [MA-SPI] Stage 3/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.4531, A1_Q_loss:0.4270]
2025-10-23 09:50:08,999 | INFO | [MA-SPI] Stage 3/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0031, A1_Policy_loss:0.0027]
2025-10-23 09:50:09,040 | INFO | [MA-SPI] Stage 3/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0011]
2025-10-23 09:50:09,082 | INFO | [MA-SPI] Stage 3/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0004]
2025-10-23 09:50:09,129 | INFO | [MA-SPI] Stage 3/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 09:50:09,174 | INFO | [MA-SPI] Stage 3/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 09:50:09,174 | INFO | [MA-SPI] Stage 3/3 - completed
2025-10-23 09:50:09,267 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 09:50:09,268 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 09:50:09,268 | INFO | [MA-LfL] Estimating policies...
2025-10-23 09:50:09,268 | INFO | [MA-LfL][Policy] Stage 1/3 - preparing data
2025-10-23 09:50:09,313 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 10/10 epochs completed (loss=1.1252, baseline=1.6094)
2025-10-23 09:50:09,351 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 10/10 epochs completed (loss=1.1199, baseline=1.6094)
2025-10-23 09:50:09,351 | INFO | [MA-LfL][Policy] Stage 2/3 - preparing data
2025-10-23 09:50:09,395 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 10/10 epochs completed (loss=1.0687, baseline=1.6094)
2025-10-23 09:50:09,429 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 10/10 epochs completed (loss=1.0781, baseline=1.6094)
2025-10-23 09:50:09,429 | INFO | [MA-LfL][Policy] Stage 3/3 - preparing data
2025-10-23 09:50:09,465 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 10/10 epochs completed (loss=1.0409, baseline=1.6094)
2025-10-23 09:50:09,492 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 10/10 epochs completed (loss=1.0714, baseline=1.6094)
2025-10-23 09:50:09,493 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 09:50:09,493 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 0
2025-10-23 09:50:09,787 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 1
2025-10-23 09:50:10,142 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 0
2025-10-23 09:50:10,455 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 1
2025-10-23 09:50:10,791 | INFO | [MA-LfL] Learning rewards...
2025-10-23 09:50:10,805 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=10000 (batch=8192, epochs=2000)
2025-10-23 09:50:13,877 | INFO | [MA-LfL][Reward] Agent 0 - 200/2000 epochs completed (latest loss=0.2854)
2025-10-23 09:50:16,813 | INFO | [MA-LfL][Reward] Agent 0 - 400/2000 epochs completed (latest loss=0.2763)
2025-10-23 09:50:19,664 | INFO | [MA-LfL][Reward] Agent 0 - 600/2000 epochs completed (latest loss=0.2697)
2025-10-23 09:50:22,625 | INFO | [MA-LfL][Reward] Agent 0 - 800/2000 epochs completed (latest loss=0.2743)
2025-10-23 09:50:25,350 | INFO | [MA-LfL][Reward] Agent 0 - 1000/2000 epochs completed (latest loss=0.2544)
2025-10-23 09:50:28,247 | INFO | [MA-LfL][Reward] Agent 0 - 1200/2000 epochs completed (latest loss=0.2597)
2025-10-23 09:50:31,174 | INFO | [MA-LfL][Reward] Agent 0 - 1400/2000 epochs completed (latest loss=0.2553)
2025-10-23 09:50:33,950 | INFO | [MA-LfL][Reward] Agent 0 - 1600/2000 epochs completed (latest loss=0.2590)
2025-10-23 09:50:36,831 | INFO | [MA-LfL][Reward] Agent 0 - 1800/2000 epochs completed (latest loss=0.2733)
2025-10-23 09:50:39,771 | INFO | [MA-LfL][Reward] Agent 0 - 2000/2000 epochs completed (latest loss=0.2645)
2025-10-23 09:50:39,779 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=10000 (batch=8192, epochs=2000)
2025-10-23 09:50:42,786 | INFO | [MA-LfL][Reward] Agent 1 - 200/2000 epochs completed (latest loss=0.2796)
2025-10-23 09:50:45,758 | INFO | [MA-LfL][Reward] Agent 1 - 400/2000 epochs completed (latest loss=0.2425)
2025-10-23 09:50:48,635 | INFO | [MA-LfL][Reward] Agent 1 - 600/2000 epochs completed (latest loss=0.2422)
2025-10-23 09:50:51,613 | INFO | [MA-LfL][Reward] Agent 1 - 800/2000 epochs completed (latest loss=0.2442)
2025-10-23 09:50:54,657 | INFO | [MA-LfL][Reward] Agent 1 - 1000/2000 epochs completed (latest loss=0.2383)
2025-10-23 09:50:57,609 | INFO | [MA-LfL][Reward] Agent 1 - 1200/2000 epochs completed (latest loss=0.2278)
2025-10-23 09:51:00,399 | INFO | [MA-LfL][Reward] Agent 1 - 1400/2000 epochs completed (latest loss=0.2324)
2025-10-23 09:51:03,190 | INFO | [MA-LfL][Reward] Agent 1 - 1600/2000 epochs completed (latest loss=0.2360)
2025-10-23 09:51:06,101 | INFO | [MA-LfL][Reward] Agent 1 - 1800/2000 epochs completed (latest loss=0.2415)
2025-10-23 09:51:09,047 | INFO | [MA-LfL][Reward] Agent 1 - 2000/2000 epochs completed (latest loss=0.2259)
2025-10-23 09:51:09,048 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 09:51:10,887 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 09:51:10,887 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 09:51:10,887 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: -0.0099 | Spearman: 0.0030
2025-10-23 09:51:10,887 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: -0.0570 | Spearman: -0.0440
2025-10-23 09:51:10,887 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2
2025-10-23 09:51:10,888 | INFO | [Experiment:heterogeneous] Trend Pearson: 0.3355, 0.3320
2025-10-23 09:51:10,888 | INFO | [Experiment:heterogeneous] Trend Spearman: 0.1984, 0.2410
2025-10-23 09:51:10,888 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 09:51:10,888 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 09:51:10,888 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 09:51:10,889 | INFO | Summary saved to outputs\summary.json
2025-10-23 09:51:10,890 | INFO | Run complete.
