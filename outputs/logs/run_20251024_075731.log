2025-10-24 07:57:31,873 | INFO | Logging initialized. Log file: outputs\logs\run_20251024_075731.log
2025-10-24 07:57:31,873 | INFO | Configuration file: config.yaml
2025-10-24 07:57:31,874 | INFO | Reward families to process: heterogeneous
2025-10-24 07:57:31,874 | INFO | MA-SPI iterations=5, episodes/stage=10, episode_length=100
2025-10-24 07:57:31,874 | INFO | MA-LfL reward epochs=20000, reward batch size=8192
2025-10-24 07:57:31,874 | INFO | Log file located at outputs\logs\run_20251024_075731.log
2025-10-24 07:57:31,874 | INFO | Running experiment for reward family: heterogeneous
2025-10-24 07:57:31,874 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-24 07:57:32,726 | INFO | [MA-SPI] Starting run with 5 stages, 10 episodes/stage, episode length 100
2025-10-24 07:57:32,739 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-24 07:57:33,177 | INFO | [MA-SPI] Stage 1/5 - collected 2/10 episodes
2025-10-24 07:57:33,431 | INFO | [MA-SPI] Stage 1/5 - collected 4/10 episodes
2025-10-24 07:57:33,687 | INFO | [MA-SPI] Stage 1/5 - collected 6/10 episodes
2025-10-24 07:57:33,938 | INFO | [MA-SPI] Stage 1/5 - collected 8/10 episodes
2025-10-24 07:57:34,195 | INFO | [MA-SPI] Stage 1/5 - collected 10/10 episodes
2025-10-24 07:57:34,196 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -137.400 (std 33.539)
2025-10-24 07:57:34,196 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -114.900 (std 35.184)
2025-10-24 07:57:34,196 | INFO | [MA-SPI] Stage 1/5 - dataset size: 1000 transitions
2025-10-24 07:57:34,429 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:2.7630, A1_Q_loss:3.1812]
2025-10-24 07:57:34,511 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.3751, A1_Q_loss:1.4296]
2025-10-24 07:57:34,592 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.8376, A1_Q_loss:1.0367]
2025-10-24 07:57:34,686 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.5093, A1_Q_loss:0.7529]
2025-10-24 07:57:34,768 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4704, A1_Q_loss:0.5672]
2025-10-24 07:57:34,802 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0288, A1_Policy_loss:0.0183]
2025-10-24 07:57:34,838 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0090, A1_Policy_loss:0.0042]
2025-10-24 07:57:34,874 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0015]
2025-10-24 07:57:34,911 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0013, A1_Policy_loss:0.0006]
2025-10-24 07:57:34,946 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0002]
2025-10-24 07:57:34,946 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-24 07:57:34,946 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-24 07:57:35,268 | INFO | [MA-SPI] Stage 2/5 - collected 2/10 episodes
2025-10-24 07:57:35,546 | INFO | [MA-SPI] Stage 2/5 - collected 4/10 episodes
2025-10-24 07:57:35,844 | INFO | [MA-SPI] Stage 2/5 - collected 6/10 episodes
2025-10-24 07:57:36,110 | INFO | [MA-SPI] Stage 2/5 - collected 8/10 episodes
2025-10-24 07:57:36,372 | INFO | [MA-SPI] Stage 2/5 - collected 10/10 episodes
2025-10-24 07:57:36,373 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: 67.000 (std 29.783)
2025-10-24 07:57:36,373 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 47.100 (std 20.535)
2025-10-24 07:57:36,373 | INFO | [MA-SPI] Stage 2/5 - dataset size: 1000 transitions
2025-10-24 07:57:36,461 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:1.6607, A1_Q_loss:1.4316]
2025-10-24 07:57:36,550 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.0833, A1_Q_loss:1.1384]
2025-10-24 07:57:36,637 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.9357, A1_Q_loss:1.0149]
2025-10-24 07:57:36,727 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.8746, A1_Q_loss:0.9769]
2025-10-24 07:57:36,823 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.8530, A1_Q_loss:0.9853]
2025-10-24 07:57:36,861 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0158, A1_Policy_loss:0.0072]
2025-10-24 07:57:36,898 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0048, A1_Policy_loss:0.0025]
2025-10-24 07:57:36,936 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0020, A1_Policy_loss:0.0010]
2025-10-24 07:57:36,974 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0004]
2025-10-24 07:57:37,013 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-24 07:57:37,013 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-24 07:57:37,013 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-24 07:57:37,300 | INFO | [MA-SPI] Stage 3/5 - collected 2/10 episodes
2025-10-24 07:57:37,607 | INFO | [MA-SPI] Stage 3/5 - collected 4/10 episodes
2025-10-24 07:57:37,847 | INFO | [MA-SPI] Stage 3/5 - collected 6/10 episodes
2025-10-24 07:57:38,096 | INFO | [MA-SPI] Stage 3/5 - collected 8/10 episodes
2025-10-24 07:57:38,347 | INFO | [MA-SPI] Stage 3/5 - collected 10/10 episodes
2025-10-24 07:57:38,348 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 113.400 (std 28.051)
2025-10-24 07:57:38,349 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 109.100 (std 25.137)
2025-10-24 07:57:38,349 | INFO | [MA-SPI] Stage 3/5 - dataset size: 1000 transitions
2025-10-24 07:57:38,436 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.7991, A1_Q_loss:0.6151]
2025-10-24 07:57:38,517 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.8251, A1_Q_loss:0.5328]
2025-10-24 07:57:38,595 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.7463, A1_Q_loss:0.5244]
2025-10-24 07:57:38,675 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.7612, A1_Q_loss:0.5156]
2025-10-24 07:57:38,764 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.7643, A1_Q_loss:0.5197]
2025-10-24 07:57:38,799 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0067, A1_Policy_loss:0.0051]
2025-10-24 07:57:38,833 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0023, A1_Policy_loss:0.0019]
2025-10-24 07:57:38,868 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0007]
2025-10-24 07:57:38,901 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-24 07:57:38,934 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-24 07:57:38,935 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-24 07:57:38,935 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-24 07:57:39,198 | INFO | [MA-SPI] Stage 4/5 - collected 2/10 episodes
2025-10-24 07:57:39,443 | INFO | [MA-SPI] Stage 4/5 - collected 4/10 episodes
2025-10-24 07:57:39,703 | INFO | [MA-SPI] Stage 4/5 - collected 6/10 episodes
2025-10-24 07:57:39,955 | INFO | [MA-SPI] Stage 4/5 - collected 8/10 episodes
2025-10-24 07:57:40,217 | INFO | [MA-SPI] Stage 4/5 - collected 10/10 episodes
2025-10-24 07:57:40,218 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 112.800 (std 30.225)
2025-10-24 07:57:40,218 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 98.900 (std 33.721)
2025-10-24 07:57:40,218 | INFO | [MA-SPI] Stage 4/5 - dataset size: 1000 transitions
2025-10-24 07:57:40,305 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.5955, A1_Q_loss:0.4295]
2025-10-24 07:57:40,384 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.5255, A1_Q_loss:0.3559]
2025-10-24 07:57:40,464 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.4722, A1_Q_loss:0.3525]
2025-10-24 07:57:40,546 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.5347, A1_Q_loss:0.3298]
2025-10-24 07:57:40,627 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4735, A1_Q_loss:0.3408]
2025-10-24 07:57:40,665 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0037, A1_Policy_loss:0.0032]
2025-10-24 07:57:40,701 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0011, A1_Policy_loss:0.0010]
2025-10-24 07:57:40,737 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0005]
2025-10-24 07:57:40,774 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-24 07:57:40,817 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-24 07:57:40,817 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-24 07:57:40,817 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-24 07:57:41,109 | INFO | [MA-SPI] Stage 5/5 - collected 2/10 episodes
2025-10-24 07:57:41,348 | INFO | [MA-SPI] Stage 5/5 - collected 4/10 episodes
2025-10-24 07:57:41,601 | INFO | [MA-SPI] Stage 5/5 - collected 6/10 episodes
2025-10-24 07:57:41,851 | INFO | [MA-SPI] Stage 5/5 - collected 8/10 episodes
2025-10-24 07:57:42,110 | INFO | [MA-SPI] Stage 5/5 - collected 10/10 episodes
2025-10-24 07:57:42,111 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 115.500 (std 18.720)
2025-10-24 07:57:42,112 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 110.000 (std 23.422)
2025-10-24 07:57:42,112 | INFO | [MA-SPI] Stage 5/5 - dataset size: 1000 transitions
2025-10-24 07:57:42,195 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.5018, A1_Q_loss:0.4675]
2025-10-24 07:57:42,271 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.4171, A1_Q_loss:0.4131]
2025-10-24 07:57:42,348 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.4285, A1_Q_loss:0.3537]
2025-10-24 07:57:42,436 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.4103, A1_Q_loss:0.4335]
2025-10-24 07:57:42,513 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4163, A1_Q_loss:0.4042]
2025-10-24 07:57:42,549 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0023, A1_Policy_loss:0.0031]
2025-10-24 07:57:42,586 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0012]
2025-10-24 07:57:42,622 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0005]
2025-10-24 07:57:42,655 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0002]
2025-10-24 07:57:42,690 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-24 07:57:42,690 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-24 07:57:42,724 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-24 07:57:42,724 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-24 07:57:42,724 | INFO | [MA-LfL] Estimating policies...
2025-10-24 07:57:42,724 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-24 07:57:42,747 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 2/10 epochs completed (loss=3.2695, baseline=1.6094)
2025-10-24 07:57:42,752 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 4/10 epochs completed (loss=1.4244, baseline=1.6094)
2025-10-24 07:57:42,756 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 6/10 epochs completed (loss=1.2134, baseline=1.6094)
2025-10-24 07:57:42,759 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 8/10 epochs completed (loss=1.1068, baseline=1.6094)
2025-10-24 07:57:42,767 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.0913, baseline=1.6094)
2025-10-24 07:57:42,780 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 2/10 epochs completed (loss=3.0694, baseline=1.6094)
2025-10-24 07:57:42,785 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 4/10 epochs completed (loss=1.4800, baseline=1.6094)
2025-10-24 07:57:42,789 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 6/10 epochs completed (loss=1.2070, baseline=1.6094)
2025-10-24 07:57:42,795 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 8/10 epochs completed (loss=1.1019, baseline=1.6094)
2025-10-24 07:57:42,799 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.0798, baseline=1.6094)
2025-10-24 07:57:42,800 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-24 07:57:42,805 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 2/10 epochs completed (loss=3.1231, baseline=1.6094)
2025-10-24 07:57:42,809 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 4/10 epochs completed (loss=2.5654, baseline=1.6094)
2025-10-24 07:57:42,814 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 6/10 epochs completed (loss=1.2076, baseline=1.6094)
2025-10-24 07:57:42,818 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 8/10 epochs completed (loss=1.0764, baseline=1.6094)
2025-10-24 07:57:42,822 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=0.9976, baseline=1.6094)
2025-10-24 07:57:42,826 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 2/10 epochs completed (loss=2.4523, baseline=1.6094)
2025-10-24 07:57:42,831 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 4/10 epochs completed (loss=1.2198, baseline=1.6094)
2025-10-24 07:57:42,836 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 6/10 epochs completed (loss=1.0589, baseline=1.6094)
2025-10-24 07:57:42,839 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 8/10 epochs completed (loss=1.0233, baseline=1.6094)
2025-10-24 07:57:42,843 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=0.9760, baseline=1.6094)
2025-10-24 07:57:42,843 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-24 07:57:42,848 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 2/10 epochs completed (loss=2.6041, baseline=1.6094)
2025-10-24 07:57:42,855 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 4/10 epochs completed (loss=1.7274, baseline=1.6094)
2025-10-24 07:57:42,858 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 6/10 epochs completed (loss=1.1143, baseline=1.6094)
2025-10-24 07:57:42,862 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 8/10 epochs completed (loss=1.0074, baseline=1.6094)
2025-10-24 07:57:42,866 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=0.9835, baseline=1.6094)
2025-10-24 07:57:42,872 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 2/10 epochs completed (loss=5.7030, baseline=1.6094)
2025-10-24 07:57:42,878 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 4/10 epochs completed (loss=1.6001, baseline=1.6094)
2025-10-24 07:57:42,881 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 6/10 epochs completed (loss=1.2568, baseline=1.6094)
2025-10-24 07:57:42,885 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 8/10 epochs completed (loss=1.0344, baseline=1.6094)
2025-10-24 07:57:42,889 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0029, baseline=1.6094)
2025-10-24 07:57:42,889 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-24 07:57:42,897 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 2/10 epochs completed (loss=2.8728, baseline=1.6094)
2025-10-24 07:57:42,901 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 4/10 epochs completed (loss=1.6201, baseline=1.6094)
2025-10-24 07:57:42,905 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 6/10 epochs completed (loss=1.2387, baseline=1.6094)
2025-10-24 07:57:42,908 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 8/10 epochs completed (loss=1.1303, baseline=1.6094)
2025-10-24 07:57:42,913 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0035, baseline=1.6094)
2025-10-24 07:57:42,918 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 2/10 epochs completed (loss=2.9283, baseline=1.6094)
2025-10-24 07:57:42,922 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 4/10 epochs completed (loss=1.4339, baseline=1.6094)
2025-10-24 07:57:42,926 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 6/10 epochs completed (loss=1.0704, baseline=1.6094)
2025-10-24 07:57:42,930 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 8/10 epochs completed (loss=1.0526, baseline=1.6094)
2025-10-24 07:57:42,934 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0177, baseline=1.6094)
2025-10-24 07:57:42,935 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-24 07:57:42,940 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 2/10 epochs completed (loss=3.1318, baseline=1.6094)
2025-10-24 07:57:42,943 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 4/10 epochs completed (loss=1.6561, baseline=1.6094)
2025-10-24 07:57:42,947 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 6/10 epochs completed (loss=1.0889, baseline=1.6094)
2025-10-24 07:57:42,951 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 8/10 epochs completed (loss=1.0369, baseline=1.6094)
2025-10-24 07:57:42,955 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0083, baseline=1.6094)
2025-10-24 07:57:42,960 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 2/10 epochs completed (loss=3.7079, baseline=1.6094)
2025-10-24 07:57:42,964 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 4/10 epochs completed (loss=1.5068, baseline=1.6094)
2025-10-24 07:57:42,969 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 6/10 epochs completed (loss=1.1110, baseline=1.6094)
2025-10-24 07:57:42,973 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 8/10 epochs completed (loss=1.0331, baseline=1.6094)
2025-10-24 07:57:42,979 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0069, baseline=1.6094)
2025-10-24 07:57:42,980 | INFO | [MA-LfL] Computing reward targets...
2025-10-24 07:57:42,980 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-24 07:57:43,324 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-24 07:57:43,661 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-24 07:57:43,987 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-24 07:57:44,343 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-24 07:57:44,697 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-24 07:57:45,038 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-24 07:57:45,385 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-24 07:57:45,736 | INFO | [MA-LfL] Learning rewards...
2025-10-24 07:57:45,739 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=4000 (batch=4000, epochs=20000)
2025-10-24 07:58:02,728 | INFO | [MA-LfL][Reward] Agent 0 - 2000/20000 epochs completed (latest loss=1.3436)
2025-10-24 07:58:19,841 | INFO | [MA-LfL][Reward] Agent 0 - 4000/20000 epochs completed (latest loss=6.5043)
2025-10-24 07:58:37,550 | INFO | [MA-LfL][Reward] Agent 0 - 6000/20000 epochs completed (latest loss=16.4512)
2025-10-24 07:58:55,400 | INFO | [MA-LfL][Reward] Agent 0 - 8000/20000 epochs completed (latest loss=25.7685)
2025-10-24 07:59:13,224 | INFO | [MA-LfL][Reward] Agent 0 - 10000/20000 epochs completed (latest loss=35.1299)
2025-10-24 07:59:30,376 | INFO | [MA-LfL][Reward] Agent 0 - 12000/20000 epochs completed (latest loss=44.9345)
2025-10-24 07:59:48,767 | INFO | [MA-LfL][Reward] Agent 0 - 14000/20000 epochs completed (latest loss=54.1701)
2025-10-24 08:00:06,767 | INFO | [MA-LfL][Reward] Agent 0 - 16000/20000 epochs completed (latest loss=62.7322)
2025-10-24 08:00:25,671 | INFO | [MA-LfL][Reward] Agent 0 - 18000/20000 epochs completed (latest loss=70.2375)
2025-10-24 08:00:45,297 | INFO | [MA-LfL][Reward] Agent 0 - 20000/20000 epochs completed (latest loss=76.8503)
2025-10-24 08:00:45,301 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=4000 (batch=4000, epochs=20000)
2025-10-24 08:01:03,199 | INFO | [MA-LfL][Reward] Agent 1 - 2000/20000 epochs completed (latest loss=0.7594)
2025-10-24 08:01:22,182 | INFO | [MA-LfL][Reward] Agent 1 - 4000/20000 epochs completed (latest loss=0.7688)
2025-10-24 08:01:39,926 | INFO | [MA-LfL][Reward] Agent 1 - 6000/20000 epochs completed (latest loss=0.8358)
2025-10-24 08:01:58,247 | INFO | [MA-LfL][Reward] Agent 1 - 8000/20000 epochs completed (latest loss=0.9799)
2025-10-24 08:02:16,577 | INFO | [MA-LfL][Reward] Agent 1 - 10000/20000 epochs completed (latest loss=1.2258)
2025-10-24 08:02:34,227 | INFO | [MA-LfL][Reward] Agent 1 - 12000/20000 epochs completed (latest loss=1.5845)
2025-10-24 08:02:54,975 | INFO | [MA-LfL][Reward] Agent 1 - 14000/20000 epochs completed (latest loss=2.0937)
2025-10-24 08:03:13,180 | INFO | [MA-LfL][Reward] Agent 1 - 16000/20000 epochs completed (latest loss=2.7472)
2025-10-24 08:03:30,599 | INFO | [MA-LfL][Reward] Agent 1 - 18000/20000 epochs completed (latest loss=3.4871)
2025-10-24 08:03:47,954 | INFO | [MA-LfL][Reward] Agent 1 - 20000/20000 epochs completed (latest loss=4.2890)
2025-10-24 08:03:47,955 | INFO | [MA-LfL] Evaluating rewards...
2025-10-24 08:03:48,684 | INFO | [MA-LfL] Computing alignment metrics (R_hat + g - gamma*g' vs Y_h)...
2025-10-24 08:03:48,729 | INFO | [MA-LfL] Pipeline complete.
2025-10-24 08:03:48,730 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-24 08:03:48,730 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: -0.0237 | Spearman: -0.0145
2025-10-24 08:03:48,730 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: -0.1135 | Spearman: -0.0976
2025-10-24 08:03:48,730 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2, 3, 4
2025-10-24 08:03:48,730 | INFO | [Experiment:heterogeneous] Trend Pearson: -0.4034, -0.6917, -0.5595, -0.5787
2025-10-24 08:03:48,731 | INFO | [Experiment:heterogeneous] Trend Spearman: -0.4059, -0.6826, -0.6808, -0.5968
2025-10-24 08:03:48,731 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-24 08:03:48,731 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-24 08:03:48,731 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-24 08:03:48,732 | INFO | Summary saved to outputs\summary.json
2025-10-24 08:03:48,732 | INFO | Run complete.
