2025-10-23 09:02:33,675 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_090233.log
2025-10-23 09:02:33,675 | INFO | Configuration file: config.yaml
2025-10-23 09:02:33,676 | INFO | Reward families to process: heterogeneous
2025-10-23 09:02:33,676 | INFO | MA-SPI iterations=3, episodes/stage=50, episode_length=100
2025-10-23 09:02:33,676 | INFO | MA-LfL reward epochs=1000, reward batch size=8192
2025-10-23 09:02:33,676 | INFO | Log file located at outputs\logs\run_20251023_090233.log
2025-10-23 09:02:33,677 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 09:02:33,677 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 09:02:34,561 | INFO | [MA-SPI] Starting run with 3 stages, 50 episodes/stage, episode length 100
2025-10-23 09:02:34,572 | INFO | [MA-SPI] Stage 1/3 - collecting trajectories...
2025-10-23 09:02:36,129 | INFO | [MA-SPI] Stage 1/3 - collected 10/50 episodes
2025-10-23 09:02:37,503 | INFO | [MA-SPI] Stage 1/3 - collected 20/50 episodes
2025-10-23 09:02:39,008 | INFO | [MA-SPI] Stage 1/3 - collected 30/50 episodes
2025-10-23 09:02:40,348 | INFO | [MA-SPI] Stage 1/3 - collected 40/50 episodes
2025-10-23 09:02:41,726 | INFO | [MA-SPI] Stage 1/3 - collected 50/50 episodes
2025-10-23 09:02:41,729 | INFO | [MA-SPI] Stage 1/3 - Agent 0 avg episode reward: -131.960 (std 30.728)
2025-10-23 09:02:41,730 | INFO | [MA-SPI] Stage 1/3 - Agent 1 avg episode reward: -111.860 (std 30.364)
2025-10-23 09:02:41,730 | INFO | [MA-SPI] Stage 1/3 - dataset size: 5000 transitions
2025-10-23 09:02:42,057 | INFO | [MA-SPI] Stage 1/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:2.9560, A1_Q_loss:3.1497]
2025-10-23 09:02:42,187 | INFO | [MA-SPI] Stage 1/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:1.6531, A1_Q_loss:1.6196]
2025-10-23 09:02:42,290 | INFO | [MA-SPI] Stage 1/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:1.1931, A1_Q_loss:0.8657]
2025-10-23 09:02:42,393 | INFO | [MA-SPI] Stage 1/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.8032, A1_Q_loss:0.6951]
2025-10-23 09:02:42,497 | INFO | [MA-SPI] Stage 1/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.7046, A1_Q_loss:0.6365]
2025-10-23 09:02:42,541 | INFO | [MA-SPI] Stage 1/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0265, A1_Policy_loss:0.0204]
2025-10-23 09:02:42,584 | INFO | [MA-SPI] Stage 1/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0082, A1_Policy_loss:0.0053]
2025-10-23 09:02:42,640 | INFO | [MA-SPI] Stage 1/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0026, A1_Policy_loss:0.0018]
2025-10-23 09:02:42,681 | INFO | [MA-SPI] Stage 1/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0007]
2025-10-23 09:02:42,721 | INFO | [MA-SPI] Stage 1/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 09:02:42,722 | INFO | [MA-SPI] Stage 1/3 - completed
2025-10-23 09:02:42,722 | INFO | [MA-SPI] Stage 2/3 - collecting trajectories...
2025-10-23 09:02:44,168 | INFO | [MA-SPI] Stage 2/3 - collected 10/50 episodes
2025-10-23 09:02:45,645 | INFO | [MA-SPI] Stage 2/3 - collected 20/50 episodes
2025-10-23 09:02:47,040 | INFO | [MA-SPI] Stage 2/3 - collected 30/50 episodes
2025-10-23 09:02:48,629 | INFO | [MA-SPI] Stage 2/3 - collected 40/50 episodes
2025-10-23 09:02:50,008 | INFO | [MA-SPI] Stage 2/3 - collected 50/50 episodes
2025-10-23 09:02:50,012 | INFO | [MA-SPI] Stage 2/3 - Agent 0 avg episode reward: 66.200 (std 33.308)
2025-10-23 09:02:50,012 | INFO | [MA-SPI] Stage 2/3 - Agent 1 avg episode reward: 67.920 (std 33.636)
2025-10-23 09:02:50,012 | INFO | [MA-SPI] Stage 2/3 - dataset size: 5000 transitions
2025-10-23 09:02:50,120 | INFO | [MA-SPI] Stage 2/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:1.6941, A1_Q_loss:1.2148]
2025-10-23 09:02:50,219 | INFO | [MA-SPI] Stage 2/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.9297, A1_Q_loss:0.9250]
2025-10-23 09:02:50,327 | INFO | [MA-SPI] Stage 2/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.8398, A1_Q_loss:0.8679]
2025-10-23 09:02:50,435 | INFO | [MA-SPI] Stage 2/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.8066, A1_Q_loss:0.8577]
2025-10-23 09:02:50,538 | INFO | [MA-SPI] Stage 2/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.7975, A1_Q_loss:0.8459]
2025-10-23 09:02:50,577 | INFO | [MA-SPI] Stage 2/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0074, A1_Policy_loss:0.0056]
2025-10-23 09:02:50,614 | INFO | [MA-SPI] Stage 2/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0022, A1_Policy_loss:0.0019]
2025-10-23 09:02:50,654 | INFO | [MA-SPI] Stage 2/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0009, A1_Policy_loss:0.0008]
2025-10-23 09:02:50,691 | INFO | [MA-SPI] Stage 2/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 09:02:50,731 | INFO | [MA-SPI] Stage 2/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 09:02:50,732 | INFO | [MA-SPI] Stage 2/3 - completed
2025-10-23 09:02:50,732 | INFO | [MA-SPI] Stage 3/3 - collecting trajectories...
2025-10-23 09:02:52,114 | INFO | [MA-SPI] Stage 3/3 - collected 10/50 episodes
2025-10-23 09:02:53,641 | INFO | [MA-SPI] Stage 3/3 - collected 20/50 episodes
2025-10-23 09:02:55,049 | INFO | [MA-SPI] Stage 3/3 - collected 30/50 episodes
2025-10-23 09:02:56,407 | INFO | [MA-SPI] Stage 3/3 - collected 40/50 episodes
2025-10-23 09:02:57,851 | INFO | [MA-SPI] Stage 3/3 - collected 50/50 episodes
2025-10-23 09:02:57,855 | INFO | [MA-SPI] Stage 3/3 - Agent 0 avg episode reward: 107.200 (std 21.972)
2025-10-23 09:02:57,855 | INFO | [MA-SPI] Stage 3/3 - Agent 1 avg episode reward: 109.680 (std 22.438)
2025-10-23 09:02:57,855 | INFO | [MA-SPI] Stage 3/3 - dataset size: 5000 transitions
2025-10-23 09:02:58,024 | INFO | [MA-SPI] Stage 3/3 - Q updates 20/100 (current batch 5000) [A0_Q_loss:0.5561, A1_Q_loss:0.4463]
2025-10-23 09:02:58,158 | INFO | [MA-SPI] Stage 3/3 - Q updates 40/100 (current batch 5000) [A0_Q_loss:0.4792, A1_Q_loss:0.4420]
2025-10-23 09:02:58,264 | INFO | [MA-SPI] Stage 3/3 - Q updates 60/100 (current batch 5000) [A0_Q_loss:0.4450, A1_Q_loss:0.4431]
2025-10-23 09:02:58,371 | INFO | [MA-SPI] Stage 3/3 - Q updates 80/100 (current batch 5000) [A0_Q_loss:0.4415, A1_Q_loss:0.4455]
2025-10-23 09:02:58,473 | INFO | [MA-SPI] Stage 3/3 - Q updates 100/100 (current batch 5000) [A0_Q_loss:0.4531, A1_Q_loss:0.4270]
2025-10-23 09:02:58,516 | INFO | [MA-SPI] Stage 3/3 - policy updates 10/50 (current batch 5000) [A0_Policy_loss:0.0031, A1_Policy_loss:0.0027]
2025-10-23 09:02:58,559 | INFO | [MA-SPI] Stage 3/3 - policy updates 20/50 (current batch 5000) [A0_Policy_loss:0.0010, A1_Policy_loss:0.0011]
2025-10-23 09:02:58,604 | INFO | [MA-SPI] Stage 3/3 - policy updates 30/50 (current batch 5000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0004]
2025-10-23 09:02:58,644 | INFO | [MA-SPI] Stage 3/3 - policy updates 40/50 (current batch 5000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-23 09:02:58,686 | INFO | [MA-SPI] Stage 3/3 - policy updates 50/50 (current batch 5000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 09:02:58,686 | INFO | [MA-SPI] Stage 3/3 - completed
2025-10-23 09:02:58,757 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 09:02:58,757 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 09:02:58,758 | INFO | [MA-LfL] Estimating policies...
2025-10-23 09:02:58,758 | INFO | [MA-LfL][Policy] Stage 1/3 - preparing data
2025-10-23 09:02:58,805 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 0: 10/10 epochs completed (loss=1.1252, baseline=1.6094)
2025-10-23 09:02:58,850 | INFO | [MA-LfL][Policy] Stage 1/3 - Agent 1: 10/10 epochs completed (loss=1.1199, baseline=1.6094)
2025-10-23 09:02:58,851 | INFO | [MA-LfL][Policy] Stage 2/3 - preparing data
2025-10-23 09:02:58,912 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 0: 10/10 epochs completed (loss=1.0687, baseline=1.6094)
2025-10-23 09:02:58,964 | INFO | [MA-LfL][Policy] Stage 2/3 - Agent 1: 10/10 epochs completed (loss=1.0781, baseline=1.6094)
2025-10-23 09:02:58,965 | INFO | [MA-LfL][Policy] Stage 3/3 - preparing data
2025-10-23 09:02:58,998 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 0: 10/10 epochs completed (loss=1.0409, baseline=1.6094)
2025-10-23 09:02:59,026 | INFO | [MA-LfL][Policy] Stage 3/3 - Agent 1: 10/10 epochs completed (loss=1.0714, baseline=1.6094)
2025-10-23 09:02:59,027 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 09:02:59,028 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 0
2025-10-23 09:02:59,343 | INFO | [MA-LfL][Targets] Stage 1/2 - Agent 1
2025-10-23 09:02:59,661 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 0
2025-10-23 09:02:59,975 | INFO | [MA-LfL][Targets] Stage 2/2 - Agent 1
2025-10-23 09:03:00,403 | INFO | [MA-LfL] Learning rewards...
2025-10-23 09:03:00,414 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=10000 (batch=8192, epochs=1000)
2025-10-23 09:03:01,893 | INFO | [MA-LfL][Reward] Agent 0 - 100/1000 epochs completed (latest loss=0.2855)
2025-10-23 09:03:03,288 | INFO | [MA-LfL][Reward] Agent 0 - 200/1000 epochs completed (latest loss=0.2609)
2025-10-23 09:03:04,663 | INFO | [MA-LfL][Reward] Agent 0 - 300/1000 epochs completed (latest loss=0.2455)
2025-10-23 09:03:06,070 | INFO | [MA-LfL][Reward] Agent 0 - 400/1000 epochs completed (latest loss=0.2635)
2025-10-23 09:03:07,396 | INFO | [MA-LfL][Reward] Agent 0 - 500/1000 epochs completed (latest loss=0.2622)
2025-10-23 09:03:08,829 | INFO | [MA-LfL][Reward] Agent 0 - 600/1000 epochs completed (latest loss=0.2546)
2025-10-23 09:03:10,157 | INFO | [MA-LfL][Reward] Agent 0 - 700/1000 epochs completed (latest loss=0.2629)
2025-10-23 09:03:11,541 | INFO | [MA-LfL][Reward] Agent 0 - 800/1000 epochs completed (latest loss=0.2622)
2025-10-23 09:03:13,007 | INFO | [MA-LfL][Reward] Agent 0 - 900/1000 epochs completed (latest loss=0.2666)
2025-10-23 09:03:14,530 | INFO | [MA-LfL][Reward] Agent 0 - 1000/1000 epochs completed (latest loss=0.2484)
2025-10-23 09:03:14,538 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=10000 (batch=8192, epochs=1000)
2025-10-23 09:03:15,942 | INFO | [MA-LfL][Reward] Agent 1 - 100/1000 epochs completed (latest loss=0.2739)
2025-10-23 09:03:17,335 | INFO | [MA-LfL][Reward] Agent 1 - 200/1000 epochs completed (latest loss=0.2438)
2025-10-23 09:03:18,726 | INFO | [MA-LfL][Reward] Agent 1 - 300/1000 epochs completed (latest loss=0.2405)
2025-10-23 09:03:20,176 | INFO | [MA-LfL][Reward] Agent 1 - 400/1000 epochs completed (latest loss=0.2482)
2025-10-23 09:03:21,687 | INFO | [MA-LfL][Reward] Agent 1 - 500/1000 epochs completed (latest loss=0.2366)
2025-10-23 09:03:23,109 | INFO | [MA-LfL][Reward] Agent 1 - 600/1000 epochs completed (latest loss=0.2359)
2025-10-23 09:03:24,469 | INFO | [MA-LfL][Reward] Agent 1 - 700/1000 epochs completed (latest loss=0.2391)
2025-10-23 09:03:25,844 | INFO | [MA-LfL][Reward] Agent 1 - 800/1000 epochs completed (latest loss=0.2245)
2025-10-23 09:03:27,235 | INFO | [MA-LfL][Reward] Agent 1 - 900/1000 epochs completed (latest loss=0.2294)
2025-10-23 09:03:28,722 | INFO | [MA-LfL][Reward] Agent 1 - 1000/1000 epochs completed (latest loss=0.2337)
2025-10-23 09:03:28,723 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 09:03:29,723 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 09:03:29,723 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 09:03:29,723 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: -0.0580 | Spearman: -0.0536
2025-10-23 09:03:29,723 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: -0.1419 | Spearman: -0.1489
2025-10-23 09:03:29,723 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2
2025-10-23 09:03:29,723 | INFO | [Experiment:heterogeneous] Trend Pearson: 0.3355, 0.3320
2025-10-23 09:03:29,723 | INFO | [Experiment:heterogeneous] Trend Spearman: 0.1984, 0.2410
2025-10-23 09:03:29,724 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 09:03:29,724 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 09:03:29,724 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 09:03:29,725 | INFO | Summary saved to outputs\summary.json
2025-10-23 09:03:29,725 | INFO | Run complete.
