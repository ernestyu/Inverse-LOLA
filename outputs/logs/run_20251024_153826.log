2025-10-24 15:38:26,239 | INFO | Logging initialized. Log file: outputs\logs\run_20251024_153826.log
2025-10-24 15:38:26,240 | INFO | Configuration file: config.yaml
2025-10-24 15:38:26,240 | INFO | Reward families to process: homogeneous, heterogeneous
2025-10-24 15:38:26,240 | INFO | MA-SPI iterations=5, episodes/stage=10, episode_length=100
2025-10-24 15:38:26,240 | INFO | MA-LfL reward epochs=20000, reward batch size=8192
2025-10-24 15:38:26,240 | INFO | Log file located at outputs\logs\run_20251024_153826.log
2025-10-24 15:38:26,240 | INFO | Running experiment for reward family: homogeneous
2025-10-24 15:38:26,240 | INFO | [Experiment:homogeneous] Starting MA-SPI...
2025-10-24 15:38:27,159 | INFO | [MA-SPI] Starting run with 5 stages, 10 episodes/stage, episode length 100
2025-10-24 15:38:27,160 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-24 15:38:27,678 | INFO | [MA-SPI] Stage 1/5 - collected 2/10 episodes
2025-10-24 15:38:27,968 | INFO | [MA-SPI] Stage 1/5 - collected 4/10 episodes
2025-10-24 15:38:28,233 | INFO | [MA-SPI] Stage 1/5 - collected 6/10 episodes
2025-10-24 15:38:28,501 | INFO | [MA-SPI] Stage 1/5 - collected 8/10 episodes
2025-10-24 15:38:28,772 | INFO | [MA-SPI] Stage 1/5 - collected 10/10 episodes
2025-10-24 15:38:28,773 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -430.400 (std 25.703)
2025-10-24 15:38:28,774 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -407.900 (std 21.333)
2025-10-24 15:38:28,774 | INFO | [MA-SPI] Stage 1/5 - dataset size: 1000 transitions
2025-10-24 15:38:29,011 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.6937, A1_Q_loss:0.6853]
2025-10-24 15:38:29,101 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.3960, A1_Q_loss:0.5827]
2025-10-24 15:38:29,189 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.3703, A1_Q_loss:0.5750]
2025-10-24 15:38:29,273 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.3706, A1_Q_loss:0.5785]
2025-10-24 15:38:29,353 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.3707, A1_Q_loss:0.5800]
2025-10-24 15:38:29,389 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0170, A1_Policy_loss:0.0111]
2025-10-24 15:38:29,423 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0044, A1_Policy_loss:0.0028]
2025-10-24 15:38:29,458 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0018, A1_Policy_loss:0.0009]
2025-10-24 15:38:29,491 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0003]
2025-10-24 15:38:29,526 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0001]
2025-10-24 15:38:29,526 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-24 15:38:29,526 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-24 15:38:29,789 | INFO | [MA-SPI] Stage 2/5 - collected 2/10 episodes
2025-10-24 15:38:30,050 | INFO | [MA-SPI] Stage 2/5 - collected 4/10 episodes
2025-10-24 15:38:30,308 | INFO | [MA-SPI] Stage 2/5 - collected 6/10 episodes
2025-10-24 15:38:30,554 | INFO | [MA-SPI] Stage 2/5 - collected 8/10 episodes
2025-10-24 15:38:30,826 | INFO | [MA-SPI] Stage 2/5 - collected 10/10 episodes
2025-10-24 15:38:30,828 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: -332.800 (std 25.443)
2025-10-24 15:38:30,828 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: -332.500 (std 30.270)
2025-10-24 15:38:30,828 | INFO | [MA-SPI] Stage 2/5 - dataset size: 1000 transitions
2025-10-24 15:38:30,913 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.8750, A1_Q_loss:0.5975]
2025-10-24 15:38:30,996 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.7798, A1_Q_loss:0.5613]
2025-10-24 15:38:31,089 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.7016, A1_Q_loss:0.5019]
2025-10-24 15:38:31,174 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.7002, A1_Q_loss:0.4854]
2025-10-24 15:38:31,258 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.7080, A1_Q_loss:0.4915]
2025-10-24 15:38:31,293 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0159, A1_Policy_loss:0.0131]
2025-10-24 15:38:31,331 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0042, A1_Policy_loss:0.0040]
2025-10-24 15:38:31,369 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0012, A1_Policy_loss:0.0014]
2025-10-24 15:38:31,408 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0005]
2025-10-24 15:38:31,446 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0002]
2025-10-24 15:38:31,446 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-24 15:38:31,446 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-24 15:38:31,769 | INFO | [MA-SPI] Stage 3/5 - collected 2/10 episodes
2025-10-24 15:38:32,085 | INFO | [MA-SPI] Stage 3/5 - collected 4/10 episodes
2025-10-24 15:38:32,518 | INFO | [MA-SPI] Stage 3/5 - collected 6/10 episodes
2025-10-24 15:38:32,810 | INFO | [MA-SPI] Stage 3/5 - collected 8/10 episodes
2025-10-24 15:38:33,112 | INFO | [MA-SPI] Stage 3/5 - collected 10/10 episodes
2025-10-24 15:38:33,113 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: -295.800 (std 18.867)
2025-10-24 15:38:33,113 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: -300.200 (std 19.752)
2025-10-24 15:38:33,113 | INFO | [MA-SPI] Stage 3/5 - dataset size: 1000 transitions
2025-10-24 15:38:33,260 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.4541, A1_Q_loss:0.6050]
2025-10-24 15:38:33,382 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.4142, A1_Q_loss:0.4676]
2025-10-24 15:38:33,493 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.4158, A1_Q_loss:0.4564]
2025-10-24 15:38:33,600 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.3974, A1_Q_loss:0.4654]
2025-10-24 15:38:33,704 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.3958, A1_Q_loss:0.4638]
2025-10-24 15:38:33,744 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0131, A1_Policy_loss:0.0074]
2025-10-24 15:38:33,792 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0039, A1_Policy_loss:0.0028]
2025-10-24 15:38:33,845 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0012, A1_Policy_loss:0.0008]
2025-10-24 15:38:33,898 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0002]
2025-10-24 15:38:33,941 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0000]
2025-10-24 15:38:33,941 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-24 15:38:33,942 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-24 15:38:34,284 | INFO | [MA-SPI] Stage 4/5 - collected 2/10 episodes
2025-10-24 15:38:34,573 | INFO | [MA-SPI] Stage 4/5 - collected 4/10 episodes
2025-10-24 15:38:34,843 | INFO | [MA-SPI] Stage 4/5 - collected 6/10 episodes
2025-10-24 15:38:35,244 | INFO | [MA-SPI] Stage 4/5 - collected 8/10 episodes
2025-10-24 15:38:35,548 | INFO | [MA-SPI] Stage 4/5 - collected 10/10 episodes
2025-10-24 15:38:35,549 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: -265.800 (std 24.070)
2025-10-24 15:38:35,549 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: -269.300 (std 17.641)
2025-10-24 15:38:35,549 | INFO | [MA-SPI] Stage 4/5 - dataset size: 1000 transitions
2025-10-24 15:38:35,646 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.4093, A1_Q_loss:0.3209]
2025-10-24 15:38:35,753 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.3501, A1_Q_loss:0.2943]
2025-10-24 15:38:35,856 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.3378, A1_Q_loss:0.2696]
2025-10-24 15:38:35,947 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.3391, A1_Q_loss:0.2686]
2025-10-24 15:38:36,050 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.3349, A1_Q_loss:0.2692]
2025-10-24 15:38:36,097 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0043, A1_Policy_loss:0.0047]
2025-10-24 15:38:36,145 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0015, A1_Policy_loss:0.0015]
2025-10-24 15:38:36,195 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0004, A1_Policy_loss:0.0005]
2025-10-24 15:38:36,256 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-24 15:38:36,299 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:-0.0000]
2025-10-24 15:38:36,299 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-24 15:38:36,299 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-24 15:38:36,589 | INFO | [MA-SPI] Stage 5/5 - collected 2/10 episodes
2025-10-24 15:38:36,878 | INFO | [MA-SPI] Stage 5/5 - collected 4/10 episodes
2025-10-24 15:38:37,191 | INFO | [MA-SPI] Stage 5/5 - collected 6/10 episodes
2025-10-24 15:38:37,472 | INFO | [MA-SPI] Stage 5/5 - collected 8/10 episodes
2025-10-24 15:38:37,772 | INFO | [MA-SPI] Stage 5/5 - collected 10/10 episodes
2025-10-24 15:38:37,774 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: -267.500 (std 21.481)
2025-10-24 15:38:37,774 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: -263.000 (std 22.869)
2025-10-24 15:38:37,774 | INFO | [MA-SPI] Stage 5/5 - dataset size: 1000 transitions
2025-10-24 15:38:37,861 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.3165, A1_Q_loss:0.4460]
2025-10-24 15:38:38,006 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.2773, A1_Q_loss:0.4132]
2025-10-24 15:38:38,163 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.2850, A1_Q_loss:0.4086]
2025-10-24 15:38:38,278 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.2740, A1_Q_loss:0.4054]
2025-10-24 15:38:38,393 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.2773, A1_Q_loss:0.4002]
2025-10-24 15:38:38,445 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0035, A1_Policy_loss:0.0032]
2025-10-24 15:38:38,495 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0013, A1_Policy_loss:0.0011]
2025-10-24 15:38:38,544 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0004]
2025-10-24 15:38:38,598 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0001]
2025-10-24 15:38:38,640 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0000]
2025-10-24 15:38:38,640 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-24 15:38:38,677 | INFO | [Experiment:homogeneous] MA-SPI completed. Artifacts saved to outputs\homogeneous\ma_spi
2025-10-24 15:38:38,677 | INFO | [Experiment:homogeneous] Starting MA-LfL...
2025-10-24 15:38:38,677 | INFO | [MA-LfL] Estimating policies...
2025-10-24 15:38:38,678 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-24 15:38:38,703 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 2/10 epochs completed (loss=3.2695, baseline=1.6094)
2025-10-24 15:38:38,713 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 4/10 epochs completed (loss=1.4244, baseline=1.6094)
2025-10-24 15:38:38,719 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 6/10 epochs completed (loss=1.2134, baseline=1.6094)
2025-10-24 15:38:38,725 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 8/10 epochs completed (loss=1.1068, baseline=1.6094)
2025-10-24 15:38:38,732 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.0913, baseline=1.6094)
2025-10-24 15:38:38,742 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 2/10 epochs completed (loss=3.0694, baseline=1.6094)
2025-10-24 15:38:38,749 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 4/10 epochs completed (loss=1.4800, baseline=1.6094)
2025-10-24 15:38:38,757 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 6/10 epochs completed (loss=1.2070, baseline=1.6094)
2025-10-24 15:38:38,765 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 8/10 epochs completed (loss=1.1019, baseline=1.6094)
2025-10-24 15:38:38,781 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.0798, baseline=1.6094)
2025-10-24 15:38:38,783 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-24 15:38:38,796 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 2/10 epochs completed (loss=3.3306, baseline=1.6094)
2025-10-24 15:38:38,805 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 4/10 epochs completed (loss=1.1918, baseline=1.6094)
2025-10-24 15:38:38,810 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 6/10 epochs completed (loss=1.1541, baseline=1.6094)
2025-10-24 15:38:38,814 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 8/10 epochs completed (loss=1.0701, baseline=1.6094)
2025-10-24 15:38:38,824 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=1.0503, baseline=1.6094)
2025-10-24 15:38:38,837 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 2/10 epochs completed (loss=3.2859, baseline=1.6094)
2025-10-24 15:38:38,849 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 4/10 epochs completed (loss=1.3173, baseline=1.6094)
2025-10-24 15:38:38,862 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 6/10 epochs completed (loss=1.1892, baseline=1.6094)
2025-10-24 15:38:38,875 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 8/10 epochs completed (loss=1.0739, baseline=1.6094)
2025-10-24 15:38:38,889 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=1.0335, baseline=1.6094)
2025-10-24 15:38:38,891 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-24 15:38:38,914 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 2/10 epochs completed (loss=3.2262, baseline=1.6094)
2025-10-24 15:38:38,929 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 4/10 epochs completed (loss=1.2301, baseline=1.6094)
2025-10-24 15:38:38,942 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 6/10 epochs completed (loss=1.1381, baseline=1.6094)
2025-10-24 15:38:38,952 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 8/10 epochs completed (loss=1.0636, baseline=1.6094)
2025-10-24 15:38:38,972 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=1.0439, baseline=1.6094)
2025-10-24 15:38:38,989 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 2/10 epochs completed (loss=3.5857, baseline=1.6094)
2025-10-24 15:38:39,001 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 4/10 epochs completed (loss=1.1026, baseline=1.6094)
2025-10-24 15:38:39,014 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 6/10 epochs completed (loss=1.1593, baseline=1.6094)
2025-10-24 15:38:39,024 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 8/10 epochs completed (loss=1.0514, baseline=1.6094)
2025-10-24 15:38:39,029 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0160, baseline=1.6094)
2025-10-24 15:38:39,030 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-24 15:38:39,039 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 2/10 epochs completed (loss=4.0035, baseline=1.6094)
2025-10-24 15:38:39,053 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 4/10 epochs completed (loss=1.5280, baseline=1.6094)
2025-10-24 15:38:39,066 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 6/10 epochs completed (loss=1.1385, baseline=1.6094)
2025-10-24 15:38:39,075 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 8/10 epochs completed (loss=1.0226, baseline=1.6094)
2025-10-24 15:38:39,084 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=0.9948, baseline=1.6094)
2025-10-24 15:38:39,103 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 2/10 epochs completed (loss=3.7141, baseline=1.6094)
2025-10-24 15:38:39,113 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 4/10 epochs completed (loss=1.7663, baseline=1.6094)
2025-10-24 15:38:39,125 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 6/10 epochs completed (loss=1.1206, baseline=1.6094)
2025-10-24 15:38:39,139 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 8/10 epochs completed (loss=1.0668, baseline=1.6094)
2025-10-24 15:38:39,156 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0180, baseline=1.6094)
2025-10-24 15:38:39,157 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-24 15:38:39,175 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 2/10 epochs completed (loss=4.8186, baseline=1.6094)
2025-10-24 15:38:39,182 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 4/10 epochs completed (loss=1.1204, baseline=1.6094)
2025-10-24 15:38:39,189 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 6/10 epochs completed (loss=1.1921, baseline=1.6094)
2025-10-24 15:38:39,196 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 8/10 epochs completed (loss=1.0787, baseline=1.6094)
2025-10-24 15:38:39,206 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0392, baseline=1.6094)
2025-10-24 15:38:39,214 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 2/10 epochs completed (loss=2.6759, baseline=1.6094)
2025-10-24 15:38:39,226 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 4/10 epochs completed (loss=1.3961, baseline=1.6094)
2025-10-24 15:38:39,235 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 6/10 epochs completed (loss=1.1221, baseline=1.6094)
2025-10-24 15:38:39,247 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 8/10 epochs completed (loss=1.0060, baseline=1.6094)
2025-10-24 15:38:39,258 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=0.9878, baseline=1.6094)
2025-10-24 15:38:39,259 | INFO | [MA-LfL] Computing reward targets...
2025-10-24 15:38:39,259 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-24 15:38:39,737 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-24 15:38:40,189 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-24 15:38:40,651 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-24 15:38:41,109 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-24 15:38:41,554 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-24 15:38:42,025 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-24 15:38:42,526 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-24 15:38:43,018 | INFO | [MA-LfL] Learning rewards...
2025-10-24 15:38:43,022 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=4000 (batch=1024, epochs=20000, reward_lr=5.00e-04, shaping_lr=1.00e-05)
2025-10-24 15:40:01,221 | INFO | [MA-LfL][Reward] Agent 0 - 2000/20000 epochs completed (latest loss=0.9458)
2025-10-24 15:41:15,314 | INFO | [MA-LfL][Reward] Agent 0 - 4000/20000 epochs completed (latest loss=0.9439)
2025-10-24 15:42:34,060 | INFO | [MA-LfL][Reward] Agent 0 - 6000/20000 epochs completed (latest loss=0.9455)
2025-10-24 15:43:43,838 | INFO | [MA-LfL][Reward] Agent 0 - 8000/20000 epochs completed (latest loss=0.9447)
2025-10-24 15:44:54,902 | INFO | [MA-LfL][Reward] Agent 0 - 10000/20000 epochs completed (latest loss=0.9391)
2025-10-24 15:46:02,894 | INFO | [MA-LfL][Reward] Agent 0 - 12000/20000 epochs completed (latest loss=0.9475)
2025-10-24 15:47:09,799 | INFO | [MA-LfL][Reward] Agent 0 - 14000/20000 epochs completed (latest loss=0.9510)
2025-10-24 15:48:18,626 | INFO | [MA-LfL][Reward] Agent 0 - 16000/20000 epochs completed (latest loss=0.9431)
2025-10-24 15:49:26,016 | INFO | [MA-LfL][Reward] Agent 0 - 18000/20000 epochs completed (latest loss=0.9427)
2025-10-24 15:50:35,347 | INFO | [MA-LfL][Reward] Agent 0 - 20000/20000 epochs completed (latest loss=0.9434)
2025-10-24 15:50:35,352 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=4000 (batch=1024, epochs=20000, reward_lr=5.00e-04, shaping_lr=1.00e-05)
2025-10-24 15:51:45,475 | INFO | [MA-LfL][Reward] Agent 1 - 2000/20000 epochs completed (latest loss=0.8067)
2025-10-24 15:52:54,755 | INFO | [MA-LfL][Reward] Agent 1 - 4000/20000 epochs completed (latest loss=0.8050)
2025-10-24 15:54:06,384 | INFO | [MA-LfL][Reward] Agent 1 - 6000/20000 epochs completed (latest loss=0.7999)
2025-10-24 15:55:16,077 | INFO | [MA-LfL][Reward] Agent 1 - 8000/20000 epochs completed (latest loss=0.8002)
2025-10-24 15:56:25,379 | INFO | [MA-LfL][Reward] Agent 1 - 10000/20000 epochs completed (latest loss=0.7992)
2025-10-24 15:57:35,028 | INFO | [MA-LfL][Reward] Agent 1 - 12000/20000 epochs completed (latest loss=0.7998)
2025-10-24 15:58:47,311 | INFO | [MA-LfL][Reward] Agent 1 - 14000/20000 epochs completed (latest loss=0.7985)
2025-10-24 15:59:56,198 | INFO | [MA-LfL][Reward] Agent 1 - 16000/20000 epochs completed (latest loss=0.7971)
2025-10-24 16:01:04,808 | INFO | [MA-LfL][Reward] Agent 1 - 18000/20000 epochs completed (latest loss=0.7983)
2025-10-24 16:02:13,187 | INFO | [MA-LfL][Reward] Agent 1 - 20000/20000 epochs completed (latest loss=0.8004)
2025-10-24 16:02:13,189 | INFO | [MA-LfL] Evaluating rewards (bare + shaped)...
2025-10-24 16:02:14,609 | INFO | [MA-LfL] Computing alignment metrics (R_hat + g - gamma*g' vs Y_h)...
2025-10-24 16:02:14,667 | INFO | [MA-LfL] Pipeline complete.
2025-10-24 16:02:14,667 | INFO | [Experiment:homogeneous] MA-LfL completed. Artifacts saved to outputs\homogeneous\ma_lfl
2025-10-24 16:02:14,667 | INFO | [Experiment:homogeneous] Agent 0 metrics - Pearson: -0.1344 | Spearman: -0.0807
2025-10-24 16:02:14,668 | INFO | [Experiment:homogeneous] Agent 1 metrics - Pearson: -0.2033 | Spearman: -0.1904
2025-10-24 16:02:14,668 | INFO | [Experiment:homogeneous] Trend stages: 1, 2, 3, 4
2025-10-24 16:02:14,668 | INFO | [Experiment:homogeneous] Trend Pearson: -0.2510, -0.3045, -0.4096, -0.3741
2025-10-24 16:02:14,668 | INFO | [Experiment:homogeneous] Trend Spearman: -0.1613, -0.2756, -0.3631, -0.3098
2025-10-24 16:02:14,668 | INFO | [Experiment:homogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-24 16:02:14,668 | INFO | [Experiment:homogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-24 16:02:14,668 | INFO | [Experiment:homogeneous] Correlation trend non-decreasing? NO
2025-10-24 16:02:14,693 | INFO | [Experiment:homogeneous][bare] Pearson (mean): -0.1688 | Spearman (mean): -0.1356
2025-10-24 16:02:14,693 | INFO | [Experiment:homogeneous][bare] Agent 0 - Pearson: -0.1344 | Spearman: -0.0807
2025-10-24 16:02:14,693 | INFO | [Experiment:homogeneous][bare] Agent 1 - Pearson: -0.2033 | Spearman: -0.1904
2025-10-24 16:02:14,693 | INFO | [Experiment:homogeneous][bare] Trend stages: 1, 2, 3, 4
2025-10-24 16:02:14,693 | INFO | [Experiment:homogeneous][bare] Trend Pearson: -0.2510, -0.3045, -0.4096, -0.3741
2025-10-24 16:02:14,693 | INFO | [Experiment:homogeneous][bare] Trend Spearman: -0.1613, -0.2756, -0.3631, -0.3098
2025-10-24 16:02:14,694 | INFO | [Experiment:homogeneous][shaped] Pearson (mean): -0.2131 | Spearman (mean): -0.1927
2025-10-24 16:02:14,694 | INFO | [Experiment:homogeneous][shaped] Agent 0 - Pearson: -0.1992 | Spearman: -0.1675
2025-10-24 16:02:14,694 | INFO | [Experiment:homogeneous][shaped] Agent 1 - Pearson: -0.2271 | Spearman: -0.2179
2025-10-24 16:02:14,694 | INFO | [Experiment:homogeneous][shaped] Trend stages: 1, 2, 3, 4
2025-10-24 16:02:14,694 | INFO | [Experiment:homogeneous][shaped] Trend Pearson: -0.2510, -0.3045, -0.4096, -0.3741
2025-10-24 16:02:14,694 | INFO | [Experiment:homogeneous][shaped] Trend Spearman: -0.1613, -0.2756, -0.3631, -0.3098
2025-10-24 16:02:14,709 | INFO | [Experiment:homogeneous][alignment] Agent 0 - Pearson: 0.8217 | Spearman: 0.7734
2025-10-24 16:02:14,709 | INFO | [Experiment:homogeneous][alignment] Agent 1 - Pearson: 0.8428 | Spearman: 0.8043
2025-10-24 16:02:14,709 | INFO | [Experiment:homogeneous][alignment] Agent 0 stages: 0, 1, 2, 3, 4
2025-10-24 16:02:14,709 | INFO | [Experiment:homogeneous][alignment] Agent 0 Pearson by stage: nan, 0.8649, 0.8100, 0.8370, 0.8038
2025-10-24 16:02:14,709 | INFO | [Experiment:homogeneous][alignment] Agent 0 Spearman by stage: nan, 0.7201, 0.7079, 0.8401, 0.8117
2025-10-24 16:02:14,709 | INFO | [Experiment:homogeneous][alignment] Agent 1 stages: 0, 1, 2, 3, 4
2025-10-24 16:02:14,709 | INFO | [Experiment:homogeneous][alignment] Agent 1 Pearson by stage: nan, 0.8238, 0.8634, 0.8525, 0.8443
2025-10-24 16:02:14,710 | INFO | [Experiment:homogeneous][alignment] Agent 1 Spearman by stage: nan, 0.7603, 0.8298, 0.8229, 0.8207
2025-10-24 16:02:14,711 | INFO | Running experiment for reward family: heterogeneous
2025-10-24 16:02:14,712 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-24 16:02:14,717 | INFO | [MA-SPI] Starting run with 5 stages, 10 episodes/stage, episode length 100
2025-10-24 16:02:14,717 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-24 16:02:15,022 | INFO | [MA-SPI] Stage 1/5 - collected 2/10 episodes
2025-10-24 16:02:15,305 | INFO | [MA-SPI] Stage 1/5 - collected 4/10 episodes
2025-10-24 16:02:15,614 | INFO | [MA-SPI] Stage 1/5 - collected 6/10 episodes
2025-10-24 16:02:15,897 | INFO | [MA-SPI] Stage 1/5 - collected 8/10 episodes
2025-10-24 16:02:16,180 | INFO | [MA-SPI] Stage 1/5 - collected 10/10 episodes
2025-10-24 16:02:16,181 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -137.400 (std 33.539)
2025-10-24 16:02:16,182 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -114.900 (std 35.184)
2025-10-24 16:02:16,182 | INFO | [MA-SPI] Stage 1/5 - dataset size: 1000 transitions
2025-10-24 16:02:16,263 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:2.7630, A1_Q_loss:3.1812]
2025-10-24 16:02:16,344 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.3751, A1_Q_loss:1.4296]
2025-10-24 16:02:16,423 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.8376, A1_Q_loss:1.0367]
2025-10-24 16:02:16,502 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.5093, A1_Q_loss:0.7529]
2025-10-24 16:02:16,605 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4704, A1_Q_loss:0.5672]
2025-10-24 16:02:16,666 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0288, A1_Policy_loss:0.0183]
2025-10-24 16:02:16,713 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0090, A1_Policy_loss:0.0042]
2025-10-24 16:02:16,764 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0034, A1_Policy_loss:0.0015]
2025-10-24 16:02:16,800 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0013, A1_Policy_loss:0.0006]
2025-10-24 16:02:16,833 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0002]
2025-10-24 16:02:16,834 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-24 16:02:16,834 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-24 16:02:17,115 | INFO | [MA-SPI] Stage 2/5 - collected 2/10 episodes
2025-10-24 16:02:17,379 | INFO | [MA-SPI] Stage 2/5 - collected 4/10 episodes
2025-10-24 16:02:17,657 | INFO | [MA-SPI] Stage 2/5 - collected 6/10 episodes
2025-10-24 16:02:17,966 | INFO | [MA-SPI] Stage 2/5 - collected 8/10 episodes
2025-10-24 16:02:18,244 | INFO | [MA-SPI] Stage 2/5 - collected 10/10 episodes
2025-10-24 16:02:18,246 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: 67.000 (std 29.783)
2025-10-24 16:02:18,246 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 47.100 (std 20.535)
2025-10-24 16:02:18,246 | INFO | [MA-SPI] Stage 2/5 - dataset size: 1000 transitions
2025-10-24 16:02:18,331 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:1.6607, A1_Q_loss:1.4316]
2025-10-24 16:02:18,427 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:1.0833, A1_Q_loss:1.1384]
2025-10-24 16:02:18,515 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.9357, A1_Q_loss:1.0149]
2025-10-24 16:02:18,606 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.8746, A1_Q_loss:0.9769]
2025-10-24 16:02:18,703 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.8530, A1_Q_loss:0.9853]
2025-10-24 16:02:18,748 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0158, A1_Policy_loss:0.0072]
2025-10-24 16:02:18,787 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0048, A1_Policy_loss:0.0025]
2025-10-24 16:02:18,837 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0020, A1_Policy_loss:0.0010]
2025-10-24 16:02:18,867 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0004]
2025-10-24 16:02:18,901 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-24 16:02:18,902 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-24 16:02:18,902 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-24 16:02:19,177 | INFO | [MA-SPI] Stage 3/5 - collected 2/10 episodes
2025-10-24 16:02:19,435 | INFO | [MA-SPI] Stage 3/5 - collected 4/10 episodes
2025-10-24 16:02:19,730 | INFO | [MA-SPI] Stage 3/5 - collected 6/10 episodes
2025-10-24 16:02:20,111 | INFO | [MA-SPI] Stage 3/5 - collected 8/10 episodes
2025-10-24 16:02:20,482 | INFO | [MA-SPI] Stage 3/5 - collected 10/10 episodes
2025-10-24 16:02:20,483 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 113.400 (std 28.051)
2025-10-24 16:02:20,484 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 109.100 (std 25.137)
2025-10-24 16:02:20,484 | INFO | [MA-SPI] Stage 3/5 - dataset size: 1000 transitions
2025-10-24 16:02:20,584 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.7991, A1_Q_loss:0.6151]
2025-10-24 16:02:20,686 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.8251, A1_Q_loss:0.5328]
2025-10-24 16:02:20,796 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.7463, A1_Q_loss:0.5244]
2025-10-24 16:02:20,906 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.7612, A1_Q_loss:0.5156]
2025-10-24 16:02:21,019 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.7643, A1_Q_loss:0.5197]
2025-10-24 16:02:21,062 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0067, A1_Policy_loss:0.0051]
2025-10-24 16:02:21,103 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0023, A1_Policy_loss:0.0019]
2025-10-24 16:02:21,145 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0008, A1_Policy_loss:0.0007]
2025-10-24 16:02:21,191 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-24 16:02:21,229 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-24 16:02:21,230 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-24 16:02:21,230 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-24 16:02:21,509 | INFO | [MA-SPI] Stage 4/5 - collected 2/10 episodes
2025-10-24 16:02:21,803 | INFO | [MA-SPI] Stage 4/5 - collected 4/10 episodes
2025-10-24 16:02:22,076 | INFO | [MA-SPI] Stage 4/5 - collected 6/10 episodes
2025-10-24 16:02:22,351 | INFO | [MA-SPI] Stage 4/5 - collected 8/10 episodes
2025-10-24 16:02:22,652 | INFO | [MA-SPI] Stage 4/5 - collected 10/10 episodes
2025-10-24 16:02:22,653 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 112.800 (std 30.225)
2025-10-24 16:02:22,653 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 98.900 (std 33.721)
2025-10-24 16:02:22,653 | INFO | [MA-SPI] Stage 4/5 - dataset size: 1000 transitions
2025-10-24 16:02:22,734 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.5955, A1_Q_loss:0.4295]
2025-10-24 16:02:22,826 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.5255, A1_Q_loss:0.3559]
2025-10-24 16:02:22,905 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.4722, A1_Q_loss:0.3525]
2025-10-24 16:02:22,981 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.5347, A1_Q_loss:0.3298]
2025-10-24 16:02:23,063 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4735, A1_Q_loss:0.3408]
2025-10-24 16:02:23,095 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0037, A1_Policy_loss:0.0032]
2025-10-24 16:02:23,128 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0011, A1_Policy_loss:0.0010]
2025-10-24 16:02:23,169 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0005, A1_Policy_loss:0.0005]
2025-10-24 16:02:23,212 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0002]
2025-10-24 16:02:23,256 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-24 16:02:23,256 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-24 16:02:23,256 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-24 16:02:23,544 | INFO | [MA-SPI] Stage 5/5 - collected 2/10 episodes
2025-10-24 16:02:23,826 | INFO | [MA-SPI] Stage 5/5 - collected 4/10 episodes
2025-10-24 16:02:24,122 | INFO | [MA-SPI] Stage 5/5 - collected 6/10 episodes
2025-10-24 16:02:24,378 | INFO | [MA-SPI] Stage 5/5 - collected 8/10 episodes
2025-10-24 16:02:24,636 | INFO | [MA-SPI] Stage 5/5 - collected 10/10 episodes
2025-10-24 16:02:24,638 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 115.500 (std 18.720)
2025-10-24 16:02:24,638 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 110.000 (std 23.422)
2025-10-24 16:02:24,638 | INFO | [MA-SPI] Stage 5/5 - dataset size: 1000 transitions
2025-10-24 16:02:24,720 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 1000) [A0_Q_loss:0.5018, A1_Q_loss:0.4675]
2025-10-24 16:02:24,794 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 1000) [A0_Q_loss:0.4171, A1_Q_loss:0.4131]
2025-10-24 16:02:24,867 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 1000) [A0_Q_loss:0.4285, A1_Q_loss:0.3537]
2025-10-24 16:02:24,939 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 1000) [A0_Q_loss:0.4103, A1_Q_loss:0.4335]
2025-10-24 16:02:25,017 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 1000) [A0_Q_loss:0.4163, A1_Q_loss:0.4042]
2025-10-24 16:02:25,053 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 1000) [A0_Policy_loss:0.0023, A1_Policy_loss:0.0031]
2025-10-24 16:02:25,089 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 1000) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0012]
2025-10-24 16:02:25,123 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 1000) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0005]
2025-10-24 16:02:25,158 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 1000) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0002]
2025-10-24 16:02:25,192 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 1000) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-24 16:02:25,192 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-24 16:02:25,222 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-24 16:02:25,222 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-24 16:02:25,222 | INFO | [MA-LfL] Estimating policies...
2025-10-24 16:02:25,222 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-24 16:02:25,227 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 2/10 epochs completed (loss=3.2695, baseline=1.6094)
2025-10-24 16:02:25,231 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 4/10 epochs completed (loss=1.4244, baseline=1.6094)
2025-10-24 16:02:25,237 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 6/10 epochs completed (loss=1.2134, baseline=1.6094)
2025-10-24 16:02:25,240 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 8/10 epochs completed (loss=1.1068, baseline=1.6094)
2025-10-24 16:02:25,244 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.0913, baseline=1.6094)
2025-10-24 16:02:25,248 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 2/10 epochs completed (loss=3.0694, baseline=1.6094)
2025-10-24 16:02:25,252 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 4/10 epochs completed (loss=1.4800, baseline=1.6094)
2025-10-24 16:02:25,255 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 6/10 epochs completed (loss=1.2070, baseline=1.6094)
2025-10-24 16:02:25,259 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 8/10 epochs completed (loss=1.1019, baseline=1.6094)
2025-10-24 16:02:25,263 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.0798, baseline=1.6094)
2025-10-24 16:02:25,263 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-24 16:02:25,269 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 2/10 epochs completed (loss=3.1231, baseline=1.6094)
2025-10-24 16:02:25,274 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 4/10 epochs completed (loss=2.5654, baseline=1.6094)
2025-10-24 16:02:25,278 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 6/10 epochs completed (loss=1.2076, baseline=1.6094)
2025-10-24 16:02:25,282 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 8/10 epochs completed (loss=1.0764, baseline=1.6094)
2025-10-24 16:02:25,285 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=0.9976, baseline=1.6094)
2025-10-24 16:02:25,290 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 2/10 epochs completed (loss=2.4523, baseline=1.6094)
2025-10-24 16:02:25,293 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 4/10 epochs completed (loss=1.2198, baseline=1.6094)
2025-10-24 16:02:25,297 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 6/10 epochs completed (loss=1.0589, baseline=1.6094)
2025-10-24 16:02:25,301 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 8/10 epochs completed (loss=1.0233, baseline=1.6094)
2025-10-24 16:02:25,305 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=0.9760, baseline=1.6094)
2025-10-24 16:02:25,305 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-24 16:02:25,311 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 2/10 epochs completed (loss=2.6041, baseline=1.6094)
2025-10-24 16:02:25,315 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 4/10 epochs completed (loss=1.7274, baseline=1.6094)
2025-10-24 16:02:25,319 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 6/10 epochs completed (loss=1.1143, baseline=1.6094)
2025-10-24 16:02:25,325 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 8/10 epochs completed (loss=1.0074, baseline=1.6094)
2025-10-24 16:02:25,329 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=0.9835, baseline=1.6094)
2025-10-24 16:02:25,334 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 2/10 epochs completed (loss=5.7030, baseline=1.6094)
2025-10-24 16:02:25,338 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 4/10 epochs completed (loss=1.6001, baseline=1.6094)
2025-10-24 16:02:25,342 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 6/10 epochs completed (loss=1.2568, baseline=1.6094)
2025-10-24 16:02:25,346 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 8/10 epochs completed (loss=1.0344, baseline=1.6094)
2025-10-24 16:02:25,350 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0029, baseline=1.6094)
2025-10-24 16:02:25,351 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-24 16:02:25,357 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 2/10 epochs completed (loss=2.8728, baseline=1.6094)
2025-10-24 16:02:25,362 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 4/10 epochs completed (loss=1.6201, baseline=1.6094)
2025-10-24 16:02:25,368 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 6/10 epochs completed (loss=1.2387, baseline=1.6094)
2025-10-24 16:02:25,372 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 8/10 epochs completed (loss=1.1303, baseline=1.6094)
2025-10-24 16:02:25,377 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0035, baseline=1.6094)
2025-10-24 16:02:25,383 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 2/10 epochs completed (loss=2.9283, baseline=1.6094)
2025-10-24 16:02:25,387 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 4/10 epochs completed (loss=1.4339, baseline=1.6094)
2025-10-24 16:02:25,391 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 6/10 epochs completed (loss=1.0704, baseline=1.6094)
2025-10-24 16:02:25,396 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 8/10 epochs completed (loss=1.0526, baseline=1.6094)
2025-10-24 16:02:25,403 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0177, baseline=1.6094)
2025-10-24 16:02:25,404 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-24 16:02:25,410 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 2/10 epochs completed (loss=3.1318, baseline=1.6094)
2025-10-24 16:02:25,414 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 4/10 epochs completed (loss=1.6561, baseline=1.6094)
2025-10-24 16:02:25,419 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 6/10 epochs completed (loss=1.0889, baseline=1.6094)
2025-10-24 16:02:25,423 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 8/10 epochs completed (loss=1.0369, baseline=1.6094)
2025-10-24 16:02:25,428 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0083, baseline=1.6094)
2025-10-24 16:02:25,433 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 2/10 epochs completed (loss=3.7079, baseline=1.6094)
2025-10-24 16:02:25,439 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 4/10 epochs completed (loss=1.5068, baseline=1.6094)
2025-10-24 16:02:25,443 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 6/10 epochs completed (loss=1.1110, baseline=1.6094)
2025-10-24 16:02:25,450 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 8/10 epochs completed (loss=1.0331, baseline=1.6094)
2025-10-24 16:02:25,456 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0069, baseline=1.6094)
2025-10-24 16:02:25,457 | INFO | [MA-LfL] Computing reward targets...
2025-10-24 16:02:25,457 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-24 16:02:25,824 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-24 16:02:26,171 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-24 16:02:26,499 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-24 16:02:26,878 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-24 16:02:27,230 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-24 16:02:27,656 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-24 16:02:28,024 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-24 16:02:28,412 | INFO | [MA-LfL] Learning rewards...
2025-10-24 16:02:28,417 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=4000 (batch=1024, epochs=20000, reward_lr=5.00e-04, shaping_lr=1.00e-05)
2025-10-24 16:03:37,027 | INFO | [MA-LfL][Reward] Agent 0 - 2000/20000 epochs completed (latest loss=1.0353)
2025-10-24 16:04:46,462 | INFO | [MA-LfL][Reward] Agent 0 - 4000/20000 epochs completed (latest loss=1.0237)
2025-10-24 16:05:57,455 | INFO | [MA-LfL][Reward] Agent 0 - 6000/20000 epochs completed (latest loss=1.0242)
2025-10-24 16:07:03,332 | INFO | [MA-LfL][Reward] Agent 0 - 8000/20000 epochs completed (latest loss=1.0281)
2025-10-24 16:08:07,793 | INFO | [MA-LfL][Reward] Agent 0 - 10000/20000 epochs completed (latest loss=1.0184)
2025-10-24 16:09:15,706 | INFO | [MA-LfL][Reward] Agent 0 - 12000/20000 epochs completed (latest loss=1.0219)
2025-10-24 16:10:20,946 | INFO | [MA-LfL][Reward] Agent 0 - 14000/20000 epochs completed (latest loss=1.0227)
2025-10-24 16:11:28,799 | INFO | [MA-LfL][Reward] Agent 0 - 16000/20000 epochs completed (latest loss=1.0236)
2025-10-24 16:12:35,926 | INFO | [MA-LfL][Reward] Agent 0 - 18000/20000 epochs completed (latest loss=1.0243)
2025-10-24 16:13:41,508 | INFO | [MA-LfL][Reward] Agent 0 - 20000/20000 epochs completed (latest loss=1.0303)
2025-10-24 16:13:41,512 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=4000 (batch=1024, epochs=20000, reward_lr=5.00e-04, shaping_lr=1.00e-05)
2025-10-24 16:14:50,650 | INFO | [MA-LfL][Reward] Agent 1 - 2000/20000 epochs completed (latest loss=0.7519)
2025-10-24 16:15:57,335 | INFO | [MA-LfL][Reward] Agent 1 - 4000/20000 epochs completed (latest loss=0.7571)
2025-10-24 16:17:06,219 | INFO | [MA-LfL][Reward] Agent 1 - 6000/20000 epochs completed (latest loss=0.7619)
2025-10-24 16:18:16,460 | INFO | [MA-LfL][Reward] Agent 1 - 8000/20000 epochs completed (latest loss=0.7478)
2025-10-24 16:19:25,579 | INFO | [MA-LfL][Reward] Agent 1 - 10000/20000 epochs completed (latest loss=0.7542)
2025-10-24 16:20:31,211 | INFO | [MA-LfL][Reward] Agent 1 - 12000/20000 epochs completed (latest loss=0.7424)
2025-10-24 16:21:38,185 | INFO | [MA-LfL][Reward] Agent 1 - 14000/20000 epochs completed (latest loss=0.7444)
2025-10-24 16:22:46,536 | INFO | [MA-LfL][Reward] Agent 1 - 16000/20000 epochs completed (latest loss=0.7415)
2025-10-24 16:23:55,877 | INFO | [MA-LfL][Reward] Agent 1 - 18000/20000 epochs completed (latest loss=0.7422)
2025-10-24 16:25:05,536 | INFO | [MA-LfL][Reward] Agent 1 - 20000/20000 epochs completed (latest loss=0.7459)
2025-10-24 16:25:05,537 | INFO | [MA-LfL] Evaluating rewards (bare + shaped)...
2025-10-24 16:25:06,938 | INFO | [MA-LfL] Computing alignment metrics (R_hat + g - gamma*g' vs Y_h)...
2025-10-24 16:25:06,983 | INFO | [MA-LfL] Pipeline complete.
2025-10-24 16:25:06,983 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-24 16:25:06,984 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: -0.2177 | Spearman: -0.1912
2025-10-24 16:25:06,984 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: -0.0849 | Spearman: -0.0673
2025-10-24 16:25:06,984 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2, 3, 4
2025-10-24 16:25:06,984 | INFO | [Experiment:heterogeneous] Trend Pearson: -0.4034, -0.6917, -0.5595, -0.5787
2025-10-24 16:25:06,984 | INFO | [Experiment:heterogeneous] Trend Spearman: -0.4059, -0.6826, -0.6808, -0.5968
2025-10-24 16:25:06,985 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-24 16:25:06,985 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-24 16:25:06,985 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-24 16:25:07,012 | INFO | [Experiment:heterogeneous][bare] Pearson (mean): -0.1513 | Spearman (mean): -0.1293
2025-10-24 16:25:07,012 | INFO | [Experiment:heterogeneous][bare] Agent 0 - Pearson: -0.2177 | Spearman: -0.1912
2025-10-24 16:25:07,012 | INFO | [Experiment:heterogeneous][bare] Agent 1 - Pearson: -0.0849 | Spearman: -0.0673
2025-10-24 16:25:07,012 | INFO | [Experiment:heterogeneous][bare] Trend stages: 1, 2, 3, 4
2025-10-24 16:25:07,012 | INFO | [Experiment:heterogeneous][bare] Trend Pearson: -0.4034, -0.6917, -0.5595, -0.5787
2025-10-24 16:25:07,012 | INFO | [Experiment:heterogeneous][bare] Trend Spearman: -0.4059, -0.6826, -0.6808, -0.5968
2025-10-24 16:25:07,012 | INFO | [Experiment:heterogeneous][shaped] Pearson (mean): -0.1493 | Spearman (mean): -0.1280
2025-10-24 16:25:07,013 | INFO | [Experiment:heterogeneous][shaped] Agent 0 - Pearson: -0.2174 | Spearman: -0.1908
2025-10-24 16:25:07,013 | INFO | [Experiment:heterogeneous][shaped] Agent 1 - Pearson: -0.0812 | Spearman: -0.0651
2025-10-24 16:25:07,013 | INFO | [Experiment:heterogeneous][shaped] Trend stages: 1, 2, 3, 4
2025-10-24 16:25:07,013 | INFO | [Experiment:heterogeneous][shaped] Trend Pearson: -0.4034, -0.6917, -0.5595, -0.5787
2025-10-24 16:25:07,013 | INFO | [Experiment:heterogeneous][shaped] Trend Spearman: -0.4059, -0.6826, -0.6808, -0.5968
2025-10-24 16:25:07,027 | INFO | [Experiment:heterogeneous][alignment] Agent 0 - Pearson: 0.8935 | Spearman: 0.7673
2025-10-24 16:25:07,027 | INFO | [Experiment:heterogeneous][alignment] Agent 1 - Pearson: 0.9166 | Spearman: 0.8069
2025-10-24 16:25:07,028 | INFO | [Experiment:heterogeneous][alignment] Agent 0 stages: 0, 1, 2, 3, 4
2025-10-24 16:25:07,028 | INFO | [Experiment:heterogeneous][alignment] Agent 0 Pearson by stage: nan, 0.8857, 0.8800, 0.9169, 0.9037
2025-10-24 16:25:07,028 | INFO | [Experiment:heterogeneous][alignment] Agent 0 Spearman by stage: nan, 0.8378, 0.7002, 0.8462, 0.6690
2025-10-24 16:25:07,028 | INFO | [Experiment:heterogeneous][alignment] Agent 1 stages: 0, 1, 2, 3, 4
2025-10-24 16:25:07,028 | INFO | [Experiment:heterogeneous][alignment] Agent 1 Pearson by stage: nan, 0.8088, 0.9473, 0.9700, 0.9064
2025-10-24 16:25:07,028 | INFO | [Experiment:heterogeneous][alignment] Agent 1 Spearman by stage: nan, 0.7873, 0.8780, 0.7825, 0.8255
2025-10-24 16:25:07,073 | INFO | Saved cross-correlation table to outputs\cross_correlation.csv
2025-10-24 16:25:07,074 | INFO | Summary saved to outputs\summary.json
2025-10-24 16:25:07,074 | INFO | Run complete.
