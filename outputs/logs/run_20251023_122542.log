2025-10-23 12:25:42,418 | INFO | Logging initialized. Log file: outputs\logs\run_20251023_122542.log
2025-10-23 12:25:42,418 | INFO | Configuration file: config.yaml
2025-10-23 12:25:42,418 | INFO | Reward families to process: heterogeneous
2025-10-23 12:25:42,418 | INFO | MA-SPI iterations=5, episodes/stage=200, episode_length=100
2025-10-23 12:25:42,419 | INFO | MA-LfL reward epochs=5000, reward batch size=8192
2025-10-23 12:25:42,419 | INFO | Log file located at outputs\logs\run_20251023_122542.log
2025-10-23 12:25:42,419 | INFO | Running experiment for reward family: heterogeneous
2025-10-23 12:25:42,419 | INFO | [Experiment:heterogeneous] Starting MA-SPI...
2025-10-23 12:25:43,724 | INFO | [MA-SPI] Starting run with 5 stages, 200 episodes/stage, episode length 100
2025-10-23 12:25:43,726 | INFO | [MA-SPI] Stage 1/5 - collecting trajectories...
2025-10-23 12:25:49,428 | INFO | [MA-SPI] Stage 1/5 - collected 40/200 episodes
2025-10-23 12:25:55,197 | INFO | [MA-SPI] Stage 1/5 - collected 80/200 episodes
2025-10-23 12:26:01,202 | INFO | [MA-SPI] Stage 1/5 - collected 120/200 episodes
2025-10-23 12:26:07,085 | INFO | [MA-SPI] Stage 1/5 - collected 160/200 episodes
2025-10-23 12:26:12,822 | INFO | [MA-SPI] Stage 1/5 - collected 200/200 episodes
2025-10-23 12:26:12,836 | INFO | [MA-SPI] Stage 1/5 - Agent 0 avg episode reward: -131.635 (std 30.482)
2025-10-23 12:26:12,836 | INFO | [MA-SPI] Stage 1/5 - Agent 1 avg episode reward: -110.445 (std 29.788)
2025-10-23 12:26:12,836 | INFO | [MA-SPI] Stage 1/5 - dataset size: 20000 transitions
2025-10-23 12:26:13,338 | INFO | [MA-SPI] Stage 1/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:3.0256, A1_Q_loss:3.1238]
2025-10-23 12:26:13,450 | INFO | [MA-SPI] Stage 1/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:1.5581, A1_Q_loss:1.6823]
2025-10-23 12:26:13,561 | INFO | [MA-SPI] Stage 1/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:1.2332, A1_Q_loss:0.9632]
2025-10-23 12:26:13,737 | INFO | [MA-SPI] Stage 1/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.8868, A1_Q_loss:0.7360]
2025-10-23 12:26:13,849 | INFO | [MA-SPI] Stage 1/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:0.7554, A1_Q_loss:0.6767]
2025-10-23 12:26:13,900 | INFO | [MA-SPI] Stage 1/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0275, A1_Policy_loss:0.0189]
2025-10-23 12:26:13,944 | INFO | [MA-SPI] Stage 1/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0089, A1_Policy_loss:0.0060]
2025-10-23 12:26:13,990 | INFO | [MA-SPI] Stage 1/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0032, A1_Policy_loss:0.0016]
2025-10-23 12:26:14,035 | INFO | [MA-SPI] Stage 1/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0009, A1_Policy_loss:0.0007]
2025-10-23 12:26:14,078 | INFO | [MA-SPI] Stage 1/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 12:26:14,078 | INFO | [MA-SPI] Stage 1/5 - completed
2025-10-23 12:26:14,078 | INFO | [MA-SPI] Stage 2/5 - collecting trajectories...
2025-10-23 12:26:19,866 | INFO | [MA-SPI] Stage 2/5 - collected 40/200 episodes
2025-10-23 12:26:25,804 | INFO | [MA-SPI] Stage 2/5 - collected 80/200 episodes
2025-10-23 12:26:31,875 | INFO | [MA-SPI] Stage 2/5 - collected 120/200 episodes
2025-10-23 12:26:38,129 | INFO | [MA-SPI] Stage 2/5 - collected 160/200 episodes
2025-10-23 12:26:44,193 | INFO | [MA-SPI] Stage 2/5 - collected 200/200 episodes
2025-10-23 12:26:44,206 | INFO | [MA-SPI] Stage 2/5 - Agent 0 avg episode reward: 61.390 (std 31.891)
2025-10-23 12:26:44,206 | INFO | [MA-SPI] Stage 2/5 - Agent 1 avg episode reward: 63.750 (std 31.855)
2025-10-23 12:26:44,207 | INFO | [MA-SPI] Stage 2/5 - dataset size: 20000 transitions
2025-10-23 12:26:44,528 | INFO | [MA-SPI] Stage 2/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:1.6991, A1_Q_loss:1.5308]
2025-10-23 12:26:44,652 | INFO | [MA-SPI] Stage 2/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:1.1167, A1_Q_loss:1.1175]
2025-10-23 12:26:44,806 | INFO | [MA-SPI] Stage 2/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:1.0780, A1_Q_loss:1.0005]
2025-10-23 12:26:44,929 | INFO | [MA-SPI] Stage 2/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:1.0346, A1_Q_loss:0.9703]
2025-10-23 12:26:45,048 | INFO | [MA-SPI] Stage 2/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:1.0133, A1_Q_loss:0.9836]
2025-10-23 12:26:45,093 | INFO | [MA-SPI] Stage 2/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0064, A1_Policy_loss:0.0051]
2025-10-23 12:26:45,135 | INFO | [MA-SPI] Stage 2/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0020, A1_Policy_loss:0.0015]
2025-10-23 12:26:45,179 | INFO | [MA-SPI] Stage 2/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0007, A1_Policy_loss:0.0005]
2025-10-23 12:26:45,225 | INFO | [MA-SPI] Stage 2/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0002]
2025-10-23 12:26:45,272 | INFO | [MA-SPI] Stage 2/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 12:26:45,272 | INFO | [MA-SPI] Stage 2/5 - completed
2025-10-23 12:26:45,272 | INFO | [MA-SPI] Stage 3/5 - collecting trajectories...
2025-10-23 12:26:51,162 | INFO | [MA-SPI] Stage 3/5 - collected 40/200 episodes
2025-10-23 12:26:57,032 | INFO | [MA-SPI] Stage 3/5 - collected 80/200 episodes
2025-10-23 12:27:02,765 | INFO | [MA-SPI] Stage 3/5 - collected 120/200 episodes
2025-10-23 12:27:08,650 | INFO | [MA-SPI] Stage 3/5 - collected 160/200 episodes
2025-10-23 12:27:14,565 | INFO | [MA-SPI] Stage 3/5 - collected 200/200 episodes
2025-10-23 12:27:14,578 | INFO | [MA-SPI] Stage 3/5 - Agent 0 avg episode reward: 110.875 (std 19.786)
2025-10-23 12:27:14,578 | INFO | [MA-SPI] Stage 3/5 - Agent 1 avg episode reward: 112.650 (std 20.964)
2025-10-23 12:27:14,578 | INFO | [MA-SPI] Stage 3/5 - dataset size: 20000 transitions
2025-10-23 12:27:14,919 | INFO | [MA-SPI] Stage 3/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:0.4893, A1_Q_loss:0.4451]
2025-10-23 12:27:15,031 | INFO | [MA-SPI] Stage 3/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:0.4705, A1_Q_loss:0.4697]
2025-10-23 12:27:15,148 | INFO | [MA-SPI] Stage 3/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:0.4519, A1_Q_loss:0.4708]
2025-10-23 12:27:15,261 | INFO | [MA-SPI] Stage 3/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.4535, A1_Q_loss:0.4902]
2025-10-23 12:27:15,375 | INFO | [MA-SPI] Stage 3/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:0.4441, A1_Q_loss:0.4682]
2025-10-23 12:27:15,425 | INFO | [MA-SPI] Stage 3/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0013, A1_Policy_loss:0.0007]
2025-10-23 12:27:15,468 | INFO | [MA-SPI] Stage 3/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0003, A1_Policy_loss:0.0003]
2025-10-23 12:27:15,513 | INFO | [MA-SPI] Stage 3/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 12:27:15,557 | INFO | [MA-SPI] Stage 3/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:-0.0000, A1_Policy_loss:0.0001]
2025-10-23 12:27:15,600 | INFO | [MA-SPI] Stage 3/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:-0.0000, A1_Policy_loss:0.0000]
2025-10-23 12:27:15,601 | INFO | [MA-SPI] Stage 3/5 - completed
2025-10-23 12:27:15,601 | INFO | [MA-SPI] Stage 4/5 - collecting trajectories...
2025-10-23 12:27:21,253 | INFO | [MA-SPI] Stage 4/5 - collected 40/200 episodes
2025-10-23 12:27:27,021 | INFO | [MA-SPI] Stage 4/5 - collected 80/200 episodes
2025-10-23 12:27:32,719 | INFO | [MA-SPI] Stage 4/5 - collected 120/200 episodes
2025-10-23 12:27:38,722 | INFO | [MA-SPI] Stage 4/5 - collected 160/200 episodes
2025-10-23 12:27:44,727 | INFO | [MA-SPI] Stage 4/5 - collected 200/200 episodes
2025-10-23 12:27:44,740 | INFO | [MA-SPI] Stage 4/5 - Agent 0 avg episode reward: 103.380 (std 17.979)
2025-10-23 12:27:44,740 | INFO | [MA-SPI] Stage 4/5 - Agent 1 avg episode reward: 105.030 (std 18.415)
2025-10-23 12:27:44,740 | INFO | [MA-SPI] Stage 4/5 - dataset size: 20000 transitions
2025-10-23 12:27:45,108 | INFO | [MA-SPI] Stage 4/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:0.4886, A1_Q_loss:0.5820]
2025-10-23 12:27:45,220 | INFO | [MA-SPI] Stage 4/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:0.5259, A1_Q_loss:0.5548]
2025-10-23 12:27:45,334 | INFO | [MA-SPI] Stage 4/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:0.4945, A1_Q_loss:0.5294]
2025-10-23 12:27:45,445 | INFO | [MA-SPI] Stage 4/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.4875, A1_Q_loss:0.5997]
2025-10-23 12:27:45,569 | INFO | [MA-SPI] Stage 4/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:0.4930, A1_Q_loss:0.5751]
2025-10-23 12:27:45,617 | INFO | [MA-SPI] Stage 4/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0009, A1_Policy_loss:0.0007]
2025-10-23 12:27:45,667 | INFO | [MA-SPI] Stage 4/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0003]
2025-10-23 12:27:45,708 | INFO | [MA-SPI] Stage 4/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 12:27:45,754 | INFO | [MA-SPI] Stage 4/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-23 12:27:45,802 | INFO | [MA-SPI] Stage 4/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0001]
2025-10-23 12:27:45,803 | INFO | [MA-SPI] Stage 4/5 - completed
2025-10-23 12:27:45,803 | INFO | [MA-SPI] Stage 5/5 - collecting trajectories...
2025-10-23 12:27:51,632 | INFO | [MA-SPI] Stage 5/5 - collected 40/200 episodes
2025-10-23 12:27:57,477 | INFO | [MA-SPI] Stage 5/5 - collected 80/200 episodes
2025-10-23 12:28:03,447 | INFO | [MA-SPI] Stage 5/5 - collected 120/200 episodes
2025-10-23 12:28:09,312 | INFO | [MA-SPI] Stage 5/5 - collected 160/200 episodes
2025-10-23 12:28:15,337 | INFO | [MA-SPI] Stage 5/5 - collected 200/200 episodes
2025-10-23 12:28:15,351 | INFO | [MA-SPI] Stage 5/5 - Agent 0 avg episode reward: 107.575 (std 20.314)
2025-10-23 12:28:15,351 | INFO | [MA-SPI] Stage 5/5 - Agent 1 avg episode reward: 107.085 (std 19.812)
2025-10-23 12:28:15,351 | INFO | [MA-SPI] Stage 5/5 - dataset size: 20000 transitions
2025-10-23 12:28:15,696 | INFO | [MA-SPI] Stage 5/5 - Q updates 20/100 (current batch 16384) [A0_Q_loss:0.4890, A1_Q_loss:0.4882]
2025-10-23 12:28:15,806 | INFO | [MA-SPI] Stage 5/5 - Q updates 40/100 (current batch 16384) [A0_Q_loss:0.4388, A1_Q_loss:0.4886]
2025-10-23 12:28:15,919 | INFO | [MA-SPI] Stage 5/5 - Q updates 60/100 (current batch 16384) [A0_Q_loss:0.4309, A1_Q_loss:0.5196]
2025-10-23 12:28:16,039 | INFO | [MA-SPI] Stage 5/5 - Q updates 80/100 (current batch 16384) [A0_Q_loss:0.4548, A1_Q_loss:0.5093]
2025-10-23 12:28:16,162 | INFO | [MA-SPI] Stage 5/5 - Q updates 100/100 (current batch 16384) [A0_Q_loss:0.5027, A1_Q_loss:0.4715]
2025-10-23 12:28:16,212 | INFO | [MA-SPI] Stage 5/5 - policy updates 10/50 (current batch 16384) [A0_Policy_loss:0.0006, A1_Policy_loss:0.0009]
2025-10-23 12:28:16,254 | INFO | [MA-SPI] Stage 5/5 - policy updates 20/50 (current batch 16384) [A0_Policy_loss:0.0002, A1_Policy_loss:0.0003]
2025-10-23 12:28:16,300 | INFO | [MA-SPI] Stage 5/5 - policy updates 30/50 (current batch 16384) [A0_Policy_loss:0.0001, A1_Policy_loss:0.0001]
2025-10-23 12:28:16,343 | INFO | [MA-SPI] Stage 5/5 - policy updates 40/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:0.0000]
2025-10-23 12:28:16,387 | INFO | [MA-SPI] Stage 5/5 - policy updates 50/50 (current batch 16384) [A0_Policy_loss:0.0000, A1_Policy_loss:-0.0000]
2025-10-23 12:28:16,388 | INFO | [MA-SPI] Stage 5/5 - completed
2025-10-23 12:28:16,823 | INFO | [Experiment:heterogeneous] MA-SPI completed. Artifacts saved to outputs\heterogeneous\ma_spi
2025-10-23 12:28:16,823 | INFO | [Experiment:heterogeneous] Starting MA-LfL...
2025-10-23 12:28:16,823 | INFO | [MA-LfL] Estimating policies...
2025-10-23 12:28:16,823 | INFO | [MA-LfL][Policy] Stage 1/5 - preparing data
2025-10-23 12:28:16,952 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 0: 10/10 epochs completed (loss=1.1150, baseline=1.6094)
2025-10-23 12:28:17,025 | INFO | [MA-LfL][Policy] Stage 1/5 - Agent 1: 10/10 epochs completed (loss=1.1067, baseline=1.6094)
2025-10-23 12:28:17,026 | INFO | [MA-LfL][Policy] Stage 2/5 - preparing data
2025-10-23 12:28:17,125 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 0: 10/10 epochs completed (loss=1.0530, baseline=1.6094)
2025-10-23 12:28:17,215 | INFO | [MA-LfL][Policy] Stage 2/5 - Agent 1: 10/10 epochs completed (loss=1.0847, baseline=1.6094)
2025-10-23 12:28:17,216 | INFO | [MA-LfL][Policy] Stage 3/5 - preparing data
2025-10-23 12:28:17,298 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 0: 10/10 epochs completed (loss=1.0561, baseline=1.6094)
2025-10-23 12:28:17,387 | INFO | [MA-LfL][Policy] Stage 3/5 - Agent 1: 10/10 epochs completed (loss=1.0248, baseline=1.6094)
2025-10-23 12:28:17,388 | INFO | [MA-LfL][Policy] Stage 4/5 - preparing data
2025-10-23 12:28:17,509 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 0: 10/10 epochs completed (loss=1.0379, baseline=1.6094)
2025-10-23 12:28:17,588 | INFO | [MA-LfL][Policy] Stage 4/5 - Agent 1: 10/10 epochs completed (loss=1.0546, baseline=1.6094)
2025-10-23 12:28:17,588 | INFO | [MA-LfL][Policy] Stage 5/5 - preparing data
2025-10-23 12:28:17,724 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 0: 10/10 epochs completed (loss=1.0278, baseline=1.6094)
2025-10-23 12:28:17,801 | INFO | [MA-LfL][Policy] Stage 5/5 - Agent 1: 10/10 epochs completed (loss=1.0173, baseline=1.6094)
2025-10-23 12:28:17,802 | INFO | [MA-LfL] Computing reward targets...
2025-10-23 12:28:17,802 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 0
2025-10-23 12:28:18,122 | INFO | [MA-LfL][Targets] Stage 1/4 - Agent 1
2025-10-23 12:28:18,444 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 0
2025-10-23 12:28:18,802 | INFO | [MA-LfL][Targets] Stage 2/4 - Agent 1
2025-10-23 12:28:19,229 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 0
2025-10-23 12:28:19,590 | INFO | [MA-LfL][Targets] Stage 3/4 - Agent 1
2025-10-23 12:28:19,977 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 0
2025-10-23 12:28:20,339 | INFO | [MA-LfL][Targets] Stage 4/4 - Agent 1
2025-10-23 12:28:20,754 | INFO | [MA-LfL] Learning rewards...
2025-10-23 12:28:20,807 | INFO | [MA-LfL][Reward] Agent 0 - dataset size=80000 (batch=8192, epochs=5000)
2025-10-23 12:29:21,378 | INFO | [MA-LfL][Reward] Agent 0 - 500/5000 epochs completed (latest loss=0.3793)
2025-10-23 12:30:23,068 | INFO | [MA-LfL][Reward] Agent 0 - 1000/5000 epochs completed (latest loss=0.3814)
2025-10-23 12:31:26,989 | INFO | [MA-LfL][Reward] Agent 0 - 1500/5000 epochs completed (latest loss=0.3774)
2025-10-23 12:32:28,761 | INFO | [MA-LfL][Reward] Agent 0 - 2000/5000 epochs completed (latest loss=0.3764)
2025-10-23 12:33:27,329 | INFO | [MA-LfL][Reward] Agent 0 - 2500/5000 epochs completed (latest loss=0.3757)
2025-10-23 12:34:26,088 | INFO | [MA-LfL][Reward] Agent 0 - 3000/5000 epochs completed (latest loss=0.3756)
2025-10-23 12:35:26,895 | INFO | [MA-LfL][Reward] Agent 0 - 3500/5000 epochs completed (latest loss=0.3756)
2025-10-23 12:36:27,776 | INFO | [MA-LfL][Reward] Agent 0 - 4000/5000 epochs completed (latest loss=0.3756)
2025-10-23 12:37:25,822 | INFO | [MA-LfL][Reward] Agent 0 - 4500/5000 epochs completed (latest loss=0.3764)
2025-10-23 12:38:45,195 | INFO | [MA-LfL][Reward] Agent 0 - 5000/5000 epochs completed (latest loss=0.3752)
2025-10-23 12:38:45,315 | INFO | [MA-LfL][Reward] Agent 1 - dataset size=80000 (batch=8192, epochs=5000)
2025-10-23 12:39:53,704 | INFO | [MA-LfL][Reward] Agent 1 - 500/5000 epochs completed (latest loss=0.3615)
2025-10-23 12:40:57,049 | INFO | [MA-LfL][Reward] Agent 1 - 1000/5000 epochs completed (latest loss=0.3594)
2025-10-23 12:42:12,356 | INFO | [MA-LfL][Reward] Agent 1 - 1500/5000 epochs completed (latest loss=0.3587)
2025-10-23 12:43:20,897 | INFO | [MA-LfL][Reward] Agent 1 - 2000/5000 epochs completed (latest loss=0.3584)
2025-10-23 12:44:19,158 | INFO | [MA-LfL][Reward] Agent 1 - 2500/5000 epochs completed (latest loss=0.3573)
2025-10-23 12:45:39,489 | INFO | [MA-LfL][Reward] Agent 1 - 3000/5000 epochs completed (latest loss=0.3572)
2025-10-23 12:47:27,979 | INFO | [MA-LfL][Reward] Agent 1 - 3500/5000 epochs completed (latest loss=0.3575)
2025-10-23 12:48:32,301 | INFO | [MA-LfL][Reward] Agent 1 - 4000/5000 epochs completed (latest loss=0.3571)
2025-10-23 12:49:29,036 | INFO | [MA-LfL][Reward] Agent 1 - 4500/5000 epochs completed (latest loss=0.3569)
2025-10-23 12:50:30,284 | INFO | [MA-LfL][Reward] Agent 1 - 5000/5000 epochs completed (latest loss=0.3573)
2025-10-23 12:50:30,285 | INFO | [MA-LfL] Evaluating rewards...
2025-10-23 12:50:31,066 | INFO | [MA-LfL] Pipeline complete.
2025-10-23 12:50:31,066 | INFO | [Experiment:heterogeneous] MA-LfL completed. Artifacts saved to outputs\heterogeneous\ma_lfl
2025-10-23 12:50:31,066 | INFO | [Experiment:heterogeneous] Agent 0 metrics - Pearson: 0.0345 | Spearman: -0.0147
2025-10-23 12:50:31,067 | INFO | [Experiment:heterogeneous] Agent 1 metrics - Pearson: 0.0173 | Spearman: -0.0383
2025-10-23 12:50:31,067 | INFO | [Experiment:heterogeneous] Trend stages: 1, 2, 3, 4
2025-10-23 12:50:31,067 | INFO | [Experiment:heterogeneous] Trend Pearson: 0.3759, 0.3331, 0.2977, 0.3299
2025-10-23 12:50:31,067 | INFO | [Experiment:heterogeneous] Trend Spearman: 0.2937, 0.2300, 0.1859, 0.2771
2025-10-23 12:50:31,067 | INFO | [Experiment:heterogeneous] Agent 0 correlation >=0.4 ? NO
2025-10-23 12:50:31,067 | INFO | [Experiment:heterogeneous] Agent 1 correlation >=0.4 ? NO
2025-10-23 12:50:31,067 | INFO | [Experiment:heterogeneous] Correlation trend non-decreasing? NO
2025-10-23 12:50:31,074 | INFO | Summary saved to outputs\summary.json
2025-10-23 12:50:31,074 | INFO | Run complete.
